{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e84a3200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os   # 导入os模块，用于处理文件路径\n",
    "import sys  # 导入sys模块，用于修改Python的搜索路径\n",
    "sys.path.insert(0, \"/data/jupyternotebook_public/jifengwang/17_HTQC_analysis/AI_prediction_properties\")  # 插入到索引0，确保导入时优先查找父目录"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8f13b19-e16a-4368-892e-850b74a6f8a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "from torch_geometric.loader import DataLoader  \n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool  \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from GATModel import GAT\n",
    "from GCNModel import GCN\n",
    "from MLPModel import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8fdf900-30f1-49a7-a367-2f1ff71d8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 调用样式文件\n",
    "plt.style.use(\"../style.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98ed9c4e-8651-4e49-9bab-61bdbc601b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 固定随机种子\n",
    "def set_seed(seed):\n",
    "    import random\n",
    "    random.seed(seed)  # 固定 Python 的随机种子\n",
    "    np.random.seed(seed)  # 固定 NumPy 的随机种子\n",
    "    torch.manual_seed(seed)  # 固定 PyTorch 的随机种子\n",
    "    torch.cuda.manual_seed(seed)  # 固定 GPU 上的随机种子\n",
    "    torch.backends.cudnn.deterministic = True  # 确保 CuDNN 的确定性\n",
    "    torch.backends.cudnn.benchmark = False  # 禁用非确定性算法优化\n",
    "\n",
    "# 在函数开头调用\n",
    "set_seed(42)  # 42 是种子值，可替换为其他数值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53c83b31-15f2-4679-ac72-0cc90bcf7e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载的数据列表大小: 1668\n",
      "加载的训练数据列表大小: 1334\n",
      "加载的验证数据列表大小: 167\n",
      "加载的测试数据列表大小: 167\n",
      "加载的数据列表大小: 549\n",
      "加载的训练数据列表大小: 439\n",
      "加载的验证数据列表大小: 55\n",
      "加载的测试数据列表大小: 55\n",
      "加载的数据列表大小: 159\n",
      "加载的训练数据列表大小: 127\n",
      "加载的验证数据列表大小: 16\n",
      "加载的测试数据列表大小: 16\n",
      "加载的数据列表大小: 696\n",
      "加载的训练数据列表大小: 556\n",
      "加载的验证数据列表大小: 70\n",
      "加载的测试数据列表大小: 70\n",
      "加载的数据列表大小: 1466\n",
      "加载的训练数据列表大小: 1172\n",
      "加载的验证数据列表大小: 147\n",
      "加载的测试数据列表大小: 147\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# 加载数据集\n",
    "def load_data_list(file_path):\n",
    "    \"\"\"\n",
    "    从指定文件路径加载数据列表。\n",
    "\n",
    "    参数：\n",
    "    file_path (str): 数据列表文件的路径。\n",
    "\n",
    "    返回：\n",
    "    list: 加载的数据列表。\n",
    "    \"\"\"\n",
    "    return torch.load(file_path)\n",
    "\n",
    "############## Tm ##############\n",
    "Tm_load_file_path = '../dataset/Tm_data_list.pt' # 总数据集\n",
    "Tm_load_train_dataset_path = '../dataset/train_Tm_data_list.pt' # 训练集\n",
    "Tm_load_val_dataset_path = '../dataset/val_Tm_data_list.pt' # 验证集\n",
    "Tm_load_test_dataset_path = '../dataset/test_Tm_data_list.pt' # 验证集\n",
    "\n",
    "# 加载数据集\n",
    "Tm_loaded_data_list = load_data_list(Tm_load_file_path)\n",
    "Tm_loaded_train_data_list = load_data_list(Tm_load_train_dataset_path)\n",
    "Tm_loaded_val_data_list = load_data_list(Tm_load_val_dataset_path)\n",
    "Tm_loaded_test_data_list = load_data_list(Tm_load_test_dataset_path)\n",
    "\n",
    "# 打印加载后数据集的信息\n",
    "print(f\"加载的数据列表大小: {len(Tm_loaded_data_list)}\")\n",
    "print(f\"加载的训练数据列表大小: {len(Tm_loaded_train_data_list)}\")\n",
    "print(f\"加载的验证数据列表大小: {len(Tm_loaded_val_data_list)}\")\n",
    "print(f\"加载的测试数据列表大小: {len(Tm_loaded_test_data_list)}\")\n",
    "\n",
    "# 加载训练集、测试集与验证集\n",
    "Tm_train_loader = DataLoader(Tm_loaded_train_data_list, batch_size=32, shuffle=True)  \n",
    "Tm_val_loader = DataLoader(Tm_loaded_val_data_list, batch_size=32, shuffle=False)  \n",
    "Tm_test_loader = DataLoader(Tm_loaded_test_data_list, batch_size=32, shuffle=False) \n",
    "\n",
    "\n",
    "############## conductivity ##############\n",
    "conductivity_load_file_path = '../dataset/conductivity_data_list.pt' # 总数据集\n",
    "conductivity_load_train_dataset_path = '../dataset/train_conductivity_data_list.pt' # 训练集\n",
    "conductivity_load_val_dataset_path = '../dataset/val_conductivity_data_list.pt' # 验证集\n",
    "conductivity_load_test_dataset_path = '../dataset/test_conductivity_data_list.pt' # 验证集\n",
    "\n",
    "# 加载数据集\n",
    "conductivity_loaded_data_list = load_data_list(conductivity_load_file_path)\n",
    "conductivity_loaded_train_data_list = load_data_list(conductivity_load_train_dataset_path)\n",
    "conductivity_loaded_val_data_list = load_data_list(conductivity_load_val_dataset_path)\n",
    "conductivity_loaded_test_data_list = load_data_list(conductivity_load_test_dataset_path)\n",
    "\n",
    "# 打印加载后数据集的信息\n",
    "print(f\"加载的数据列表大小: {len(conductivity_loaded_data_list)}\")\n",
    "print(f\"加载的训练数据列表大小: {len(conductivity_loaded_train_data_list)}\")\n",
    "print(f\"加载的验证数据列表大小: {len(conductivity_loaded_val_data_list)}\")\n",
    "print(f\"加载的测试数据列表大小: {len(conductivity_loaded_test_data_list)}\")\n",
    "\n",
    "# 加载训练集、测试集与验证集\n",
    "conductivity_train_loader = DataLoader(conductivity_loaded_train_data_list, batch_size=32, shuffle=True)  \n",
    "conductivity_val_loader = DataLoader(conductivity_loaded_val_data_list, batch_size=32, shuffle=False)  \n",
    "conductivity_test_loader = DataLoader(conductivity_loaded_test_data_list, batch_size=32, shuffle=False)  \n",
    "\n",
    "######################阴离子氧化势######################\n",
    "anion_ox_save_total_dataset_path = '../dataset/anion_ox_data_list.pt' # 总数据集\n",
    "anion_ox_save_train_dataset_path = '../dataset/train_anion_ox_data_list.pt' # 训练集\n",
    "anion_ox_save_val_dataset_path = '../dataset/val_anion_ox_data_list.pt' # 验证集\n",
    "anion_ox_save_test_dataset_path = '../dataset/test_anion_ox_data_list.pt' # 测试集\n",
    "\n",
    "# 加载数据集\n",
    "anion_ox_loaded_data_list = load_data_list(anion_ox_save_total_dataset_path)\n",
    "anion_ox_loaded_train_data_list = load_data_list(anion_ox_save_train_dataset_path)\n",
    "anion_ox_loaded_val_data_list = load_data_list(anion_ox_save_val_dataset_path)\n",
    "anion_ox_loaded_test_data_list = load_data_list(anion_ox_save_test_dataset_path)\n",
    "\n",
    "# 打印加载后数据集的信息\n",
    "print(f\"加载的数据列表大小: {len(anion_ox_loaded_data_list)}\")\n",
    "print(f\"加载的训练数据列表大小: {len(anion_ox_loaded_train_data_list)}\")\n",
    "print(f\"加载的验证数据列表大小: {len(anion_ox_loaded_val_data_list)}\")\n",
    "print(f\"加载的测试数据列表大小: {len(anion_ox_loaded_test_data_list)}\")\n",
    "\n",
    "# 加载训练集、测试集与验证集\n",
    "anion_ox_train_loader = DataLoader(anion_ox_loaded_train_data_list, batch_size=32, shuffle=True)  \n",
    "anion_ox_val_loader = DataLoader(anion_ox_loaded_val_data_list, batch_size=32, shuffle=False)  \n",
    "anion_ox_test_loader = DataLoader(anion_ox_loaded_test_data_list, batch_size=32, shuffle=False)  \n",
    "\n",
    "######################阳离子还原势######################\n",
    "cation_red_save_total_dataset_path = '../dataset/cation_red_data_list.pt' # 总数据集\n",
    "cation_red_save_train_dataset_path = '../dataset/train_cation_red_data_list.pt' # 训练集\n",
    "cation_red_save_val_dataset_path = '../dataset/val_cation_red_data_list.pt' # 验证集\n",
    "cation_red_save_test_dataset_path = '../dataset/test_cation_red_data_list.pt' # 测试集\n",
    "\n",
    "# 加载数据集\n",
    "cation_red_loaded_data_list = load_data_list(cation_red_save_total_dataset_path)\n",
    "cation_red_loaded_train_data_list = load_data_list(cation_red_save_train_dataset_path)\n",
    "cation_red_loaded_val_data_list = load_data_list(cation_red_save_val_dataset_path)\n",
    "cation_red_loaded_test_data_list = load_data_list(cation_red_save_test_dataset_path)\n",
    "\n",
    "# 打印加载后数据集的信息\n",
    "print(f\"加载的数据列表大小: {len(cation_red_loaded_data_list)}\")\n",
    "print(f\"加载的训练数据列表大小: {len(cation_red_loaded_train_data_list)}\")\n",
    "print(f\"加载的验证数据列表大小: {len(cation_red_loaded_val_data_list)}\")\n",
    "print(f\"加载的测试数据列表大小: {len(cation_red_loaded_test_data_list)}\")\n",
    "\n",
    "# 加载训练集、测试集与验证集\n",
    "cation_red_train_loader = DataLoader(cation_red_loaded_train_data_list, batch_size=32, shuffle=True)  \n",
    "cation_red_val_loader = DataLoader(cation_red_loaded_val_data_list, batch_size=32, shuffle=False)  \n",
    "cation_red_test_loader = DataLoader(cation_red_loaded_test_data_list, batch_size=32, shuffle=False)  \n",
    "# 加载训练集、测试集与验证集\n",
    "cation_red_train_loader = DataLoader(cation_red_loaded_train_data_list, batch_size=32, shuffle=True)  \n",
    "cation_red_val_loader = DataLoader(cation_red_loaded_val_data_list, batch_size=32, shuffle=False)  \n",
    "cation_red_test_loader = DataLoader(cation_red_loaded_test_data_list, batch_size=32, shuffle=False)  \n",
    "\n",
    "######################离子液体ECW######################\n",
    "IL_ECW_save_total_dataset_path = '../dataset/IL_ECW_data_list.pt' # 总数据集\n",
    "IL_ECW_save_train_dataset_path = '../dataset/train_IL_ECW_data_list.pt' # 训练集\n",
    "IL_ECW_save_val_dataset_path = '../dataset/val_IL_ECW_data_list.pt' # 验证集\n",
    "IL_ECW_save_test_dataset_path = '../dataset/test_IL_ECW_data_list.pt' # 测试集\n",
    "\n",
    "# 加载数据集\n",
    "IL_ECW_loaded_data_list = load_data_list(IL_ECW_save_total_dataset_path)\n",
    "IL_ECW_loaded_train_data_list = load_data_list(IL_ECW_save_train_dataset_path)\n",
    "IL_ECW_loaded_val_data_list = load_data_list(IL_ECW_save_val_dataset_path)\n",
    "IL_ECW_loaded_test_data_list = load_data_list(IL_ECW_save_test_dataset_path)\n",
    "\n",
    "# 打印加载后数据集的信息\n",
    "print(f\"加载的数据列表大小: {len(IL_ECW_loaded_data_list)}\")\n",
    "print(f\"加载的训练数据列表大小: {len(IL_ECW_loaded_train_data_list)}\")\n",
    "print(f\"加载的验证数据列表大小: {len(IL_ECW_loaded_val_data_list)}\")\n",
    "print(f\"加载的测试数据列表大小: {len(IL_ECW_loaded_test_data_list)}\")\n",
    "\n",
    "# 加载训练集、测试集与验证集\n",
    "IL_ECW_train_loader = DataLoader(IL_ECW_loaded_train_data_list, batch_size=32, shuffle=True)  \n",
    "IL_ECW_val_loader = DataLoader(IL_ECW_loaded_val_data_list, batch_size=32, shuffle=False)  \n",
    "IL_ECW_test_loader = DataLoader(IL_ECW_loaded_test_data_list, batch_size=32, shuffle=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2bc14f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[28, 5], edge_index=[2, 58], y=[1, 1], idx=[1], name='Cationname227', smiles='[H]c1n[n+](C([H])([H])C([H])([H])Oc2c([H])c([H])c([H])c([H])c2[H])c([H])c([H])c1[H]', morgan_fp=[1, 2048], moldescriptor=[1, 183])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cation_red_loaded_train_data_list[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bd1426e-5d77-4655-8fc2-b8287f29126e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算模型参数量\n",
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    计算模型的总参数量。\n",
    "    参数:\n",
    "        model: PyTorch 模型\n",
    "    返回:\n",
    "        total_params: 模型的总参数量\n",
    "    \"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "060632a3-e3e4-49fc-aa52-f05dd0bfea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 设置设备为GPU（如果可用），否则使用CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def training(index, loader, model, loss_fn, optimizer, scale=1):\n",
    "    \"\"\"\n",
    "    训练函数，对模型进行一个epoch的训练。\n",
    "\n",
    "    参数：\n",
    "    - loader: DataLoader对象，训练数据加载器\n",
    "    - model: 待训练的模型\n",
    "    - loss_fn: 损失函数\n",
    "    - optimizer: 优化器\n",
    "\n",
    "    返回：\n",
    "    - average_loss: 当前epoch的平均损失\n",
    "    \"\"\"\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    total_loss = 0  # 初始化总损失\n",
    "    \n",
    "    for data in loader:  # 遍历每个批次的数据\n",
    "        data = data.to(device)  # 将数据移动到GPU\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        data.x = data.x.float()  # 将节点特征转换为浮点数\n",
    "        out = model(data)  # 前向传播计算输出\n",
    "        loss = loss_fn(out, scale*data.y.view(-1, 1))  # 只取 y 的最后一列作为真值\n",
    "        loss.backward()  # 反向传播计算梯度\n",
    "        optimizer.step()  # 更新模型参数\n",
    "        total_loss += loss.item()  # 累加损失值\n",
    "        \n",
    "    average_loss = total_loss / len(loader)  # 计算平均损失\n",
    "\n",
    "    \n",
    "    return average_loss  # 返回当前epoch的平均损失\n",
    "\n",
    "def validation(index, loader, model, loss_fn, scale=1):\n",
    "    \"\"\"\n",
    "    验证函数，评估模型在验证集上的性能。\n",
    "\n",
    "    参数：\n",
    "    - loader: DataLoader对象，验证数据加载器\n",
    "    - model: 待评估的模型\n",
    "    - loss_fn: 损失函数\n",
    "\n",
    "    返回：\n",
    "    - average_loss: 验证集上的平均损失\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    total_loss = 0  # 初始化总损失\n",
    "    \n",
    "    with torch.no_grad():  # 禁用梯度计算，节省内存\n",
    "        for data in loader:  # 遍历验证集中的每个批次\n",
    "            data = data.to(device)  # 将数据移动到GPU\n",
    "            data.x = data.x.float()  # 将节点特征转换为浮点数\n",
    "            out = model(data)  # 前向传播计算输出\n",
    "            loss = loss_fn(out, scale*data.y.view(-1, 1))  # 只取 y 的最后一列作为真值\n",
    "            total_loss += loss.item()  # 累加损失值\n",
    "            \n",
    "    average_loss = total_loss / len(loader)  # 计算平均损失\n",
    "    \n",
    "    return average_loss  # 返回验证集的平均损失\n",
    "\n",
    "def train_epochs(index, epochs, model, train_loader, val_loader, test_loader, path, scale=1):\n",
    "    \"\"\"\n",
    "    训练多个epoch的函数，并在每个epoch后进行验证。\n",
    "\n",
    "    参数：\n",
    "    - epochs: 总的训练epoch数\n",
    "    - model: 待训练的模型\n",
    "    - train_loader: DataLoader对象，训练数据加载器\n",
    "    - val_loader: DataLoader对象，验证数据加载器\n",
    "    - path: 保存最佳模型的路径\n",
    "\n",
    "    返回：\n",
    "    - train_losses: 包含每个epoch训练损失的数组\n",
    "    - val_losses: 包含每个epoch验证损失的数组\n",
    "    - train_pred: 最后一个epoch的训练集预测值数组\n",
    "    - train_true: 最后一个epoch的训练集真实值数组\n",
    "    \"\"\"\n",
    "    # 定义初始学习率\n",
    "    initial_lr = 5e-4\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), initial_lr, weight_decay=5e-4)  # 定义优化器\n",
    "    loss_fn = torch.nn.MSELoss()  # 定义均方误差损失函数\n",
    "\n",
    "    train_losses = np.zeros(epochs)  # 初始化存储每个epoch训练损失的数组\n",
    "    val_losses = np.zeros(epochs)  # 初始化存储每个epoch验证损失的数组\n",
    "    best_loss = float('inf')  # 初始化最佳验证损失为正无穷\n",
    "\n",
    "    patience_counter = 0        # 初始化早停计数器\n",
    "    max_patience = epochs/10           # 设置连续没有改进的最大轮数为epochs/10\n",
    "\n",
    "    # 当前学习率变量，便于后续动态调整\n",
    "    current_lr = initial_lr\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # 训练一个epoch并获取平均训练损失\n",
    "        train_loss = training(index, train_loader, model, loss_fn, optimizer, scale)\n",
    "        # 验证当前模型并获取平均验证损失\n",
    "        val_loss = validation(index, val_loader, model, loss_fn, scale)\n",
    "        \n",
    "        # 记录当前epoch的训练和验证损失\n",
    "        train_losses[epoch] = train_loss\n",
    "        val_losses[epoch] = val_loss\n",
    "\n",
    "        # 打印当前epoch的损失情况\n",
    "        print(f\"Epoch: {epoch}, Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}\")\n",
    "\n",
    "        # 检查验证损失是否得到改善\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), path)  # 保存当前最佳模型\n",
    "            print(\"Model has been saved!\")\n",
    "            # 改进时重置早停计数器\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            # 若无改善，早停计数器加1\n",
    "            patience_counter += 1\n",
    "            print(f\"Patience counter: {patience_counter}\")\n",
    "            # 检查是否达到连续无改进的最大轮数\n",
    "            if patience_counter >= max_patience:\n",
    "                # 判断当前学习率是否还可以降低\n",
    "                if current_lr > initial_lr / 1000:\n",
    "                    # 降低学习率为原来的1/10\n",
    "                    current_lr /= 10\n",
    "                    # 更新优化器中每个参数组的学习率\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        param_group['lr'] = current_lr\n",
    "                    print(f\"Learning rate reduced to: {current_lr}\")\n",
    "                    # 降低学习率后重置早停计数器，继续训练\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    # 当学习率已经降至初始学习率的1/1000且仍无改进时，触发提前停止\n",
    "                    print(f\"Early stopping triggered. Learning rate has reached its minimum threshold ({current_lr}).\")\n",
    "                    break\n",
    "\n",
    "    # 在测试集上对模型进行评估\n",
    "    model.load_state_dict(torch.load(path)) # 加载训练结束后最好的模型\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    test_pred = []\n",
    "    test_true = []\n",
    "    loss_fn = torch.nn.MSELoss()  # 定义均方误差损失函数\n",
    "\n",
    "    # 在测试集上进行评估\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        data.x = data.x.float()\n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, scale*data.y.view(-1, 1))  # 只取 y 的最后一列作为真值\n",
    "        total_loss += loss.item()\n",
    "        # 模型输出的预测值已经是在放大后的尺度上\n",
    "        test_pred.append(out.detach().cpu().numpy())\n",
    "        test_true.append(scale*data.y.cpu().numpy())\n",
    "\n",
    "    test_pred = np.concatenate(test_pred, axis=0)\n",
    "    test_true = np.concatenate(test_true, axis=0)\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "\n",
    "    # 计算测试集上的指标：MSE, MAE 和 R2\n",
    "    test_pred_flat = test_pred.flatten()  # 扁平化预测结果\n",
    "    test_true_flat = test_true.flatten()  # 扁平化真实值\n",
    "    test_mse = mean_squared_error(test_true_flat, test_pred_flat)\n",
    "    test_mae = mean_absolute_error(test_true_flat, test_pred_flat)\n",
    "    test_r2 = r2_score(test_true_flat, test_pred_flat)\n",
    "\n",
    "    print(f\"Test Loss: {average_loss:.4f}, MSE: {test_mse:.4f}, MAE: {test_mae:.4f}, R2: {test_r2:.4f}\")\n",
    "    \n",
    "    return train_losses, val_losses, test_pred, test_true, test_mse, test_mae, test_r2  # 返回损失和预测结果\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "678cc6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# 设置设备为GPU（如果可用），否则使用CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def training_mlp(index, loader, model, loss_fn, optimizer, scale=10, input_type=\"fp\"):\n",
    "    \"\"\"\n",
    "    训练函数，对模型进行一个epoch的训练。\n",
    "\n",
    "    参数：\n",
    "    - loader: DataLoader对象，训练数据加载器\n",
    "    - model: 待训练的模型\n",
    "    - loss_fn: 损失函数\n",
    "    - optimizer: 优化器\n",
    "    - input_type: 可选\"fp\"（分子指纹）或者“2Ddescriptors”\n",
    "    返回：\n",
    "    - average_loss: 当前epoch的平均损失\n",
    "    \"\"\"\n",
    "    model.train()  # 设置模型为训练模式\n",
    "    total_loss = 0  # 初始化总损失\n",
    "    for data in loader:  # 遍历每个批次的数据\n",
    "        data = data.to(device)  # 将数据移动到GPU\n",
    "        optimizer.zero_grad()  # 清空梯度\n",
    "        \n",
    "        if input_type==\"fp\":\n",
    "            data.morgan_fp = data.morgan_fp.float()  # 将节点特征转换为浮点数\n",
    "        elif input_type==\"2Ddescriptors\":\n",
    "            data.moldescriptor = data.moldescriptor.float()  # 将节点特征转换为浮点数\n",
    "            \n",
    "        out = model(data)  # 前向传播计算输出\n",
    "        loss = loss_fn(out, scale*data.y.view(-1, 1))  # 只取 y 的最后一列作为真值，由于单位转化为ms/cm，所以y值需要乘以10\n",
    "        loss.backward()  # 反向传播计算梯度\n",
    "        optimizer.step()  # 更新模型参数\n",
    "        total_loss += loss.item()  # 累加损失值\n",
    "    average_loss = total_loss / len(loader)  # 计算平均损失\n",
    "    return average_loss  # 返回当前epoch的平均损失\n",
    "\n",
    "def validation_mlp(index, loader, model, loss_fn, scale=10, input_type=\"fp\"):\n",
    "    \"\"\"\n",
    "    验证函数，评估模型在验证集上的性能。\n",
    "\n",
    "    参数：\n",
    "    - loader: DataLoader对象，验证数据加载器\n",
    "    - model: 待评估的模型\n",
    "    - loss_fn: 损失函数\n",
    "\n",
    "    返回：\n",
    "    - average_loss: 验证集上的平均损失\n",
    "    \"\"\"\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    total_loss = 0  # 初始化总损失\n",
    "    with torch.no_grad():  # 禁用梯度计算，节省内存\n",
    "        for data in loader:  # 遍历验证集中的每个批次\n",
    "            data = data.to(device)  # 将数据移动到GPU\n",
    "            \n",
    "            if input_type==\"fp\":\n",
    "                data.morgan_fp = data.morgan_fp.float()  # 将节点特征转换为浮点数\n",
    "            elif input_type==\"2Ddescriptors\":\n",
    "                data.moldescriptor = data.moldescriptor.float()  # 将节点特征转换为浮点数\n",
    "\n",
    "            out = model(data)  # 前向传播计算输出\n",
    "            loss = loss_fn(out, scale*data.y.view(-1, 1))  # 只取 y 的最后一列作为真值\n",
    "            total_loss += loss.item()  # 累加损失值\n",
    "    average_loss = total_loss / len(loader)  # 计算平均损失\n",
    "    return average_loss  # 返回验证集的平均损失\n",
    "\n",
    "def train_epochs_mlp(index, epochs, model, train_loader, val_loader, test_loader, path, scale=10, input_type=\"fp\"):\n",
    "    \"\"\"\n",
    "    训练多个epoch的函数，并在每个epoch后进行验证。\n",
    "\n",
    "    参数：\n",
    "    - epochs: 总的训练epoch数\n",
    "    - model: 待训练的模型\n",
    "    - train_loader: DataLoader对象，训练数据加载器\n",
    "    - val_loader: DataLoader对象，验证数据加载器\n",
    "    - path: 保存最佳模型的路径\n",
    "\n",
    "    返回：\n",
    "    - train_losses: 包含每个epoch训练损失的数组\n",
    "    - val_losses: 包含每个epoch验证损失的数组\n",
    "    - train_pred: 最后一个epoch的训练集预测值数组\n",
    "    - train_true: 最后一个epoch的训练集真实值数组\n",
    "    \"\"\"\n",
    "    initial_lr = 5e-4\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr, weight_decay=5e-4)  # 定义优化器\n",
    "    loss_fn = torch.nn.MSELoss()  # 定义均方误差损失函数\n",
    "\n",
    "    train_losses = np.zeros(epochs)  # 初始化存储每个epoch训练损失的数组\n",
    "    val_losses = np.zeros(epochs)  # 初始化存储每个epoch验证损失的数组\n",
    "    best_loss = float('inf')  # 初始化最佳验证损失为正无穷\n",
    "\n",
    "    patience_counter = 0        # 初始化早停计数器\n",
    "    max_patience = epochs/10           # 设置连续没有改进的最大轮数为epochs/20\n",
    "    # 当前学习率变量，便于后续动态调整\n",
    "    current_lr = initial_lr\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # 训练一个epoch并获取平均训练损失\n",
    "        train_loss = training_mlp(index, train_loader, model, loss_fn, optimizer, scale, input_type=\"fp\")\n",
    "        # 验证当前模型并获取平均验证损失\n",
    "        val_loss = validation_mlp(index, val_loader, model, loss_fn, scale, input_type=\"fp\")\n",
    "        \n",
    "        # 记录当前epoch的训练和验证损失\n",
    "        train_losses[epoch] = train_loss\n",
    "        val_losses[epoch] = val_loss\n",
    "\n",
    "        # 打印当前epoch的损失情况\n",
    "        print(f\"Epoch: {epoch}, Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}\")\n",
    "\n",
    "        # 检查验证损失是否得到改善\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), path)  # 保存当前最佳模型\n",
    "            print(\"Model has been saved!\")\n",
    "            # 改进时重置早停计数器\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            # 若无改善，早停计数器加1\n",
    "            patience_counter += 1\n",
    "            print(f\"Patience counter: {patience_counter}\")\n",
    "            # 检查是否达到连续无改进的最大轮数\n",
    "            if patience_counter >= max_patience:\n",
    "                # 判断当前学习率是否还可以降低\n",
    "                if current_lr > initial_lr / 1000:\n",
    "                    # 降低学习率为原来的1/10\n",
    "                    current_lr /= 10\n",
    "                    # 更新优化器中每个参数组的学习率\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        param_group['lr'] = current_lr\n",
    "                    print(f\"Learning rate reduced to: {current_lr}\")\n",
    "                    # 降低学习率后重置早停计数器，继续训练\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    # 当学习率已经降至初始学习率的1/1000且仍无改进时，触发提前停止\n",
    "                    print(f\"Early stopping triggered. Learning rate has reached its minimum threshold ({current_lr}).\")\n",
    "                    break\n",
    "\n",
    "    # 在测试集上对模型进行评估\n",
    "    model.load_state_dict(torch.load(path)) # 加载训练结束后最好的模型\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    test_pred = []\n",
    "    test_true = []\n",
    "    loss_fn = torch.nn.MSELoss()  # 定义均方误差损失函数\n",
    "\n",
    "    # 在测试集上进行评估\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        if input_type==\"fp\":\n",
    "            data.morgan_fp = data.morgan_fp.float()  # 将节点特征转换为浮点数\n",
    "        elif input_type==\"2Ddescriptors\":\n",
    "            data.moldescriptor = data.moldescriptor.float()  # 将节点特征转换为浮点数\n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, scale*data.y.view(-1, 1))  # 只取 y 的最后一列作为真值\n",
    "        total_loss += loss.item()\n",
    "        # 模型输出的预测值已经是在放大后的尺度上\n",
    "        test_pred.append(out.detach().cpu().numpy())\n",
    "        # 为了保证尺度一致\n",
    "        test_true.append(scale*data.y.cpu().numpy())\n",
    "\n",
    "    test_pred = np.concatenate(test_pred, axis=0)\n",
    "    test_true = np.concatenate(test_true, axis=0)\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "\n",
    "    # 计算测试集上的指标：MSE, MAE 和 R2\n",
    "    test_pred_flat = test_pred.flatten()  # 扁平化预测结果\n",
    "    test_true_flat = test_true.flatten()  # 扁平化真实值\n",
    "    test_mse = mean_squared_error(test_true_flat, test_pred_flat)\n",
    "    test_mae = mean_absolute_error(test_true_flat, test_pred_flat)\n",
    "    test_r2 = r2_score(test_true_flat, test_pred_flat)\n",
    "\n",
    "    print(f\"Test Loss: {average_loss:.4f}, MSE: {test_mse:.4f}, MAE: {test_mae:.4f}, R2: {test_r2:.4f}\")\n",
    "    \n",
    "    return train_losses, val_losses, test_pred, test_true, test_mse, test_mae, test_r2  # 返回损失和预测结果\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13cd444c-a852-4d03-b102-d6308967538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAT\n",
    "model_Tm_GAT = GAT(in_channels=5,hidden_channels=256).to(device)  \n",
    "model_conductivity_GAT = GAT(in_channels=5,hidden_channels=256).to(device)  \n",
    "model_anion_ox_GAT = GAT(in_channels=5,hidden_channels=256).to(device)  \n",
    "model_cation_red_GAT = GAT(in_channels=5,hidden_channels=256).to(device)  \n",
    "model_IL_ECW_GAT = GAT(in_channels=5,hidden_channels=256).to(device) \n",
    "# GCN\n",
    "model_Tm_GCN = GCN(hidden_dim=128).to(device)\n",
    "model_conductivity_GCN = GCN(hidden_dim=128).to(device) \n",
    "model_anion_ox_GCN = GCN(hidden_dim=128).to(device) \n",
    "model_cation_red_GCN = GCN(hidden_dim=128).to(device) \n",
    "model_IL_ECW_GCN = GCN(hidden_dim=128).to(device) \n",
    "# MLP\n",
    "input_size = 2048\n",
    "hidden_sizes = [256, 64]\n",
    "output_size = 1\n",
    "epochs = 200\n",
    "model_Tm_MLP = MLP(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size).to(device) \n",
    "model_conductivity_MLP = MLP(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size).to(device) \n",
    "model_anion_ox_MLP = MLP(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size).to(device) \n",
    "model_cation_red_MLP = MLP(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size).to(device) \n",
    "model_IL_ECW_MLP = MLP(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size).to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cabc2b",
   "metadata": {},
   "source": [
    "# GAT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee2dd6-0d79-4afa-8d68-82ffd27c243f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 6.3579, Val loss: 4.7279\n",
      "Model has been saved!\n",
      "Epoch: 1, Train loss: 5.5067, Val loss: 4.7029\n",
      "Model has been saved!\n",
      "Epoch: 2, Train loss: 5.1164, Val loss: 4.7005\n",
      "Model has been saved!\n",
      "Epoch: 3, Train loss: 5.4283, Val loss: 4.8492\n",
      "Patience counter: 1\n",
      "Epoch: 4, Train loss: 4.8972, Val loss: 4.3962\n",
      "Model has been saved!\n",
      "Epoch: 5, Train loss: 5.1182, Val loss: 4.3173\n",
      "Model has been saved!\n",
      "Epoch: 6, Train loss: 5.0397, Val loss: 4.2361\n",
      "Model has been saved!\n",
      "Epoch: 7, Train loss: 4.7135, Val loss: 4.1502\n",
      "Model has been saved!\n",
      "Epoch: 8, Train loss: 4.6985, Val loss: 4.1015\n",
      "Model has been saved!\n",
      "Epoch: 9, Train loss: 4.6534, Val loss: 4.1630\n",
      "Patience counter: 1\n",
      "Epoch: 10, Train loss: 4.7291, Val loss: 4.0575\n",
      "Model has been saved!\n",
      "Epoch: 11, Train loss: 4.7766, Val loss: 4.0638\n",
      "Patience counter: 1\n",
      "Epoch: 12, Train loss: 4.3567, Val loss: 3.9738\n",
      "Model has been saved!\n",
      "Epoch: 13, Train loss: 4.6638, Val loss: 4.0701\n",
      "Patience counter: 1\n",
      "Epoch: 14, Train loss: 4.6076, Val loss: 4.0470\n",
      "Patience counter: 2\n",
      "Epoch: 15, Train loss: 4.5400, Val loss: 3.9273\n",
      "Model has been saved!\n",
      "Epoch: 16, Train loss: 4.5581, Val loss: 3.9457\n",
      "Patience counter: 1\n",
      "Epoch: 17, Train loss: 4.2176, Val loss: 3.9500\n",
      "Patience counter: 2\n",
      "Epoch: 18, Train loss: 4.4347, Val loss: 3.9007\n",
      "Model has been saved!\n",
      "Epoch: 19, Train loss: 4.5593, Val loss: 3.9034\n",
      "Patience counter: 1\n",
      "Epoch: 20, Train loss: 4.3377, Val loss: 4.0343\n",
      "Patience counter: 2\n",
      "Epoch: 21, Train loss: 4.3650, Val loss: 3.8898\n",
      "Model has been saved!\n",
      "Epoch: 22, Train loss: 4.3202, Val loss: 3.8422\n",
      "Model has been saved!\n",
      "Epoch: 23, Train loss: 4.2726, Val loss: 3.9559\n",
      "Patience counter: 1\n",
      "Epoch: 24, Train loss: 4.4064, Val loss: 4.2956\n",
      "Patience counter: 2\n",
      "Epoch: 25, Train loss: 4.3728, Val loss: 3.8118\n",
      "Model has been saved!\n",
      "Epoch: 26, Train loss: 4.2356, Val loss: 3.8267\n",
      "Patience counter: 1\n",
      "Epoch: 27, Train loss: 4.2187, Val loss: 3.9990\n",
      "Patience counter: 2\n",
      "Epoch: 28, Train loss: 4.4779, Val loss: 4.0398\n",
      "Patience counter: 3\n",
      "Epoch: 29, Train loss: 4.2272, Val loss: 3.8370\n",
      "Patience counter: 4\n",
      "Epoch: 30, Train loss: 4.1926, Val loss: 3.9357\n",
      "Patience counter: 5\n",
      "Epoch: 31, Train loss: 4.2859, Val loss: 3.8260\n",
      "Patience counter: 6\n",
      "Epoch: 32, Train loss: 4.3023, Val loss: 3.8075\n",
      "Model has been saved!\n",
      "Epoch: 33, Train loss: 4.1674, Val loss: 3.8001\n",
      "Model has been saved!\n",
      "Epoch: 34, Train loss: 4.2488, Val loss: 3.8692\n",
      "Patience counter: 1\n",
      "Epoch: 35, Train loss: 4.2767, Val loss: 3.8600\n",
      "Patience counter: 2\n",
      "Epoch: 36, Train loss: 4.0675, Val loss: 3.7771\n",
      "Model has been saved!\n",
      "Epoch: 37, Train loss: 4.3077, Val loss: 3.8001\n",
      "Patience counter: 1\n",
      "Epoch: 38, Train loss: 3.9933, Val loss: 4.0089\n",
      "Patience counter: 2\n",
      "Epoch: 39, Train loss: 4.2657, Val loss: 3.7703\n",
      "Model has been saved!\n",
      "Epoch: 40, Train loss: 4.0776, Val loss: 3.7654\n",
      "Model has been saved!\n",
      "Epoch: 41, Train loss: 4.1411, Val loss: 3.8121\n",
      "Patience counter: 1\n",
      "Epoch: 42, Train loss: 4.0793, Val loss: 3.8244\n",
      "Patience counter: 2\n",
      "Epoch: 43, Train loss: 4.1317, Val loss: 3.7695\n",
      "Patience counter: 3\n",
      "Epoch: 44, Train loss: 4.1408, Val loss: 3.8244\n",
      "Patience counter: 4\n",
      "Epoch: 45, Train loss: 4.0498, Val loss: 3.8005\n",
      "Patience counter: 5\n",
      "Epoch: 46, Train loss: 4.0613, Val loss: 3.7157\n",
      "Model has been saved!\n",
      "Epoch: 47, Train loss: 4.4063, Val loss: 3.9583\n",
      "Patience counter: 1\n",
      "Epoch: 48, Train loss: 4.0869, Val loss: 3.7306\n",
      "Patience counter: 2\n",
      "Epoch: 49, Train loss: 4.0418, Val loss: 3.8799\n",
      "Patience counter: 3\n",
      "Epoch: 50, Train loss: 4.0810, Val loss: 3.8578\n",
      "Patience counter: 4\n",
      "Epoch: 51, Train loss: 4.0927, Val loss: 3.7431\n",
      "Patience counter: 5\n",
      "Epoch: 52, Train loss: 4.0918, Val loss: 3.7569\n",
      "Patience counter: 6\n",
      "Epoch: 53, Train loss: 4.0982, Val loss: 3.7887\n",
      "Patience counter: 7\n",
      "Epoch: 54, Train loss: 4.1893, Val loss: 3.7581\n",
      "Patience counter: 8\n",
      "Epoch: 55, Train loss: 4.0444, Val loss: 3.8879\n",
      "Patience counter: 9\n",
      "Epoch: 56, Train loss: 4.1219, Val loss: 3.7154\n",
      "Model has been saved!\n",
      "Epoch: 57, Train loss: 3.9290, Val loss: 3.7492\n",
      "Patience counter: 1\n",
      "Epoch: 58, Train loss: 4.2108, Val loss: 3.9671\n",
      "Patience counter: 2\n",
      "Epoch: 59, Train loss: 4.0080, Val loss: 3.6838\n",
      "Model has been saved!\n",
      "Epoch: 60, Train loss: 4.2597, Val loss: 4.1785\n",
      "Patience counter: 1\n",
      "Epoch: 61, Train loss: 4.0103, Val loss: 3.7668\n",
      "Patience counter: 2\n",
      "Epoch: 62, Train loss: 4.0776, Val loss: 3.7733\n",
      "Patience counter: 3\n",
      "Epoch: 63, Train loss: 4.1746, Val loss: 3.8292\n",
      "Patience counter: 4\n",
      "Epoch: 64, Train loss: 3.9589, Val loss: 3.8581\n",
      "Patience counter: 5\n",
      "Epoch: 65, Train loss: 4.1189, Val loss: 3.7849\n",
      "Patience counter: 6\n",
      "Epoch: 66, Train loss: 4.0528, Val loss: 3.7109\n",
      "Patience counter: 7\n",
      "Epoch: 67, Train loss: 4.0662, Val loss: 3.7449\n",
      "Patience counter: 8\n",
      "Epoch: 68, Train loss: 3.9813, Val loss: 3.7585\n",
      "Patience counter: 9\n",
      "Epoch: 69, Train loss: 3.9595, Val loss: 3.7490\n",
      "Patience counter: 10\n",
      "Epoch: 70, Train loss: 3.9635, Val loss: 3.8563\n",
      "Patience counter: 11\n",
      "Epoch: 71, Train loss: 4.0923, Val loss: 3.7381\n",
      "Patience counter: 12\n",
      "Epoch: 72, Train loss: 3.9559, Val loss: 3.6451\n",
      "Model has been saved!\n",
      "Epoch: 73, Train loss: 3.9043, Val loss: 3.7173\n",
      "Patience counter: 1\n",
      "Epoch: 74, Train loss: 4.0884, Val loss: 3.6773\n",
      "Patience counter: 2\n",
      "Epoch: 75, Train loss: 3.8647, Val loss: 3.7521\n",
      "Patience counter: 3\n",
      "Epoch: 76, Train loss: 4.0018, Val loss: 3.9213\n",
      "Patience counter: 4\n",
      "Epoch: 77, Train loss: 4.0776, Val loss: 3.6660\n",
      "Patience counter: 5\n",
      "Epoch: 78, Train loss: 4.1791, Val loss: 3.6490\n",
      "Patience counter: 6\n",
      "Epoch: 79, Train loss: 3.9864, Val loss: 3.6683\n",
      "Patience counter: 7\n",
      "Epoch: 80, Train loss: 3.9730, Val loss: 3.7629\n",
      "Patience counter: 8\n",
      "Epoch: 81, Train loss: 3.9403, Val loss: 3.6655\n",
      "Patience counter: 9\n",
      "Epoch: 82, Train loss: 3.9493, Val loss: 3.7713\n",
      "Patience counter: 10\n",
      "Epoch: 83, Train loss: 3.8886, Val loss: 3.7368\n",
      "Patience counter: 11\n",
      "Epoch: 84, Train loss: 3.9789, Val loss: 3.7397\n",
      "Patience counter: 12\n",
      "Epoch: 85, Train loss: 4.0276, Val loss: 3.7843\n",
      "Patience counter: 13\n",
      "Epoch: 86, Train loss: 4.1224, Val loss: 3.7499\n",
      "Patience counter: 14\n",
      "Epoch: 87, Train loss: 4.2682, Val loss: 3.6523\n",
      "Patience counter: 15\n",
      "Epoch: 88, Train loss: 4.2798, Val loss: 3.6806\n",
      "Patience counter: 16\n",
      "Epoch: 89, Train loss: 4.3302, Val loss: 3.9204\n",
      "Patience counter: 17\n",
      "Epoch: 90, Train loss: 4.1103, Val loss: 3.6143\n",
      "Model has been saved!\n",
      "Epoch: 91, Train loss: 3.9340, Val loss: 3.7779\n",
      "Patience counter: 1\n",
      "Epoch: 92, Train loss: 4.0401, Val loss: 3.6374\n",
      "Patience counter: 2\n",
      "Epoch: 93, Train loss: 4.0421, Val loss: 3.6918\n",
      "Patience counter: 3\n",
      "Epoch: 94, Train loss: 4.1141, Val loss: 3.7995\n",
      "Patience counter: 4\n",
      "Epoch: 95, Train loss: 3.9958, Val loss: 3.6071\n",
      "Model has been saved!\n",
      "Epoch: 96, Train loss: 4.0108, Val loss: 3.7248\n",
      "Patience counter: 1\n",
      "Epoch: 97, Train loss: 3.9843, Val loss: 3.5964\n",
      "Model has been saved!\n",
      "Epoch: 98, Train loss: 3.9776, Val loss: 3.7197\n",
      "Patience counter: 1\n",
      "Epoch: 99, Train loss: 3.8403, Val loss: 3.7604\n",
      "Patience counter: 2\n",
      "Epoch: 100, Train loss: 4.1662, Val loss: 3.5463\n",
      "Model has been saved!\n",
      "Epoch: 101, Train loss: 4.0300, Val loss: 3.7590\n",
      "Patience counter: 1\n",
      "Epoch: 102, Train loss: 3.8484, Val loss: 3.7289\n",
      "Patience counter: 2\n",
      "Epoch: 103, Train loss: 3.9335, Val loss: 3.7862\n",
      "Patience counter: 3\n",
      "Epoch: 104, Train loss: 3.9287, Val loss: 3.7531\n",
      "Patience counter: 4\n",
      "Epoch: 105, Train loss: 3.9601, Val loss: 3.7736\n",
      "Patience counter: 5\n",
      "Epoch: 106, Train loss: 3.9909, Val loss: 3.6948\n",
      "Patience counter: 6\n",
      "Epoch: 107, Train loss: 4.1232, Val loss: 3.6000\n",
      "Patience counter: 7\n",
      "Epoch: 108, Train loss: 4.0427, Val loss: 3.6355\n",
      "Patience counter: 8\n",
      "Epoch: 109, Train loss: 3.7686, Val loss: 3.6188\n",
      "Patience counter: 9\n",
      "Epoch: 110, Train loss: 3.8482, Val loss: 3.6939\n",
      "Patience counter: 10\n",
      "Epoch: 111, Train loss: 3.8008, Val loss: 3.6054\n",
      "Patience counter: 11\n",
      "Epoch: 112, Train loss: 3.9834, Val loss: 3.8062\n",
      "Patience counter: 12\n",
      "Epoch: 113, Train loss: 4.1595, Val loss: 4.0097\n",
      "Patience counter: 13\n",
      "Epoch: 114, Train loss: 4.0151, Val loss: 3.6026\n",
      "Patience counter: 14\n",
      "Epoch: 115, Train loss: 3.9927, Val loss: 3.6854\n",
      "Patience counter: 15\n",
      "Epoch: 116, Train loss: 4.0327, Val loss: 3.9321\n",
      "Patience counter: 16\n",
      "Epoch: 117, Train loss: 3.8480, Val loss: 3.5938\n",
      "Patience counter: 17\n",
      "Epoch: 118, Train loss: 3.8876, Val loss: 3.6375\n",
      "Patience counter: 18\n",
      "Epoch: 119, Train loss: 3.9285, Val loss: 3.5746\n",
      "Patience counter: 19\n",
      "Epoch: 120, Train loss: 3.7797, Val loss: 3.8222\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-05\n",
      "Epoch: 121, Train loss: 3.8099, Val loss: 3.6419\n",
      "Patience counter: 1\n",
      "Epoch: 122, Train loss: 3.7359, Val loss: 3.5990\n",
      "Patience counter: 2\n",
      "Epoch: 123, Train loss: 3.8154, Val loss: 3.6001\n",
      "Patience counter: 3\n",
      "Epoch: 124, Train loss: 3.6245, Val loss: 3.6023\n",
      "Patience counter: 4\n",
      "Epoch: 125, Train loss: 3.7233, Val loss: 3.6002\n",
      "Patience counter: 5\n",
      "Epoch: 126, Train loss: 3.8016, Val loss: 3.6011\n",
      "Patience counter: 6\n",
      "Epoch: 127, Train loss: 3.7703, Val loss: 3.5967\n",
      "Patience counter: 7\n",
      "Epoch: 128, Train loss: 3.5926, Val loss: 3.5826\n",
      "Patience counter: 8\n",
      "Epoch: 129, Train loss: 3.7924, Val loss: 3.5811\n",
      "Patience counter: 9\n",
      "Epoch: 130, Train loss: 3.7922, Val loss: 3.5817\n",
      "Patience counter: 10\n",
      "Epoch: 131, Train loss: 3.7599, Val loss: 3.5763\n",
      "Patience counter: 11\n",
      "Epoch: 132, Train loss: 3.6360, Val loss: 3.5749\n",
      "Patience counter: 12\n",
      "Epoch: 133, Train loss: 3.7183, Val loss: 3.5747\n",
      "Patience counter: 13\n",
      "Epoch: 134, Train loss: 3.6911, Val loss: 3.5912\n",
      "Patience counter: 14\n",
      "Epoch: 135, Train loss: 3.6244, Val loss: 3.5837\n",
      "Patience counter: 15\n",
      "Epoch: 136, Train loss: 3.7532, Val loss: 3.5718\n",
      "Patience counter: 16\n",
      "Epoch: 137, Train loss: 3.7644, Val loss: 3.5873\n",
      "Patience counter: 17\n",
      "Epoch: 138, Train loss: 3.7456, Val loss: 3.5786\n",
      "Patience counter: 18\n",
      "Epoch: 139, Train loss: 3.6805, Val loss: 3.5914\n",
      "Patience counter: 19\n",
      "Epoch: 140, Train loss: 3.7243, Val loss: 3.5914\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-06\n",
      "Epoch: 141, Train loss: 3.7702, Val loss: 3.5875\n",
      "Patience counter: 1\n",
      "Epoch: 142, Train loss: 3.7471, Val loss: 3.5894\n",
      "Patience counter: 2\n",
      "Epoch: 143, Train loss: 3.7785, Val loss: 3.5861\n",
      "Patience counter: 3\n",
      "Epoch: 144, Train loss: 3.6996, Val loss: 3.5849\n",
      "Patience counter: 4\n",
      "Epoch: 145, Train loss: 3.7147, Val loss: 3.5822\n",
      "Patience counter: 5\n",
      "Epoch: 146, Train loss: 3.6880, Val loss: 3.5842\n",
      "Patience counter: 6\n",
      "Epoch: 147, Train loss: 3.7489, Val loss: 3.5838\n",
      "Patience counter: 7\n",
      "Epoch: 148, Train loss: 3.7151, Val loss: 3.5830\n",
      "Patience counter: 8\n",
      "Epoch: 149, Train loss: 3.7700, Val loss: 3.5825\n",
      "Patience counter: 9\n",
      "Epoch: 150, Train loss: 3.8352, Val loss: 3.5819\n",
      "Patience counter: 10\n",
      "Epoch: 151, Train loss: 3.6332, Val loss: 3.5830\n",
      "Patience counter: 11\n",
      "Epoch: 152, Train loss: 3.7637, Val loss: 3.5810\n",
      "Patience counter: 12\n",
      "Epoch: 153, Train loss: 3.8273, Val loss: 3.5796\n",
      "Patience counter: 13\n",
      "Epoch: 154, Train loss: 3.7297, Val loss: 3.5795\n",
      "Patience counter: 14\n",
      "Epoch: 155, Train loss: 3.8278, Val loss: 3.5792\n",
      "Patience counter: 15\n",
      "Epoch: 156, Train loss: 3.6966, Val loss: 3.5809\n",
      "Patience counter: 16\n",
      "Epoch: 157, Train loss: 3.5731, Val loss: 3.5799\n",
      "Patience counter: 17\n",
      "Epoch: 158, Train loss: 3.7238, Val loss: 3.5800\n",
      "Patience counter: 18\n",
      "Epoch: 159, Train loss: 3.7823, Val loss: 3.5794\n",
      "Patience counter: 19\n",
      "Epoch: 160, Train loss: 3.6971, Val loss: 3.5800\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-07\n",
      "Epoch: 161, Train loss: 3.7361, Val loss: 3.5797\n",
      "Patience counter: 1\n",
      "Epoch: 162, Train loss: 3.7001, Val loss: 3.5797\n",
      "Patience counter: 2\n",
      "Epoch: 163, Train loss: 3.8105, Val loss: 3.5798\n",
      "Patience counter: 3\n",
      "Epoch: 164, Train loss: 3.7426, Val loss: 3.5798\n",
      "Patience counter: 4\n",
      "Epoch: 165, Train loss: 3.7678, Val loss: 3.5797\n",
      "Patience counter: 5\n",
      "Epoch: 166, Train loss: 3.6429, Val loss: 3.5796\n",
      "Patience counter: 6\n",
      "Epoch: 167, Train loss: 3.6028, Val loss: 3.5798\n",
      "Patience counter: 7\n",
      "Epoch: 168, Train loss: 3.6965, Val loss: 3.5796\n",
      "Patience counter: 8\n",
      "Epoch: 169, Train loss: 3.6425, Val loss: 3.5796\n",
      "Patience counter: 9\n",
      "Epoch: 170, Train loss: 3.7394, Val loss: 3.5798\n",
      "Patience counter: 10\n",
      "Epoch: 171, Train loss: 3.7025, Val loss: 3.5798\n",
      "Patience counter: 11\n",
      "Epoch: 172, Train loss: 3.6358, Val loss: 3.5799\n",
      "Patience counter: 12\n",
      "Epoch: 173, Train loss: 3.6643, Val loss: 3.5798\n",
      "Patience counter: 13\n",
      "Epoch: 174, Train loss: 3.7038, Val loss: 3.5798\n",
      "Patience counter: 14\n",
      "Epoch: 175, Train loss: 3.7675, Val loss: 3.5799\n",
      "Patience counter: 15\n",
      "Epoch: 176, Train loss: 3.7859, Val loss: 3.5797\n",
      "Patience counter: 16\n",
      "Epoch: 177, Train loss: 3.6594, Val loss: 3.5795\n",
      "Patience counter: 17\n",
      "Epoch: 178, Train loss: 3.7382, Val loss: 3.5794\n",
      "Patience counter: 18\n",
      "Epoch: 179, Train loss: 3.8190, Val loss: 3.5794\n",
      "Patience counter: 19\n",
      "Epoch: 180, Train loss: 3.6839, Val loss: 3.5794\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-08\n",
      "Epoch: 181, Train loss: 3.7019, Val loss: 3.5793\n",
      "Patience counter: 1\n",
      "Epoch: 182, Train loss: 3.6797, Val loss: 3.5794\n",
      "Patience counter: 2\n",
      "Epoch: 183, Train loss: 3.6753, Val loss: 3.5793\n",
      "Patience counter: 3\n",
      "Epoch: 184, Train loss: 3.7098, Val loss: 3.5794\n",
      "Patience counter: 4\n",
      "Epoch: 185, Train loss: 3.7000, Val loss: 3.5794\n",
      "Patience counter: 5\n",
      "Epoch: 186, Train loss: 3.7699, Val loss: 3.5794\n",
      "Patience counter: 6\n",
      "Epoch: 187, Train loss: 3.7380, Val loss: 3.5793\n",
      "Patience counter: 7\n",
      "Epoch: 188, Train loss: 3.6982, Val loss: 3.5793\n",
      "Patience counter: 8\n",
      "Epoch: 189, Train loss: 3.7360, Val loss: 3.5794\n",
      "Patience counter: 9\n",
      "Epoch: 190, Train loss: 3.7351, Val loss: 3.5794\n",
      "Patience counter: 10\n",
      "Epoch: 191, Train loss: 3.7839, Val loss: 3.5794\n",
      "Patience counter: 11\n",
      "Epoch: 192, Train loss: 3.7211, Val loss: 3.5793\n",
      "Patience counter: 12\n",
      "Epoch: 193, Train loss: 3.7501, Val loss: 3.5793\n",
      "Patience counter: 13\n",
      "Epoch: 194, Train loss: 3.6503, Val loss: 3.5793\n",
      "Patience counter: 14\n",
      "Epoch: 195, Train loss: 3.6940, Val loss: 3.5793\n",
      "Patience counter: 15\n",
      "Epoch: 196, Train loss: 3.8046, Val loss: 3.5793\n",
      "Patience counter: 16\n",
      "Epoch: 197, Train loss: 3.7317, Val loss: 3.5793\n",
      "Patience counter: 17\n",
      "Epoch: 198, Train loss: 3.6258, Val loss: 3.5793\n",
      "Patience counter: 18\n",
      "Epoch: 199, Train loss: 3.7307, Val loss: 3.5793\n",
      "Patience counter: 19\n",
      "Test Loss: 4.3671, MSE: 4.2196, MAE: 1.3731, R2: 0.3765\n"
     ]
    }
   ],
   "source": [
    "# 训练模型，设置epoch数为100\n",
    "epochs = 200\n",
    "\n",
    "# 熔点GAT模型\n",
    "Tm_train_losses_gat, Tm_val_losses_gat, Tm_test_pred_gat, Tm_test_true_gat, Tm_test_mse_gat, Tm_test_mae_gat, Tm_test_r2_gat = train_epochs(\n",
    "    0, epochs, model_Tm_GAT, Tm_train_loader, Tm_val_loader, Tm_test_loader, \"Tm_GAT_model.pt\"\n",
    ")\n",
    "\n",
    "# 电导率GAT模型\n",
    "conductivity_train_losses_gat, conductivity_val_losses_gat, conductivity_test_pred_gat, conductivity_test_true_gat, conductivity_test_mse_gat, conductivity_test_mae_gat, conductivity_test_r2_gat = train_epochs(\n",
    "    0, epochs, model_conductivity_GAT, conductivity_train_loader, conductivity_val_loader, conductivity_test_loader, \"conductivity_GAT_model.pt\", scale=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e3c6cc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 2.7326, Val loss: 2.7854\n",
      "Model has been saved!\n",
      "Epoch: 1, Train loss: 2.6732, Val loss: 2.9394\n",
      "Patience counter: 1\n",
      "Epoch: 2, Train loss: 2.0669, Val loss: 3.6037\n",
      "Patience counter: 2\n",
      "Epoch: 3, Train loss: 1.8777, Val loss: 2.5932\n",
      "Model has been saved!\n",
      "Epoch: 4, Train loss: 2.0786, Val loss: 2.7414\n",
      "Patience counter: 1\n",
      "Epoch: 5, Train loss: 1.9872, Val loss: 3.0885\n",
      "Patience counter: 2\n",
      "Epoch: 6, Train loss: 1.8031, Val loss: 2.7540\n",
      "Patience counter: 3\n",
      "Epoch: 7, Train loss: 1.8491, Val loss: 2.6854\n",
      "Patience counter: 4\n",
      "Epoch: 8, Train loss: 2.0075, Val loss: 2.7890\n",
      "Patience counter: 5\n",
      "Epoch: 9, Train loss: 1.8161, Val loss: 2.9009\n",
      "Patience counter: 6\n",
      "Epoch: 10, Train loss: 1.7761, Val loss: 2.7897\n",
      "Patience counter: 7\n",
      "Epoch: 11, Train loss: 1.9610, Val loss: 2.8464\n",
      "Patience counter: 8\n",
      "Epoch: 12, Train loss: 1.7389, Val loss: 2.6493\n",
      "Patience counter: 9\n",
      "Epoch: 13, Train loss: 1.9751, Val loss: 2.8676\n",
      "Patience counter: 10\n",
      "Epoch: 14, Train loss: 1.8205, Val loss: 2.8600\n",
      "Patience counter: 11\n",
      "Epoch: 15, Train loss: 1.8647, Val loss: 2.7203\n",
      "Patience counter: 12\n",
      "Epoch: 16, Train loss: 1.7432, Val loss: 2.7563\n",
      "Patience counter: 13\n",
      "Epoch: 17, Train loss: 1.7673, Val loss: 3.0714\n",
      "Patience counter: 14\n",
      "Epoch: 18, Train loss: 1.7800, Val loss: 2.6773\n",
      "Patience counter: 15\n",
      "Epoch: 19, Train loss: 1.7744, Val loss: 3.0281\n",
      "Patience counter: 16\n",
      "Epoch: 20, Train loss: 1.7605, Val loss: 3.1366\n",
      "Patience counter: 17\n",
      "Epoch: 21, Train loss: 1.7775, Val loss: 2.6785\n",
      "Patience counter: 18\n",
      "Epoch: 22, Train loss: 1.7453, Val loss: 2.9522\n",
      "Patience counter: 19\n",
      "Epoch: 23, Train loss: 1.7696, Val loss: 2.9835\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-05\n",
      "Epoch: 24, Train loss: 1.8737, Val loss: 2.9774\n",
      "Patience counter: 1\n",
      "Epoch: 25, Train loss: 1.5735, Val loss: 2.9382\n",
      "Patience counter: 2\n",
      "Epoch: 26, Train loss: 1.8443, Val loss: 2.8790\n",
      "Patience counter: 3\n",
      "Epoch: 27, Train loss: 1.6345, Val loss: 2.8757\n",
      "Patience counter: 4\n",
      "Epoch: 28, Train loss: 1.6365, Val loss: 2.8968\n",
      "Patience counter: 5\n",
      "Epoch: 29, Train loss: 1.6388, Val loss: 2.9381\n",
      "Patience counter: 6\n",
      "Epoch: 30, Train loss: 1.5615, Val loss: 2.9682\n",
      "Patience counter: 7\n",
      "Epoch: 31, Train loss: 1.8148, Val loss: 3.0034\n",
      "Patience counter: 8\n",
      "Epoch: 32, Train loss: 1.7222, Val loss: 3.0410\n",
      "Patience counter: 9\n",
      "Epoch: 33, Train loss: 1.7771, Val loss: 3.0423\n",
      "Patience counter: 10\n",
      "Epoch: 34, Train loss: 1.5861, Val loss: 2.9794\n",
      "Patience counter: 11\n",
      "Epoch: 35, Train loss: 1.6412, Val loss: 2.9510\n",
      "Patience counter: 12\n",
      "Epoch: 36, Train loss: 1.6803, Val loss: 2.9404\n",
      "Patience counter: 13\n",
      "Epoch: 37, Train loss: 1.9968, Val loss: 2.9636\n",
      "Patience counter: 14\n",
      "Epoch: 38, Train loss: 1.7326, Val loss: 2.9518\n",
      "Patience counter: 15\n",
      "Epoch: 39, Train loss: 1.4981, Val loss: 2.9544\n",
      "Patience counter: 16\n",
      "Epoch: 40, Train loss: 1.6269, Val loss: 2.9444\n",
      "Patience counter: 17\n",
      "Epoch: 41, Train loss: 1.5885, Val loss: 2.9422\n",
      "Patience counter: 18\n",
      "Epoch: 42, Train loss: 1.5999, Val loss: 2.9741\n",
      "Patience counter: 19\n",
      "Epoch: 43, Train loss: 1.6909, Val loss: 2.9872\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-06\n",
      "Epoch: 44, Train loss: 1.6488, Val loss: 2.9892\n",
      "Patience counter: 1\n",
      "Epoch: 45, Train loss: 1.8359, Val loss: 2.9905\n",
      "Patience counter: 2\n",
      "Epoch: 46, Train loss: 1.8159, Val loss: 2.9920\n",
      "Patience counter: 3\n",
      "Epoch: 47, Train loss: 1.6333, Val loss: 2.9920\n",
      "Patience counter: 4\n",
      "Epoch: 48, Train loss: 1.6631, Val loss: 2.9897\n",
      "Patience counter: 5\n",
      "Epoch: 49, Train loss: 1.5859, Val loss: 2.9852\n",
      "Patience counter: 6\n",
      "Epoch: 50, Train loss: 1.6728, Val loss: 2.9828\n",
      "Patience counter: 7\n",
      "Epoch: 51, Train loss: 1.5811, Val loss: 2.9816\n",
      "Patience counter: 8\n",
      "Epoch: 52, Train loss: 1.4656, Val loss: 2.9771\n",
      "Patience counter: 9\n",
      "Epoch: 53, Train loss: 1.7181, Val loss: 2.9754\n",
      "Patience counter: 10\n",
      "Epoch: 54, Train loss: 1.6599, Val loss: 2.9749\n",
      "Patience counter: 11\n",
      "Epoch: 55, Train loss: 1.7305, Val loss: 2.9712\n",
      "Patience counter: 12\n",
      "Epoch: 56, Train loss: 1.5225, Val loss: 2.9728\n",
      "Patience counter: 13\n",
      "Epoch: 57, Train loss: 1.6286, Val loss: 2.9722\n",
      "Patience counter: 14\n",
      "Epoch: 58, Train loss: 1.6512, Val loss: 2.9680\n",
      "Patience counter: 15\n",
      "Epoch: 59, Train loss: 1.6878, Val loss: 2.9710\n",
      "Patience counter: 16\n",
      "Epoch: 60, Train loss: 1.6605, Val loss: 2.9647\n",
      "Patience counter: 17\n",
      "Epoch: 61, Train loss: 1.5154, Val loss: 2.9598\n",
      "Patience counter: 18\n",
      "Epoch: 62, Train loss: 1.5802, Val loss: 2.9571\n",
      "Patience counter: 19\n",
      "Epoch: 63, Train loss: 1.7712, Val loss: 2.9591\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-07\n",
      "Epoch: 64, Train loss: 1.5525, Val loss: 2.9593\n",
      "Patience counter: 1\n",
      "Epoch: 65, Train loss: 1.6097, Val loss: 2.9596\n",
      "Patience counter: 2\n",
      "Epoch: 66, Train loss: 1.6427, Val loss: 2.9599\n",
      "Patience counter: 3\n",
      "Epoch: 67, Train loss: 1.5653, Val loss: 2.9610\n",
      "Patience counter: 4\n",
      "Epoch: 68, Train loss: 1.5774, Val loss: 2.9619\n",
      "Patience counter: 5\n",
      "Epoch: 69, Train loss: 1.7420, Val loss: 2.9623\n",
      "Patience counter: 6\n",
      "Epoch: 70, Train loss: 1.5145, Val loss: 2.9632\n",
      "Patience counter: 7\n",
      "Epoch: 71, Train loss: 1.4522, Val loss: 2.9636\n",
      "Patience counter: 8\n",
      "Epoch: 72, Train loss: 1.5557, Val loss: 2.9643\n",
      "Patience counter: 9\n",
      "Epoch: 73, Train loss: 1.5075, Val loss: 2.9648\n",
      "Patience counter: 10\n",
      "Epoch: 74, Train loss: 1.7638, Val loss: 2.9653\n",
      "Patience counter: 11\n",
      "Epoch: 75, Train loss: 1.5856, Val loss: 2.9654\n",
      "Patience counter: 12\n",
      "Epoch: 76, Train loss: 1.5204, Val loss: 2.9655\n",
      "Patience counter: 13\n",
      "Epoch: 77, Train loss: 1.6502, Val loss: 2.9657\n",
      "Patience counter: 14\n",
      "Epoch: 78, Train loss: 1.7497, Val loss: 2.9663\n",
      "Patience counter: 15\n",
      "Epoch: 79, Train loss: 1.8474, Val loss: 2.9662\n",
      "Patience counter: 16\n",
      "Epoch: 80, Train loss: 1.6537, Val loss: 2.9661\n",
      "Patience counter: 17\n",
      "Epoch: 81, Train loss: 1.6644, Val loss: 2.9665\n",
      "Patience counter: 18\n",
      "Epoch: 82, Train loss: 1.7203, Val loss: 2.9669\n",
      "Patience counter: 19\n",
      "Epoch: 83, Train loss: 1.4828, Val loss: 2.9673\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-08\n",
      "Epoch: 84, Train loss: 1.6528, Val loss: 2.9674\n",
      "Patience counter: 1\n",
      "Epoch: 85, Train loss: 1.6132, Val loss: 2.9674\n",
      "Patience counter: 2\n",
      "Epoch: 86, Train loss: 1.6399, Val loss: 2.9674\n",
      "Patience counter: 3\n",
      "Epoch: 87, Train loss: 1.5846, Val loss: 2.9675\n",
      "Patience counter: 4\n",
      "Epoch: 88, Train loss: 1.5907, Val loss: 2.9675\n",
      "Patience counter: 5\n",
      "Epoch: 89, Train loss: 1.6414, Val loss: 2.9676\n",
      "Patience counter: 6\n",
      "Epoch: 90, Train loss: 1.6513, Val loss: 2.9676\n",
      "Patience counter: 7\n",
      "Epoch: 91, Train loss: 1.8098, Val loss: 2.9676\n",
      "Patience counter: 8\n",
      "Epoch: 92, Train loss: 1.6488, Val loss: 2.9676\n",
      "Patience counter: 9\n",
      "Epoch: 93, Train loss: 1.6392, Val loss: 2.9676\n",
      "Patience counter: 10\n",
      "Epoch: 94, Train loss: 1.5793, Val loss: 2.9677\n",
      "Patience counter: 11\n",
      "Epoch: 95, Train loss: 1.6479, Val loss: 2.9677\n",
      "Patience counter: 12\n",
      "Epoch: 96, Train loss: 1.5799, Val loss: 2.9677\n",
      "Patience counter: 13\n",
      "Epoch: 97, Train loss: 1.5025, Val loss: 2.9678\n",
      "Patience counter: 14\n",
      "Epoch: 98, Train loss: 1.5018, Val loss: 2.9678\n",
      "Patience counter: 15\n",
      "Epoch: 99, Train loss: 1.7173, Val loss: 2.9678\n",
      "Patience counter: 16\n",
      "Epoch: 100, Train loss: 1.6592, Val loss: 2.9679\n",
      "Patience counter: 17\n",
      "Epoch: 101, Train loss: 1.6146, Val loss: 2.9678\n",
      "Patience counter: 18\n",
      "Epoch: 102, Train loss: 1.4613, Val loss: 2.9679\n",
      "Patience counter: 19\n",
      "Epoch: 103, Train loss: 1.5615, Val loss: 2.9678\n",
      "Patience counter: 20\n",
      "Early stopping triggered. Learning rate has reached its minimum threshold (5.000000000000001e-08).\n",
      "Test Loss: 1.4613, MSE: 1.4613, MAE: 1.0214, R2: -0.4672\n",
      "Epoch: 0, Train loss: 1.1902, Val loss: 1.1989\n",
      "Model has been saved!\n",
      "Epoch: 1, Train loss: 0.9525, Val loss: 1.1215\n",
      "Model has been saved!\n",
      "Epoch: 2, Train loss: 0.9200, Val loss: 1.1846\n",
      "Patience counter: 1\n",
      "Epoch: 3, Train loss: 0.8532, Val loss: 1.1374\n",
      "Patience counter: 2\n",
      "Epoch: 4, Train loss: 0.8985, Val loss: 1.3888\n",
      "Patience counter: 3\n",
      "Epoch: 5, Train loss: 0.9424, Val loss: 1.1583\n",
      "Patience counter: 4\n",
      "Epoch: 6, Train loss: 0.8603, Val loss: 1.1600\n",
      "Patience counter: 5\n",
      "Epoch: 7, Train loss: 0.8424, Val loss: 1.1095\n",
      "Model has been saved!\n",
      "Epoch: 8, Train loss: 0.8822, Val loss: 1.1334\n",
      "Patience counter: 1\n",
      "Epoch: 9, Train loss: 0.8346, Val loss: 1.1042\n",
      "Model has been saved!\n",
      "Epoch: 10, Train loss: 0.8456, Val loss: 1.1653\n",
      "Patience counter: 1\n",
      "Epoch: 11, Train loss: 0.7902, Val loss: 1.0892\n",
      "Model has been saved!\n",
      "Epoch: 12, Train loss: 0.8040, Val loss: 1.0824\n",
      "Model has been saved!\n",
      "Epoch: 13, Train loss: 0.8176, Val loss: 1.0910\n",
      "Patience counter: 1\n",
      "Epoch: 14, Train loss: 0.8526, Val loss: 1.0711\n",
      "Model has been saved!\n",
      "Epoch: 15, Train loss: 0.8059, Val loss: 1.0485\n",
      "Model has been saved!\n",
      "Epoch: 16, Train loss: 0.7769, Val loss: 1.0447\n",
      "Model has been saved!\n",
      "Epoch: 17, Train loss: 0.7926, Val loss: 1.0353\n",
      "Model has been saved!\n",
      "Epoch: 18, Train loss: 0.7729, Val loss: 1.0897\n",
      "Patience counter: 1\n",
      "Epoch: 19, Train loss: 0.7817, Val loss: 1.0713\n",
      "Patience counter: 2\n",
      "Epoch: 20, Train loss: 0.7828, Val loss: 1.0655\n",
      "Patience counter: 3\n",
      "Epoch: 21, Train loss: 0.7747, Val loss: 1.0185\n",
      "Model has been saved!\n",
      "Epoch: 22, Train loss: 0.7386, Val loss: 1.0540\n",
      "Patience counter: 1\n",
      "Epoch: 23, Train loss: 0.7265, Val loss: 1.0138\n",
      "Model has been saved!\n",
      "Epoch: 24, Train loss: 0.7404, Val loss: 1.0319\n",
      "Patience counter: 1\n",
      "Epoch: 25, Train loss: 0.7634, Val loss: 1.0113\n",
      "Model has been saved!\n",
      "Epoch: 26, Train loss: 0.7915, Val loss: 1.0118\n",
      "Patience counter: 1\n",
      "Epoch: 27, Train loss: 0.7427, Val loss: 1.0164\n",
      "Patience counter: 2\n",
      "Epoch: 28, Train loss: 0.7545, Val loss: 1.0164\n",
      "Patience counter: 3\n",
      "Epoch: 29, Train loss: 0.7560, Val loss: 1.0303\n",
      "Patience counter: 4\n",
      "Epoch: 30, Train loss: 0.7391, Val loss: 1.0200\n",
      "Patience counter: 5\n",
      "Epoch: 31, Train loss: 0.7514, Val loss: 1.0145\n",
      "Patience counter: 6\n",
      "Epoch: 32, Train loss: 0.7440, Val loss: 1.0165\n",
      "Patience counter: 7\n",
      "Epoch: 33, Train loss: 0.7281, Val loss: 1.0136\n",
      "Patience counter: 8\n",
      "Epoch: 34, Train loss: 0.7256, Val loss: 1.0096\n",
      "Model has been saved!\n",
      "Epoch: 35, Train loss: 0.7389, Val loss: 1.0195\n",
      "Patience counter: 1\n",
      "Epoch: 36, Train loss: 0.7587, Val loss: 1.0107\n",
      "Patience counter: 2\n",
      "Epoch: 37, Train loss: 0.7538, Val loss: 1.0145\n",
      "Patience counter: 3\n",
      "Epoch: 38, Train loss: 0.7331, Val loss: 1.0185\n",
      "Patience counter: 4\n",
      "Epoch: 39, Train loss: 0.7230, Val loss: 1.0209\n",
      "Patience counter: 5\n",
      "Epoch: 40, Train loss: 0.7055, Val loss: 1.0260\n",
      "Patience counter: 6\n",
      "Epoch: 41, Train loss: 0.7422, Val loss: 1.0747\n",
      "Patience counter: 7\n",
      "Epoch: 42, Train loss: 0.7683, Val loss: 1.0398\n",
      "Patience counter: 8\n",
      "Epoch: 43, Train loss: 0.7248, Val loss: 1.0147\n",
      "Patience counter: 9\n",
      "Epoch: 44, Train loss: 0.7182, Val loss: 1.0266\n",
      "Patience counter: 10\n",
      "Epoch: 45, Train loss: 0.7170, Val loss: 1.0149\n",
      "Patience counter: 11\n",
      "Epoch: 46, Train loss: 0.7281, Val loss: 1.0082\n",
      "Model has been saved!\n",
      "Epoch: 47, Train loss: 0.7507, Val loss: 1.0197\n",
      "Patience counter: 1\n",
      "Epoch: 48, Train loss: 0.7351, Val loss: 1.0103\n",
      "Patience counter: 2\n",
      "Epoch: 49, Train loss: 0.7263, Val loss: 1.0049\n",
      "Model has been saved!\n",
      "Epoch: 50, Train loss: 0.6998, Val loss: 1.0089\n",
      "Patience counter: 1\n",
      "Epoch: 51, Train loss: 0.7661, Val loss: 1.0077\n",
      "Patience counter: 2\n",
      "Epoch: 52, Train loss: 0.7087, Val loss: 1.0114\n",
      "Patience counter: 3\n",
      "Epoch: 53, Train loss: 0.7153, Val loss: 1.0890\n",
      "Patience counter: 4\n",
      "Epoch: 54, Train loss: 0.7281, Val loss: 1.0266\n",
      "Patience counter: 5\n",
      "Epoch: 55, Train loss: 0.7147, Val loss: 1.0311\n",
      "Patience counter: 6\n",
      "Epoch: 56, Train loss: 0.6988, Val loss: 1.0170\n",
      "Patience counter: 7\n",
      "Epoch: 57, Train loss: 0.7363, Val loss: 1.0006\n",
      "Model has been saved!\n",
      "Epoch: 58, Train loss: 0.7361, Val loss: 1.0113\n",
      "Patience counter: 1\n",
      "Epoch: 59, Train loss: 0.7086, Val loss: 1.0294\n",
      "Patience counter: 2\n",
      "Epoch: 60, Train loss: 0.7314, Val loss: 1.0182\n",
      "Patience counter: 3\n",
      "Epoch: 61, Train loss: 0.7449, Val loss: 1.0204\n",
      "Patience counter: 4\n",
      "Epoch: 62, Train loss: 0.7640, Val loss: 1.0590\n",
      "Patience counter: 5\n",
      "Epoch: 63, Train loss: 0.7397, Val loss: 1.0095\n",
      "Patience counter: 6\n",
      "Epoch: 64, Train loss: 0.7144, Val loss: 1.0371\n",
      "Patience counter: 7\n",
      "Epoch: 65, Train loss: 0.7363, Val loss: 1.0361\n",
      "Patience counter: 8\n",
      "Epoch: 66, Train loss: 0.7043, Val loss: 1.0654\n",
      "Patience counter: 9\n",
      "Epoch: 67, Train loss: 0.7253, Val loss: 1.0150\n",
      "Patience counter: 10\n",
      "Epoch: 68, Train loss: 0.7095, Val loss: 1.0079\n",
      "Patience counter: 11\n",
      "Epoch: 69, Train loss: 0.7180, Val loss: 0.9996\n",
      "Model has been saved!\n",
      "Epoch: 70, Train loss: 0.7466, Val loss: 1.0172\n",
      "Patience counter: 1\n",
      "Epoch: 71, Train loss: 0.7318, Val loss: 1.0221\n",
      "Patience counter: 2\n",
      "Epoch: 72, Train loss: 0.7063, Val loss: 1.0150\n",
      "Patience counter: 3\n",
      "Epoch: 73, Train loss: 0.7097, Val loss: 1.0114\n",
      "Patience counter: 4\n",
      "Epoch: 74, Train loss: 0.7795, Val loss: 0.9966\n",
      "Model has been saved!\n",
      "Epoch: 75, Train loss: 0.7098, Val loss: 1.0047\n",
      "Patience counter: 1\n",
      "Epoch: 76, Train loss: 0.7144, Val loss: 1.0051\n",
      "Patience counter: 2\n",
      "Epoch: 77, Train loss: 0.7165, Val loss: 1.0056\n",
      "Patience counter: 3\n",
      "Epoch: 78, Train loss: 0.8164, Val loss: 1.0032\n",
      "Patience counter: 4\n",
      "Epoch: 79, Train loss: 0.7236, Val loss: 1.0035\n",
      "Patience counter: 5\n",
      "Epoch: 80, Train loss: 0.7354, Val loss: 1.0129\n",
      "Patience counter: 6\n",
      "Epoch: 81, Train loss: 0.7007, Val loss: 1.0031\n",
      "Patience counter: 7\n",
      "Epoch: 82, Train loss: 0.7258, Val loss: 0.9955\n",
      "Model has been saved!\n",
      "Epoch: 83, Train loss: 0.7147, Val loss: 1.0049\n",
      "Patience counter: 1\n",
      "Epoch: 84, Train loss: 0.6974, Val loss: 1.0048\n",
      "Patience counter: 2\n",
      "Epoch: 85, Train loss: 0.7031, Val loss: 1.0017\n",
      "Patience counter: 3\n",
      "Epoch: 86, Train loss: 0.7113, Val loss: 1.0004\n",
      "Patience counter: 4\n",
      "Epoch: 87, Train loss: 0.7088, Val loss: 0.9892\n",
      "Model has been saved!\n",
      "Epoch: 88, Train loss: 0.7116, Val loss: 0.9952\n",
      "Patience counter: 1\n",
      "Epoch: 89, Train loss: 0.7006, Val loss: 1.0328\n",
      "Patience counter: 2\n",
      "Epoch: 90, Train loss: 0.7496, Val loss: 1.0164\n",
      "Patience counter: 3\n",
      "Epoch: 91, Train loss: 0.7097, Val loss: 1.0090\n",
      "Patience counter: 4\n",
      "Epoch: 92, Train loss: 0.7071, Val loss: 1.0104\n",
      "Patience counter: 5\n",
      "Epoch: 93, Train loss: 0.6900, Val loss: 1.0017\n",
      "Patience counter: 6\n",
      "Epoch: 94, Train loss: 0.6949, Val loss: 1.0062\n",
      "Patience counter: 7\n",
      "Epoch: 95, Train loss: 0.6968, Val loss: 1.0003\n",
      "Patience counter: 8\n",
      "Epoch: 96, Train loss: 0.7037, Val loss: 0.9978\n",
      "Patience counter: 9\n",
      "Epoch: 97, Train loss: 0.7165, Val loss: 1.0452\n",
      "Patience counter: 10\n",
      "Epoch: 98, Train loss: 0.6854, Val loss: 1.0068\n",
      "Patience counter: 11\n",
      "Epoch: 99, Train loss: 0.6838, Val loss: 1.0103\n",
      "Patience counter: 12\n",
      "Epoch: 100, Train loss: 0.7038, Val loss: 1.0083\n",
      "Patience counter: 13\n",
      "Epoch: 101, Train loss: 0.7203, Val loss: 0.9911\n",
      "Patience counter: 14\n",
      "Epoch: 102, Train loss: 0.7171, Val loss: 1.0025\n",
      "Patience counter: 15\n",
      "Epoch: 103, Train loss: 0.6941, Val loss: 1.0490\n",
      "Patience counter: 16\n",
      "Epoch: 104, Train loss: 0.7290, Val loss: 1.0083\n",
      "Patience counter: 17\n",
      "Epoch: 105, Train loss: 0.7115, Val loss: 1.0098\n",
      "Patience counter: 18\n",
      "Epoch: 106, Train loss: 0.6951, Val loss: 1.0074\n",
      "Patience counter: 19\n",
      "Epoch: 107, Train loss: 0.7018, Val loss: 1.0095\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-05\n",
      "Epoch: 108, Train loss: 0.6820, Val loss: 0.9983\n",
      "Patience counter: 1\n",
      "Epoch: 109, Train loss: 0.6843, Val loss: 0.9951\n",
      "Patience counter: 2\n",
      "Epoch: 110, Train loss: 0.6679, Val loss: 0.9979\n",
      "Patience counter: 3\n",
      "Epoch: 111, Train loss: 0.6888, Val loss: 0.9954\n",
      "Patience counter: 4\n",
      "Epoch: 112, Train loss: 0.7361, Val loss: 0.9964\n",
      "Patience counter: 5\n",
      "Epoch: 113, Train loss: 0.6874, Val loss: 0.9954\n",
      "Patience counter: 6\n",
      "Epoch: 114, Train loss: 0.6930, Val loss: 0.9972\n",
      "Patience counter: 7\n",
      "Epoch: 115, Train loss: 0.6834, Val loss: 0.9975\n",
      "Patience counter: 8\n",
      "Epoch: 116, Train loss: 0.6921, Val loss: 1.0004\n",
      "Patience counter: 9\n",
      "Epoch: 117, Train loss: 0.6947, Val loss: 0.9952\n",
      "Patience counter: 10\n",
      "Epoch: 118, Train loss: 0.6861, Val loss: 0.9946\n",
      "Patience counter: 11\n",
      "Epoch: 119, Train loss: 0.6898, Val loss: 0.9979\n",
      "Patience counter: 12\n",
      "Epoch: 120, Train loss: 0.7228, Val loss: 0.9930\n",
      "Patience counter: 13\n",
      "Epoch: 121, Train loss: 0.6859, Val loss: 0.9973\n",
      "Patience counter: 14\n",
      "Epoch: 122, Train loss: 0.6857, Val loss: 0.9976\n",
      "Patience counter: 15\n",
      "Epoch: 123, Train loss: 0.6908, Val loss: 0.9965\n",
      "Patience counter: 16\n",
      "Epoch: 124, Train loss: 0.6764, Val loss: 0.9973\n",
      "Patience counter: 17\n",
      "Epoch: 125, Train loss: 0.6849, Val loss: 0.9990\n",
      "Patience counter: 18\n",
      "Epoch: 126, Train loss: 0.6936, Val loss: 0.9980\n",
      "Patience counter: 19\n",
      "Epoch: 127, Train loss: 0.7090, Val loss: 0.9963\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-06\n",
      "Epoch: 128, Train loss: 0.7008, Val loss: 0.9968\n",
      "Patience counter: 1\n",
      "Epoch: 129, Train loss: 0.7149, Val loss: 0.9963\n",
      "Patience counter: 2\n",
      "Epoch: 130, Train loss: 0.6806, Val loss: 0.9965\n",
      "Patience counter: 3\n",
      "Epoch: 131, Train loss: 0.6659, Val loss: 0.9968\n",
      "Patience counter: 4\n",
      "Epoch: 132, Train loss: 0.7412, Val loss: 0.9970\n",
      "Patience counter: 5\n",
      "Epoch: 133, Train loss: 0.7792, Val loss: 0.9971\n",
      "Patience counter: 6\n",
      "Epoch: 134, Train loss: 0.7132, Val loss: 0.9965\n",
      "Patience counter: 7\n",
      "Epoch: 135, Train loss: 0.6697, Val loss: 0.9963\n",
      "Patience counter: 8\n",
      "Epoch: 136, Train loss: 0.6658, Val loss: 0.9964\n",
      "Patience counter: 9\n",
      "Epoch: 137, Train loss: 0.6811, Val loss: 0.9962\n",
      "Patience counter: 10\n",
      "Epoch: 138, Train loss: 0.6922, Val loss: 0.9965\n",
      "Patience counter: 11\n",
      "Epoch: 139, Train loss: 0.6835, Val loss: 0.9962\n",
      "Patience counter: 12\n",
      "Epoch: 140, Train loss: 0.6715, Val loss: 0.9960\n",
      "Patience counter: 13\n",
      "Epoch: 141, Train loss: 0.7425, Val loss: 0.9960\n",
      "Patience counter: 14\n",
      "Epoch: 142, Train loss: 0.6954, Val loss: 0.9951\n",
      "Patience counter: 15\n",
      "Epoch: 143, Train loss: 0.7086, Val loss: 0.9954\n",
      "Patience counter: 16\n",
      "Epoch: 144, Train loss: 0.6895, Val loss: 0.9953\n",
      "Patience counter: 17\n",
      "Epoch: 145, Train loss: 0.7407, Val loss: 0.9953\n",
      "Patience counter: 18\n",
      "Epoch: 146, Train loss: 0.6824, Val loss: 0.9953\n",
      "Patience counter: 19\n",
      "Epoch: 147, Train loss: 0.6765, Val loss: 0.9955\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-07\n",
      "Epoch: 148, Train loss: 0.6833, Val loss: 0.9955\n",
      "Patience counter: 1\n",
      "Epoch: 149, Train loss: 0.6902, Val loss: 0.9954\n",
      "Patience counter: 2\n",
      "Epoch: 150, Train loss: 0.6723, Val loss: 0.9955\n",
      "Patience counter: 3\n",
      "Epoch: 151, Train loss: 0.6969, Val loss: 0.9955\n",
      "Patience counter: 4\n",
      "Epoch: 152, Train loss: 0.6956, Val loss: 0.9955\n",
      "Patience counter: 5\n",
      "Epoch: 153, Train loss: 0.6814, Val loss: 0.9955\n",
      "Patience counter: 6\n",
      "Epoch: 154, Train loss: 0.6793, Val loss: 0.9955\n",
      "Patience counter: 7\n",
      "Epoch: 155, Train loss: 0.6864, Val loss: 0.9955\n",
      "Patience counter: 8\n",
      "Epoch: 156, Train loss: 0.6901, Val loss: 0.9955\n",
      "Patience counter: 9\n",
      "Epoch: 157, Train loss: 0.6719, Val loss: 0.9955\n",
      "Patience counter: 10\n",
      "Epoch: 158, Train loss: 0.6778, Val loss: 0.9955\n",
      "Patience counter: 11\n",
      "Epoch: 159, Train loss: 0.6908, Val loss: 0.9955\n",
      "Patience counter: 12\n",
      "Epoch: 160, Train loss: 0.7103, Val loss: 0.9954\n",
      "Patience counter: 13\n",
      "Epoch: 161, Train loss: 0.6750, Val loss: 0.9954\n",
      "Patience counter: 14\n",
      "Epoch: 162, Train loss: 0.6799, Val loss: 0.9954\n",
      "Patience counter: 15\n",
      "Epoch: 163, Train loss: 0.6662, Val loss: 0.9955\n",
      "Patience counter: 16\n",
      "Epoch: 164, Train loss: 0.6849, Val loss: 0.9955\n",
      "Patience counter: 17\n",
      "Epoch: 165, Train loss: 0.6830, Val loss: 0.9955\n",
      "Patience counter: 18\n",
      "Epoch: 166, Train loss: 0.7185, Val loss: 0.9955\n",
      "Patience counter: 19\n",
      "Epoch: 167, Train loss: 0.6894, Val loss: 0.9955\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-08\n",
      "Epoch: 168, Train loss: 0.6649, Val loss: 0.9955\n",
      "Patience counter: 1\n",
      "Epoch: 169, Train loss: 0.6918, Val loss: 0.9955\n",
      "Patience counter: 2\n",
      "Epoch: 170, Train loss: 0.7147, Val loss: 0.9955\n",
      "Patience counter: 3\n",
      "Epoch: 171, Train loss: 0.6880, Val loss: 0.9955\n",
      "Patience counter: 4\n",
      "Epoch: 172, Train loss: 0.6956, Val loss: 0.9955\n",
      "Patience counter: 5\n",
      "Epoch: 173, Train loss: 0.6905, Val loss: 0.9955\n",
      "Patience counter: 6\n",
      "Epoch: 174, Train loss: 0.6830, Val loss: 0.9955\n",
      "Patience counter: 7\n",
      "Epoch: 175, Train loss: 0.6967, Val loss: 0.9955\n",
      "Patience counter: 8\n",
      "Epoch: 176, Train loss: 0.6826, Val loss: 0.9955\n",
      "Patience counter: 9\n",
      "Epoch: 177, Train loss: 0.6913, Val loss: 0.9955\n",
      "Patience counter: 10\n",
      "Epoch: 178, Train loss: 0.6872, Val loss: 0.9955\n",
      "Patience counter: 11\n",
      "Epoch: 179, Train loss: 0.6903, Val loss: 0.9955\n",
      "Patience counter: 12\n",
      "Epoch: 180, Train loss: 0.7033, Val loss: 0.9955\n",
      "Patience counter: 13\n",
      "Epoch: 181, Train loss: 0.6990, Val loss: 0.9955\n",
      "Patience counter: 14\n",
      "Epoch: 182, Train loss: 0.6937, Val loss: 0.9955\n",
      "Patience counter: 15\n",
      "Epoch: 183, Train loss: 0.6843, Val loss: 0.9955\n",
      "Patience counter: 16\n",
      "Epoch: 184, Train loss: 0.6845, Val loss: 0.9955\n",
      "Patience counter: 17\n",
      "Epoch: 185, Train loss: 0.6874, Val loss: 0.9955\n",
      "Patience counter: 18\n",
      "Epoch: 186, Train loss: 0.6805, Val loss: 0.9955\n",
      "Patience counter: 19\n",
      "Epoch: 187, Train loss: 0.7359, Val loss: 0.9955\n",
      "Patience counter: 20\n",
      "Early stopping triggered. Learning rate has reached its minimum threshold (5.000000000000001e-08).\n",
      "Test Loss: 0.6334, MSE: 0.6649, MAE: 0.6270, R2: 0.2423\n"
     ]
    }
   ],
   "source": [
    "# 训练模型，设置epoch数为100\n",
    "epochs = 200\n",
    "\n",
    "# 阴离子氧化势GAT模型\n",
    "anion_ox_train_losses_gat, anion_ox_val_losses_gat, anion_ox_test_pred_gat, anion_ox_test_true_gat, anion_ox_test_mse_gat, anion_ox_test_mae_gat, anion_ox_test_r2_gat = train_epochs(\n",
    "    0, epochs, model_anion_ox_GAT, anion_ox_train_loader, anion_ox_val_loader, anion_ox_test_loader, \"anion_ox_GAT_model.pt\"\n",
    ")\n",
    "\n",
    "# 阳离子还原势GAT模型\n",
    "cation_red_train_losses_gat, cation_red_val_losses_gat, cation_red_test_pred_gat, cation_red_test_true_gat, cation_red_test_mse_gat, cation_red_test_mae_gat, cation_red_test_r2_gat = train_epochs(\n",
    "    0, epochs, model_cation_red_GAT, cation_red_train_loader, cation_red_val_loader, cation_red_test_loader, \"cation_red_GAT_model.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50beced9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 3.7250, Val loss: 3.4247\n",
      "Model has been saved!\n",
      "Epoch: 1, Train loss: 3.2735, Val loss: 3.2925\n",
      "Model has been saved!\n",
      "Epoch: 2, Train loss: 3.2506, Val loss: 3.3717\n",
      "Patience counter: 1\n",
      "Epoch: 3, Train loss: 3.0221, Val loss: 3.0153\n",
      "Model has been saved!\n",
      "Epoch: 4, Train loss: 2.9660, Val loss: 2.9578\n",
      "Model has been saved!\n",
      "Epoch: 5, Train loss: 2.8422, Val loss: 2.9067\n",
      "Model has been saved!\n",
      "Epoch: 6, Train loss: 2.6589, Val loss: 2.7863\n",
      "Model has been saved!\n",
      "Epoch: 7, Train loss: 2.4904, Val loss: 2.9605\n",
      "Patience counter: 1\n",
      "Epoch: 8, Train loss: 2.3865, Val loss: 2.7215\n",
      "Model has been saved!\n",
      "Epoch: 9, Train loss: 2.6620, Val loss: 3.7904\n",
      "Patience counter: 1\n",
      "Epoch: 10, Train loss: 2.5029, Val loss: 2.6549\n",
      "Model has been saved!\n",
      "Epoch: 11, Train loss: 2.3963, Val loss: 2.6610\n",
      "Patience counter: 1\n",
      "Epoch: 12, Train loss: 2.3747, Val loss: 2.6366\n",
      "Model has been saved!\n",
      "Epoch: 13, Train loss: 2.2906, Val loss: 2.5441\n",
      "Model has been saved!\n",
      "Epoch: 14, Train loss: 2.2641, Val loss: 2.5260\n",
      "Model has been saved!\n",
      "Epoch: 15, Train loss: 2.2639, Val loss: 2.5194\n",
      "Model has been saved!\n",
      "Epoch: 16, Train loss: 2.1935, Val loss: 2.4785\n",
      "Model has been saved!\n",
      "Epoch: 17, Train loss: 2.2808, Val loss: 2.5198\n",
      "Patience counter: 1\n",
      "Epoch: 18, Train loss: 2.1797, Val loss: 2.4296\n",
      "Model has been saved!\n",
      "Epoch: 19, Train loss: 2.1705, Val loss: 2.5494\n",
      "Patience counter: 1\n",
      "Epoch: 20, Train loss: 2.2311, Val loss: 2.4983\n",
      "Patience counter: 2\n",
      "Epoch: 21, Train loss: 2.1679, Val loss: 2.3686\n",
      "Model has been saved!\n",
      "Epoch: 22, Train loss: 2.0579, Val loss: 2.3167\n",
      "Model has been saved!\n",
      "Epoch: 23, Train loss: 2.0589, Val loss: 2.3117\n",
      "Model has been saved!\n",
      "Epoch: 24, Train loss: 2.0854, Val loss: 2.2794\n",
      "Model has been saved!\n",
      "Epoch: 25, Train loss: 2.1275, Val loss: 2.2941\n",
      "Patience counter: 1\n",
      "Epoch: 26, Train loss: 2.0543, Val loss: 2.5068\n",
      "Patience counter: 2\n",
      "Epoch: 27, Train loss: 2.0718, Val loss: 2.2786\n",
      "Model has been saved!\n",
      "Epoch: 28, Train loss: 2.0294, Val loss: 2.4708\n",
      "Patience counter: 1\n",
      "Epoch: 29, Train loss: 2.0311, Val loss: 2.2948\n",
      "Patience counter: 2\n",
      "Epoch: 30, Train loss: 2.0250, Val loss: 2.2401\n",
      "Model has been saved!\n",
      "Epoch: 31, Train loss: 2.0388, Val loss: 2.2258\n",
      "Model has been saved!\n",
      "Epoch: 32, Train loss: 2.0505, Val loss: 2.1997\n",
      "Model has been saved!\n",
      "Epoch: 33, Train loss: 1.9155, Val loss: 2.1685\n",
      "Model has been saved!\n",
      "Epoch: 34, Train loss: 1.9281, Val loss: 2.1711\n",
      "Patience counter: 1\n",
      "Epoch: 35, Train loss: 1.9214, Val loss: 2.1224\n",
      "Model has been saved!\n",
      "Epoch: 36, Train loss: 1.9344, Val loss: 2.2647\n",
      "Patience counter: 1\n",
      "Epoch: 37, Train loss: 1.9080, Val loss: 2.0657\n",
      "Model has been saved!\n",
      "Epoch: 38, Train loss: 1.8955, Val loss: 2.0535\n",
      "Model has been saved!\n",
      "Epoch: 39, Train loss: 1.8885, Val loss: 2.1949\n",
      "Patience counter: 1\n",
      "Epoch: 40, Train loss: 2.0198, Val loss: 2.3892\n",
      "Patience counter: 2\n",
      "Epoch: 41, Train loss: 2.0009, Val loss: 2.1424\n",
      "Patience counter: 3\n",
      "Epoch: 42, Train loss: 1.9239, Val loss: 2.0561\n",
      "Patience counter: 4\n",
      "Epoch: 43, Train loss: 1.9470, Val loss: 2.0151\n",
      "Model has been saved!\n",
      "Epoch: 44, Train loss: 1.7934, Val loss: 2.0045\n",
      "Model has been saved!\n",
      "Epoch: 45, Train loss: 1.8183, Val loss: 2.0784\n",
      "Patience counter: 1\n",
      "Epoch: 46, Train loss: 1.8571, Val loss: 1.9821\n",
      "Model has been saved!\n",
      "Epoch: 47, Train loss: 1.8061, Val loss: 1.8988\n",
      "Model has been saved!\n",
      "Epoch: 48, Train loss: 1.7419, Val loss: 1.9039\n",
      "Patience counter: 1\n",
      "Epoch: 49, Train loss: 1.8159, Val loss: 2.0303\n",
      "Patience counter: 2\n",
      "Epoch: 50, Train loss: 1.7710, Val loss: 1.8637\n",
      "Model has been saved!\n",
      "Epoch: 51, Train loss: 1.7459, Val loss: 1.8639\n",
      "Patience counter: 1\n",
      "Epoch: 52, Train loss: 1.6641, Val loss: 1.9017\n",
      "Patience counter: 2\n",
      "Epoch: 53, Train loss: 1.6609, Val loss: 1.8168\n",
      "Model has been saved!\n",
      "Epoch: 54, Train loss: 1.6985, Val loss: 1.9568\n",
      "Patience counter: 1\n",
      "Epoch: 55, Train loss: 1.6816, Val loss: 1.8419\n",
      "Patience counter: 2\n",
      "Epoch: 56, Train loss: 1.5857, Val loss: 1.7622\n",
      "Model has been saved!\n",
      "Epoch: 57, Train loss: 1.7017, Val loss: 1.8350\n",
      "Patience counter: 1\n",
      "Epoch: 58, Train loss: 1.6579, Val loss: 1.7877\n",
      "Patience counter: 2\n",
      "Epoch: 59, Train loss: 1.6113, Val loss: 1.8019\n",
      "Patience counter: 3\n",
      "Epoch: 60, Train loss: 1.5913, Val loss: 1.7776\n",
      "Patience counter: 4\n",
      "Epoch: 61, Train loss: 1.6150, Val loss: 1.8429\n",
      "Patience counter: 5\n",
      "Epoch: 62, Train loss: 1.6171, Val loss: 1.7984\n",
      "Patience counter: 6\n",
      "Epoch: 63, Train loss: 1.5765, Val loss: 1.6777\n",
      "Model has been saved!\n",
      "Epoch: 64, Train loss: 1.5845, Val loss: 1.8737\n",
      "Patience counter: 1\n",
      "Epoch: 65, Train loss: 1.6813, Val loss: 1.8258\n",
      "Patience counter: 2\n",
      "Epoch: 66, Train loss: 1.6214, Val loss: 1.7206\n",
      "Patience counter: 3\n",
      "Epoch: 67, Train loss: 1.5370, Val loss: 1.9948\n",
      "Patience counter: 4\n",
      "Epoch: 68, Train loss: 1.6816, Val loss: 1.8026\n",
      "Patience counter: 5\n",
      "Epoch: 69, Train loss: 1.5266, Val loss: 1.7762\n",
      "Patience counter: 6\n",
      "Epoch: 70, Train loss: 1.5065, Val loss: 1.8008\n",
      "Patience counter: 7\n",
      "Epoch: 71, Train loss: 1.5436, Val loss: 1.7248\n",
      "Patience counter: 8\n",
      "Epoch: 72, Train loss: 1.6211, Val loss: 1.7950\n",
      "Patience counter: 9\n",
      "Epoch: 73, Train loss: 1.6212, Val loss: 1.7014\n",
      "Patience counter: 10\n",
      "Epoch: 74, Train loss: 1.5404, Val loss: 1.6686\n",
      "Model has been saved!\n",
      "Epoch: 75, Train loss: 1.5867, Val loss: 1.7780\n",
      "Patience counter: 1\n",
      "Epoch: 76, Train loss: 1.5596, Val loss: 1.8342\n",
      "Patience counter: 2\n",
      "Epoch: 77, Train loss: 1.5416, Val loss: 1.7365\n",
      "Patience counter: 3\n",
      "Epoch: 78, Train loss: 1.5692, Val loss: 1.6666\n",
      "Model has been saved!\n",
      "Epoch: 79, Train loss: 1.5345, Val loss: 1.6613\n",
      "Model has been saved!\n",
      "Epoch: 80, Train loss: 1.6304, Val loss: 1.6384\n",
      "Model has been saved!\n",
      "Epoch: 81, Train loss: 1.5204, Val loss: 1.7176\n",
      "Patience counter: 1\n",
      "Epoch: 82, Train loss: 1.5312, Val loss: 1.8159\n",
      "Patience counter: 2\n",
      "Epoch: 83, Train loss: 1.5167, Val loss: 1.8243\n",
      "Patience counter: 3\n",
      "Epoch: 84, Train loss: 1.4816, Val loss: 1.6536\n",
      "Patience counter: 4\n",
      "Epoch: 85, Train loss: 1.4436, Val loss: 1.7608\n",
      "Patience counter: 5\n",
      "Epoch: 86, Train loss: 1.4693, Val loss: 1.6987\n",
      "Patience counter: 6\n",
      "Epoch: 87, Train loss: 1.4760, Val loss: 1.8785\n",
      "Patience counter: 7\n",
      "Epoch: 88, Train loss: 1.4817, Val loss: 1.8912\n",
      "Patience counter: 8\n",
      "Epoch: 89, Train loss: 1.5375, Val loss: 1.7066\n",
      "Patience counter: 9\n",
      "Epoch: 90, Train loss: 1.4239, Val loss: 1.7073\n",
      "Patience counter: 10\n",
      "Epoch: 91, Train loss: 1.4558, Val loss: 1.5968\n",
      "Model has been saved!\n",
      "Epoch: 92, Train loss: 1.4129, Val loss: 1.6737\n",
      "Patience counter: 1\n",
      "Epoch: 93, Train loss: 1.5024, Val loss: 1.9822\n",
      "Patience counter: 2\n",
      "Epoch: 94, Train loss: 1.4623, Val loss: 1.6415\n",
      "Patience counter: 3\n",
      "Epoch: 95, Train loss: 1.4462, Val loss: 1.6482\n",
      "Patience counter: 4\n",
      "Epoch: 96, Train loss: 1.4064, Val loss: 1.6184\n",
      "Patience counter: 5\n",
      "Epoch: 97, Train loss: 1.4928, Val loss: 1.5996\n",
      "Patience counter: 6\n",
      "Epoch: 98, Train loss: 1.3641, Val loss: 1.8295\n",
      "Patience counter: 7\n",
      "Epoch: 99, Train loss: 1.4066, Val loss: 1.6783\n",
      "Patience counter: 8\n",
      "Epoch: 100, Train loss: 1.4763, Val loss: 1.7787\n",
      "Patience counter: 9\n",
      "Epoch: 101, Train loss: 1.4761, Val loss: 1.6306\n",
      "Patience counter: 10\n",
      "Epoch: 102, Train loss: 1.4245, Val loss: 1.6265\n",
      "Patience counter: 11\n",
      "Epoch: 103, Train loss: 1.4503, Val loss: 1.7541\n",
      "Patience counter: 12\n",
      "Epoch: 104, Train loss: 1.4428, Val loss: 1.7061\n",
      "Patience counter: 13\n",
      "Epoch: 105, Train loss: 1.3799, Val loss: 1.6478\n",
      "Patience counter: 14\n",
      "Epoch: 106, Train loss: 1.4042, Val loss: 1.5362\n",
      "Model has been saved!\n",
      "Epoch: 107, Train loss: 1.3368, Val loss: 1.5525\n",
      "Patience counter: 1\n",
      "Epoch: 108, Train loss: 1.4111, Val loss: 1.7514\n",
      "Patience counter: 2\n",
      "Epoch: 109, Train loss: 1.3545, Val loss: 1.5782\n",
      "Patience counter: 3\n",
      "Epoch: 110, Train loss: 1.4096, Val loss: 1.5670\n",
      "Patience counter: 4\n",
      "Epoch: 111, Train loss: 1.4324, Val loss: 1.5813\n",
      "Patience counter: 5\n",
      "Epoch: 112, Train loss: 1.3706, Val loss: 1.6193\n",
      "Patience counter: 6\n",
      "Epoch: 113, Train loss: 1.3793, Val loss: 1.7141\n",
      "Patience counter: 7\n",
      "Epoch: 114, Train loss: 1.3930, Val loss: 1.5983\n",
      "Patience counter: 8\n",
      "Epoch: 115, Train loss: 1.3820, Val loss: 1.8783\n",
      "Patience counter: 9\n",
      "Epoch: 116, Train loss: 1.4230, Val loss: 1.5124\n",
      "Model has been saved!\n",
      "Epoch: 117, Train loss: 1.3662, Val loss: 1.6067\n",
      "Patience counter: 1\n",
      "Epoch: 118, Train loss: 1.3589, Val loss: 1.5806\n",
      "Patience counter: 2\n",
      "Epoch: 119, Train loss: 1.3631, Val loss: 1.5697\n",
      "Patience counter: 3\n",
      "Epoch: 120, Train loss: 1.4293, Val loss: 1.6241\n",
      "Patience counter: 4\n",
      "Epoch: 121, Train loss: 1.3528, Val loss: 1.8712\n",
      "Patience counter: 5\n",
      "Epoch: 122, Train loss: 1.3736, Val loss: 1.5562\n",
      "Patience counter: 6\n",
      "Epoch: 123, Train loss: 1.3144, Val loss: 1.7995\n",
      "Patience counter: 7\n",
      "Epoch: 124, Train loss: 1.3696, Val loss: 1.4976\n",
      "Model has been saved!\n",
      "Epoch: 125, Train loss: 1.4001, Val loss: 1.6276\n",
      "Patience counter: 1\n",
      "Epoch: 126, Train loss: 1.3304, Val loss: 1.5319\n",
      "Patience counter: 2\n",
      "Epoch: 127, Train loss: 1.3880, Val loss: 1.5802\n",
      "Patience counter: 3\n",
      "Epoch: 128, Train loss: 1.3628, Val loss: 1.7191\n",
      "Patience counter: 4\n",
      "Epoch: 129, Train loss: 1.3090, Val loss: 1.5231\n",
      "Patience counter: 5\n",
      "Epoch: 130, Train loss: 1.2994, Val loss: 1.5442\n",
      "Patience counter: 6\n",
      "Epoch: 131, Train loss: 1.4055, Val loss: 1.7097\n",
      "Patience counter: 7\n",
      "Epoch: 132, Train loss: 1.3130, Val loss: 1.6677\n",
      "Patience counter: 8\n",
      "Epoch: 133, Train loss: 1.3947, Val loss: 1.6952\n",
      "Patience counter: 9\n",
      "Epoch: 134, Train loss: 1.3980, Val loss: 1.6652\n",
      "Patience counter: 10\n",
      "Epoch: 135, Train loss: 1.3363, Val loss: 1.7234\n",
      "Patience counter: 11\n",
      "Epoch: 136, Train loss: 1.3406, Val loss: 1.6431\n",
      "Patience counter: 12\n",
      "Epoch: 137, Train loss: 1.3416, Val loss: 1.7976\n",
      "Patience counter: 13\n",
      "Epoch: 138, Train loss: 1.3943, Val loss: 1.7004\n",
      "Patience counter: 14\n",
      "Epoch: 139, Train loss: 1.3465, Val loss: 1.6240\n",
      "Patience counter: 15\n",
      "Epoch: 140, Train loss: 1.2808, Val loss: 1.7228\n",
      "Patience counter: 16\n",
      "Epoch: 141, Train loss: 1.3160, Val loss: 1.7694\n",
      "Patience counter: 17\n",
      "Epoch: 142, Train loss: 1.3136, Val loss: 1.7094\n",
      "Patience counter: 18\n",
      "Epoch: 143, Train loss: 1.3808, Val loss: 1.5410\n",
      "Patience counter: 19\n",
      "Epoch: 144, Train loss: 1.3390, Val loss: 1.5138\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-05\n",
      "Epoch: 145, Train loss: 1.2284, Val loss: 1.5761\n",
      "Patience counter: 1\n",
      "Epoch: 146, Train loss: 1.2291, Val loss: 1.5896\n",
      "Patience counter: 2\n",
      "Epoch: 147, Train loss: 1.1812, Val loss: 1.6117\n",
      "Patience counter: 3\n",
      "Epoch: 148, Train loss: 1.2252, Val loss: 1.6272\n",
      "Patience counter: 4\n",
      "Epoch: 149, Train loss: 1.2487, Val loss: 1.6269\n",
      "Patience counter: 5\n",
      "Epoch: 150, Train loss: 1.2239, Val loss: 1.6096\n",
      "Patience counter: 6\n",
      "Epoch: 151, Train loss: 1.2133, Val loss: 1.6431\n",
      "Patience counter: 7\n",
      "Epoch: 152, Train loss: 1.2217, Val loss: 1.6230\n",
      "Patience counter: 8\n",
      "Epoch: 153, Train loss: 1.2042, Val loss: 1.6167\n",
      "Patience counter: 9\n",
      "Epoch: 154, Train loss: 1.2312, Val loss: 1.6233\n",
      "Patience counter: 10\n",
      "Epoch: 155, Train loss: 1.2246, Val loss: 1.6300\n",
      "Patience counter: 11\n",
      "Epoch: 156, Train loss: 1.2175, Val loss: 1.6232\n",
      "Patience counter: 12\n",
      "Epoch: 157, Train loss: 1.2026, Val loss: 1.6258\n",
      "Patience counter: 13\n",
      "Epoch: 158, Train loss: 1.2014, Val loss: 1.6319\n",
      "Patience counter: 14\n",
      "Epoch: 159, Train loss: 1.2250, Val loss: 1.6214\n",
      "Patience counter: 15\n",
      "Epoch: 160, Train loss: 1.1870, Val loss: 1.6301\n",
      "Patience counter: 16\n",
      "Epoch: 161, Train loss: 1.1960, Val loss: 1.6440\n",
      "Patience counter: 17\n",
      "Epoch: 162, Train loss: 1.1939, Val loss: 1.6265\n",
      "Patience counter: 18\n",
      "Epoch: 163, Train loss: 1.1833, Val loss: 1.6386\n",
      "Patience counter: 19\n",
      "Epoch: 164, Train loss: 1.2008, Val loss: 1.6318\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-06\n",
      "Epoch: 165, Train loss: 1.1873, Val loss: 1.6243\n",
      "Patience counter: 1\n",
      "Epoch: 166, Train loss: 1.2112, Val loss: 1.6224\n",
      "Patience counter: 2\n",
      "Epoch: 167, Train loss: 1.2080, Val loss: 1.6213\n",
      "Patience counter: 3\n",
      "Epoch: 168, Train loss: 1.1852, Val loss: 1.6243\n",
      "Patience counter: 4\n",
      "Epoch: 169, Train loss: 1.2187, Val loss: 1.6234\n",
      "Patience counter: 5\n",
      "Epoch: 170, Train loss: 1.1779, Val loss: 1.6259\n",
      "Patience counter: 6\n",
      "Epoch: 171, Train loss: 1.1899, Val loss: 1.6232\n",
      "Patience counter: 7\n",
      "Epoch: 172, Train loss: 1.1755, Val loss: 1.6276\n",
      "Patience counter: 8\n",
      "Epoch: 173, Train loss: 1.1880, Val loss: 1.6302\n",
      "Patience counter: 9\n",
      "Epoch: 174, Train loss: 1.1890, Val loss: 1.6270\n",
      "Patience counter: 10\n",
      "Epoch: 175, Train loss: 1.2006, Val loss: 1.6267\n",
      "Patience counter: 11\n",
      "Epoch: 176, Train loss: 1.1788, Val loss: 1.6277\n",
      "Patience counter: 12\n",
      "Epoch: 177, Train loss: 1.1503, Val loss: 1.6250\n",
      "Patience counter: 13\n",
      "Epoch: 178, Train loss: 1.1796, Val loss: 1.6314\n",
      "Patience counter: 14\n",
      "Epoch: 179, Train loss: 1.1720, Val loss: 1.6300\n",
      "Patience counter: 15\n",
      "Epoch: 180, Train loss: 1.1996, Val loss: 1.6305\n",
      "Patience counter: 16\n",
      "Epoch: 181, Train loss: 1.1538, Val loss: 1.6319\n",
      "Patience counter: 17\n",
      "Epoch: 182, Train loss: 1.1633, Val loss: 1.6315\n",
      "Patience counter: 18\n",
      "Epoch: 183, Train loss: 1.1752, Val loss: 1.6301\n",
      "Patience counter: 19\n",
      "Epoch: 184, Train loss: 1.2130, Val loss: 1.6282\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-07\n",
      "Epoch: 185, Train loss: 1.1906, Val loss: 1.6281\n",
      "Patience counter: 1\n",
      "Epoch: 186, Train loss: 1.1690, Val loss: 1.6282\n",
      "Patience counter: 2\n",
      "Epoch: 187, Train loss: 1.1877, Val loss: 1.6280\n",
      "Patience counter: 3\n",
      "Epoch: 188, Train loss: 1.1789, Val loss: 1.6278\n",
      "Patience counter: 4\n",
      "Epoch: 189, Train loss: 1.1598, Val loss: 1.6278\n",
      "Patience counter: 5\n",
      "Epoch: 190, Train loss: 1.1683, Val loss: 1.6279\n",
      "Patience counter: 6\n",
      "Epoch: 191, Train loss: 1.1580, Val loss: 1.6280\n",
      "Patience counter: 7\n",
      "Epoch: 192, Train loss: 1.1642, Val loss: 1.6279\n",
      "Patience counter: 8\n",
      "Epoch: 193, Train loss: 1.1624, Val loss: 1.6280\n",
      "Patience counter: 9\n",
      "Epoch: 194, Train loss: 1.1556, Val loss: 1.6276\n",
      "Patience counter: 10\n",
      "Epoch: 195, Train loss: 1.1981, Val loss: 1.6276\n",
      "Patience counter: 11\n",
      "Epoch: 196, Train loss: 1.1980, Val loss: 1.6277\n",
      "Patience counter: 12\n",
      "Epoch: 197, Train loss: 1.1656, Val loss: 1.6279\n",
      "Patience counter: 13\n",
      "Epoch: 198, Train loss: 1.1753, Val loss: 1.6280\n",
      "Patience counter: 14\n",
      "Epoch: 199, Train loss: 1.2042, Val loss: 1.6281\n",
      "Patience counter: 15\n",
      "Test Loss: 1.2045, MSE: 1.2540, MAE: 0.8118, R2: 0.5750\n"
     ]
    }
   ],
   "source": [
    "# 训练模型，设置epoch数为100\n",
    "epochs = 200\n",
    "\n",
    "# 阳离子还原势GAT模型\n",
    "IL_ECW_train_losses_gat, IL_ECW_val_losses_gat, IL_ECW_test_pred_gat, IL_ECW_test_true_gat, IL_ECW_test_mse_gat, IL_ECW_test_mae_gat, IL_ECW_test_r2_gat = train_epochs(\n",
    "    0, epochs, model_IL_ECW_GAT, IL_ECW_train_loader, IL_ECW_val_loader, IL_ECW_test_loader, \"IL_ECW_GAT_model.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223e3546",
   "metadata": {},
   "source": [
    "# GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6038e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 6.2317, Val loss: 5.9087\n",
      "Model has been saved!\n",
      "Epoch: 1, Train loss: 5.7853, Val loss: 5.0352\n",
      "Model has been saved!\n",
      "Epoch: 2, Train loss: 5.1652, Val loss: 4.2417\n",
      "Model has been saved!\n",
      "Epoch: 3, Train loss: 5.0685, Val loss: 4.1457\n",
      "Model has been saved!\n",
      "Epoch: 4, Train loss: 4.8006, Val loss: 4.3940\n",
      "Patience counter: 1\n",
      "Epoch: 5, Train loss: 4.4212, Val loss: 3.4913\n",
      "Model has been saved!\n",
      "Epoch: 6, Train loss: 4.2824, Val loss: 4.1552\n",
      "Patience counter: 1\n",
      "Epoch: 7, Train loss: 4.0612, Val loss: 3.8310\n",
      "Patience counter: 2\n",
      "Epoch: 8, Train loss: 4.1228, Val loss: 3.7771\n",
      "Patience counter: 3\n",
      "Epoch: 9, Train loss: 4.2387, Val loss: 3.6043\n",
      "Patience counter: 4\n",
      "Epoch: 10, Train loss: 3.8354, Val loss: 3.7281\n",
      "Patience counter: 5\n",
      "Epoch: 11, Train loss: 3.5981, Val loss: 3.4450\n",
      "Model has been saved!\n",
      "Epoch: 12, Train loss: 3.3871, Val loss: 3.6897\n",
      "Patience counter: 1\n",
      "Epoch: 13, Train loss: 3.5019, Val loss: 3.6491\n",
      "Patience counter: 2\n",
      "Epoch: 14, Train loss: 3.6115, Val loss: 3.6776\n",
      "Patience counter: 3\n",
      "Epoch: 15, Train loss: 3.6473, Val loss: 3.9248\n",
      "Patience counter: 4\n",
      "Epoch: 16, Train loss: 4.3733, Val loss: 3.7030\n",
      "Patience counter: 5\n",
      "Epoch: 17, Train loss: 3.9192, Val loss: 3.8886\n",
      "Patience counter: 6\n",
      "Epoch: 18, Train loss: 3.7244, Val loss: 3.4301\n",
      "Model has been saved!\n",
      "Epoch: 19, Train loss: 3.5531, Val loss: 4.6199\n",
      "Patience counter: 1\n",
      "Epoch: 20, Train loss: 3.1125, Val loss: 3.2859\n",
      "Model has been saved!\n",
      "Epoch: 21, Train loss: 3.1114, Val loss: 3.0225\n",
      "Model has been saved!\n",
      "Epoch: 22, Train loss: 2.9856, Val loss: 4.4313\n",
      "Patience counter: 1\n",
      "Epoch: 23, Train loss: 3.3208, Val loss: 3.3120\n",
      "Patience counter: 2\n",
      "Epoch: 24, Train loss: 3.0720, Val loss: 4.2701\n",
      "Patience counter: 3\n",
      "Epoch: 25, Train loss: 3.2670, Val loss: 3.6299\n",
      "Patience counter: 4\n",
      "Epoch: 26, Train loss: 3.2806, Val loss: 3.4567\n",
      "Patience counter: 5\n",
      "Epoch: 27, Train loss: 2.8862, Val loss: 3.5351\n",
      "Patience counter: 6\n",
      "Epoch: 28, Train loss: 3.6644, Val loss: 3.3070\n",
      "Patience counter: 7\n",
      "Epoch: 29, Train loss: 3.3600, Val loss: 3.5556\n",
      "Patience counter: 8\n",
      "Epoch: 30, Train loss: 3.6041, Val loss: 3.3185\n",
      "Patience counter: 9\n",
      "Epoch: 31, Train loss: 2.7832, Val loss: 3.0722\n",
      "Patience counter: 10\n",
      "Epoch: 32, Train loss: 3.0050, Val loss: 2.5284\n",
      "Model has been saved!\n",
      "Epoch: 33, Train loss: 3.1875, Val loss: 3.1223\n",
      "Patience counter: 1\n",
      "Epoch: 34, Train loss: 3.0149, Val loss: 2.8397\n",
      "Patience counter: 2\n",
      "Epoch: 35, Train loss: 2.9405, Val loss: 2.6236\n",
      "Patience counter: 3\n",
      "Epoch: 36, Train loss: 3.1398, Val loss: 3.0312\n",
      "Patience counter: 4\n",
      "Epoch: 37, Train loss: 2.9916, Val loss: 3.3471\n",
      "Patience counter: 5\n",
      "Epoch: 38, Train loss: 2.8524, Val loss: 3.0179\n",
      "Patience counter: 6\n",
      "Epoch: 39, Train loss: 3.1908, Val loss: 3.0593\n",
      "Patience counter: 7\n",
      "Epoch: 40, Train loss: 3.1349, Val loss: 2.8815\n",
      "Patience counter: 8\n",
      "Epoch: 41, Train loss: 2.9168, Val loss: 2.6683\n",
      "Patience counter: 9\n",
      "Epoch: 42, Train loss: 2.5748, Val loss: 3.2380\n",
      "Patience counter: 10\n",
      "Epoch: 43, Train loss: 3.1748, Val loss: 2.8134\n",
      "Patience counter: 11\n",
      "Epoch: 44, Train loss: 2.6929, Val loss: 2.7127\n",
      "Patience counter: 12\n",
      "Epoch: 45, Train loss: 2.8287, Val loss: 4.0635\n",
      "Patience counter: 13\n",
      "Epoch: 46, Train loss: 3.0918, Val loss: 3.3863\n",
      "Patience counter: 14\n",
      "Epoch: 47, Train loss: 2.8872, Val loss: 2.6847\n",
      "Patience counter: 15\n",
      "Epoch: 48, Train loss: 3.1374, Val loss: 2.4411\n",
      "Model has been saved!\n",
      "Epoch: 49, Train loss: 2.8296, Val loss: 2.2375\n",
      "Model has been saved!\n",
      "Epoch: 50, Train loss: 2.5638, Val loss: 2.1443\n",
      "Model has been saved!\n",
      "Epoch: 51, Train loss: 2.9129, Val loss: 2.0385\n",
      "Model has been saved!\n",
      "Epoch: 52, Train loss: 2.7744, Val loss: 2.2082\n",
      "Patience counter: 1\n",
      "Epoch: 53, Train loss: 2.4644, Val loss: 2.4031\n",
      "Patience counter: 2\n",
      "Epoch: 54, Train loss: 2.5021, Val loss: 2.2434\n",
      "Patience counter: 3\n",
      "Epoch: 55, Train loss: 2.6404, Val loss: 2.4708\n",
      "Patience counter: 4\n",
      "Epoch: 56, Train loss: 2.5242, Val loss: 2.4380\n",
      "Patience counter: 5\n",
      "Epoch: 57, Train loss: 2.4273, Val loss: 2.4240\n",
      "Patience counter: 6\n",
      "Epoch: 58, Train loss: 2.5691, Val loss: 1.8996\n",
      "Model has been saved!\n",
      "Epoch: 59, Train loss: 2.7937, Val loss: 1.8380\n",
      "Model has been saved!\n",
      "Epoch: 60, Train loss: 2.5532, Val loss: 2.3414\n",
      "Patience counter: 1\n",
      "Epoch: 61, Train loss: 2.6622, Val loss: 1.6016\n",
      "Model has been saved!\n",
      "Epoch: 62, Train loss: 2.5007, Val loss: 1.8278\n",
      "Patience counter: 1\n",
      "Epoch: 63, Train loss: 2.6622, Val loss: 1.7222\n",
      "Patience counter: 2\n",
      "Epoch: 64, Train loss: 2.9804, Val loss: 2.2954\n",
      "Patience counter: 3\n",
      "Epoch: 65, Train loss: 2.2838, Val loss: 1.9374\n",
      "Patience counter: 4\n",
      "Epoch: 66, Train loss: 2.4016, Val loss: 1.5332\n",
      "Model has been saved!\n",
      "Epoch: 67, Train loss: 2.5700, Val loss: 2.2793\n",
      "Patience counter: 1\n",
      "Epoch: 68, Train loss: 2.3990, Val loss: 1.7033\n",
      "Patience counter: 2\n",
      "Epoch: 69, Train loss: 2.2761, Val loss: 2.4035\n",
      "Patience counter: 3\n",
      "Epoch: 70, Train loss: 2.5190, Val loss: 1.7955\n",
      "Patience counter: 4\n",
      "Epoch: 71, Train loss: 2.4415, Val loss: 1.9568\n",
      "Patience counter: 5\n",
      "Epoch: 72, Train loss: 2.1166, Val loss: 1.8655\n",
      "Patience counter: 6\n",
      "Epoch: 73, Train loss: 2.4903, Val loss: 2.5243\n",
      "Patience counter: 7\n",
      "Epoch: 74, Train loss: 2.3174, Val loss: 2.3512\n",
      "Patience counter: 8\n",
      "Epoch: 75, Train loss: 2.1068, Val loss: 1.9453\n",
      "Patience counter: 9\n",
      "Epoch: 76, Train loss: 2.1680, Val loss: 2.2413\n",
      "Patience counter: 10\n",
      "Epoch: 77, Train loss: 2.4554, Val loss: 2.1859\n",
      "Patience counter: 11\n",
      "Epoch: 78, Train loss: 2.1634, Val loss: 1.8902\n",
      "Patience counter: 12\n",
      "Epoch: 79, Train loss: 2.2169, Val loss: 2.1253\n",
      "Patience counter: 13\n",
      "Epoch: 80, Train loss: 2.2580, Val loss: 2.0703\n",
      "Patience counter: 14\n",
      "Epoch: 81, Train loss: 2.4562, Val loss: 2.6707\n",
      "Patience counter: 15\n",
      "Epoch: 82, Train loss: 2.6220, Val loss: 2.5124\n",
      "Patience counter: 16\n",
      "Epoch: 83, Train loss: 2.5968, Val loss: 1.8371\n",
      "Patience counter: 17\n",
      "Epoch: 84, Train loss: 2.7410, Val loss: 1.7749\n",
      "Patience counter: 18\n",
      "Epoch: 85, Train loss: 2.4814, Val loss: 1.9102\n",
      "Patience counter: 19\n",
      "Epoch: 86, Train loss: 2.4541, Val loss: 2.3394\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-05\n",
      "Epoch: 87, Train loss: 2.4914, Val loss: 1.6495\n",
      "Patience counter: 1\n",
      "Epoch: 88, Train loss: 1.9173, Val loss: 1.9397\n",
      "Patience counter: 2\n",
      "Epoch: 89, Train loss: 2.2599, Val loss: 1.7497\n",
      "Patience counter: 3\n",
      "Epoch: 90, Train loss: 1.9854, Val loss: 1.6128\n",
      "Patience counter: 4\n",
      "Epoch: 91, Train loss: 2.0663, Val loss: 1.6318\n",
      "Patience counter: 5\n",
      "Epoch: 92, Train loss: 2.3713, Val loss: 1.6079\n",
      "Patience counter: 6\n",
      "Epoch: 93, Train loss: 2.1676, Val loss: 1.6150\n",
      "Patience counter: 7\n",
      "Epoch: 94, Train loss: 1.9301, Val loss: 1.6921\n",
      "Patience counter: 8\n",
      "Epoch: 95, Train loss: 1.8926, Val loss: 1.6985\n",
      "Patience counter: 9\n",
      "Epoch: 96, Train loss: 1.9013, Val loss: 1.5890\n",
      "Patience counter: 10\n",
      "Epoch: 97, Train loss: 2.2818, Val loss: 1.7477\n",
      "Patience counter: 11\n",
      "Epoch: 98, Train loss: 2.0773, Val loss: 1.6534\n",
      "Patience counter: 12\n",
      "Epoch: 99, Train loss: 1.9864, Val loss: 1.6412\n",
      "Patience counter: 13\n",
      "Epoch: 100, Train loss: 2.1976, Val loss: 1.6288\n",
      "Patience counter: 14\n",
      "Epoch: 101, Train loss: 1.9546, Val loss: 1.5311\n",
      "Model has been saved!\n",
      "Epoch: 102, Train loss: 2.0057, Val loss: 1.7222\n",
      "Patience counter: 1\n",
      "Epoch: 103, Train loss: 2.1442, Val loss: 1.5709\n",
      "Patience counter: 2\n",
      "Epoch: 104, Train loss: 1.9223, Val loss: 1.6285\n",
      "Patience counter: 3\n",
      "Epoch: 105, Train loss: 1.9025, Val loss: 1.5986\n",
      "Patience counter: 4\n",
      "Epoch: 106, Train loss: 1.9902, Val loss: 1.6222\n",
      "Patience counter: 5\n",
      "Epoch: 107, Train loss: 1.8966, Val loss: 1.5885\n",
      "Patience counter: 6\n",
      "Epoch: 108, Train loss: 2.0437, Val loss: 1.6598\n",
      "Patience counter: 7\n",
      "Epoch: 109, Train loss: 1.9638, Val loss: 1.6854\n",
      "Patience counter: 8\n",
      "Epoch: 110, Train loss: 1.9192, Val loss: 1.6526\n",
      "Patience counter: 9\n",
      "Epoch: 111, Train loss: 2.0829, Val loss: 1.7455\n",
      "Patience counter: 10\n",
      "Epoch: 112, Train loss: 1.8832, Val loss: 1.7444\n",
      "Patience counter: 11\n",
      "Epoch: 113, Train loss: 1.9086, Val loss: 1.5351\n",
      "Patience counter: 12\n",
      "Epoch: 114, Train loss: 1.8906, Val loss: 1.5153\n",
      "Model has been saved!\n",
      "Epoch: 115, Train loss: 1.8313, Val loss: 1.5614\n",
      "Patience counter: 1\n",
      "Epoch: 116, Train loss: 1.9749, Val loss: 1.6775\n",
      "Patience counter: 2\n",
      "Epoch: 117, Train loss: 1.9465, Val loss: 1.5459\n",
      "Patience counter: 3\n",
      "Epoch: 118, Train loss: 2.0293, Val loss: 1.6468\n",
      "Patience counter: 4\n",
      "Epoch: 119, Train loss: 1.8190, Val loss: 1.5411\n",
      "Patience counter: 5\n",
      "Epoch: 120, Train loss: 1.9643, Val loss: 1.6217\n",
      "Patience counter: 6\n",
      "Epoch: 121, Train loss: 1.8997, Val loss: 1.6374\n",
      "Patience counter: 7\n",
      "Epoch: 122, Train loss: 2.0648, Val loss: 1.6446\n",
      "Patience counter: 8\n",
      "Epoch: 123, Train loss: 1.9602, Val loss: 1.5921\n",
      "Patience counter: 9\n",
      "Epoch: 124, Train loss: 1.8116, Val loss: 1.6595\n",
      "Patience counter: 10\n",
      "Epoch: 125, Train loss: 1.8550, Val loss: 1.5359\n",
      "Patience counter: 11\n",
      "Epoch: 126, Train loss: 1.8634, Val loss: 1.4888\n",
      "Model has been saved!\n",
      "Epoch: 127, Train loss: 1.7884, Val loss: 1.5143\n",
      "Patience counter: 1\n",
      "Epoch: 128, Train loss: 1.6362, Val loss: 1.4712\n",
      "Model has been saved!\n",
      "Epoch: 129, Train loss: 1.9991, Val loss: 1.5748\n",
      "Patience counter: 1\n",
      "Epoch: 130, Train loss: 2.0180, Val loss: 1.5494\n",
      "Patience counter: 2\n",
      "Epoch: 131, Train loss: 2.0418, Val loss: 1.5556\n",
      "Patience counter: 3\n",
      "Epoch: 132, Train loss: 1.9541, Val loss: 1.7242\n",
      "Patience counter: 4\n",
      "Epoch: 133, Train loss: 1.8824, Val loss: 1.5533\n",
      "Patience counter: 5\n",
      "Epoch: 134, Train loss: 1.9190, Val loss: 1.5195\n",
      "Patience counter: 6\n",
      "Epoch: 135, Train loss: 1.8905, Val loss: 1.6006\n",
      "Patience counter: 7\n",
      "Epoch: 136, Train loss: 1.8088, Val loss: 1.5960\n",
      "Patience counter: 8\n",
      "Epoch: 137, Train loss: 1.7974, Val loss: 1.5405\n",
      "Patience counter: 9\n",
      "Epoch: 138, Train loss: 2.0857, Val loss: 1.5015\n",
      "Patience counter: 10\n",
      "Epoch: 139, Train loss: 1.8132, Val loss: 1.5587\n",
      "Patience counter: 11\n",
      "Epoch: 140, Train loss: 1.8177, Val loss: 1.5031\n",
      "Patience counter: 12\n",
      "Epoch: 141, Train loss: 1.8547, Val loss: 1.5445\n",
      "Patience counter: 13\n",
      "Epoch: 142, Train loss: 1.8182, Val loss: 1.6793\n",
      "Patience counter: 14\n",
      "Epoch: 143, Train loss: 1.9534, Val loss: 1.5477\n",
      "Patience counter: 15\n",
      "Epoch: 144, Train loss: 1.9453, Val loss: 1.5772\n",
      "Patience counter: 16\n",
      "Epoch: 145, Train loss: 1.7312, Val loss: 1.6184\n",
      "Patience counter: 17\n",
      "Epoch: 146, Train loss: 1.7435, Val loss: 1.5231\n",
      "Patience counter: 18\n",
      "Epoch: 147, Train loss: 1.7821, Val loss: 1.5834\n",
      "Patience counter: 19\n",
      "Epoch: 148, Train loss: 1.7059, Val loss: 1.5275\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-06\n",
      "Epoch: 149, Train loss: 1.8304, Val loss: 1.4744\n",
      "Patience counter: 1\n",
      "Epoch: 150, Train loss: 1.7724, Val loss: 1.5021\n",
      "Patience counter: 2\n",
      "Epoch: 151, Train loss: 2.0565, Val loss: 1.5402\n",
      "Patience counter: 3\n",
      "Epoch: 152, Train loss: 1.9649, Val loss: 1.5299\n",
      "Patience counter: 4\n",
      "Epoch: 153, Train loss: 1.9344, Val loss: 1.5438\n",
      "Patience counter: 5\n",
      "Epoch: 154, Train loss: 1.8453, Val loss: 1.5060\n",
      "Patience counter: 6\n",
      "Epoch: 155, Train loss: 1.6973, Val loss: 1.5564\n",
      "Patience counter: 7\n",
      "Epoch: 156, Train loss: 1.9110, Val loss: 1.5671\n",
      "Patience counter: 8\n",
      "Epoch: 157, Train loss: 2.0438, Val loss: 1.5282\n",
      "Patience counter: 9\n",
      "Epoch: 158, Train loss: 1.8666, Val loss: 1.5097\n",
      "Patience counter: 10\n",
      "Epoch: 159, Train loss: 1.9538, Val loss: 1.5527\n",
      "Patience counter: 11\n",
      "Epoch: 160, Train loss: 1.9200, Val loss: 1.5207\n",
      "Patience counter: 12\n",
      "Epoch: 161, Train loss: 1.8177, Val loss: 1.5044\n",
      "Patience counter: 13\n",
      "Epoch: 162, Train loss: 1.8246, Val loss: 1.5557\n",
      "Patience counter: 14\n",
      "Epoch: 163, Train loss: 1.9281, Val loss: 1.5241\n",
      "Patience counter: 15\n",
      "Epoch: 164, Train loss: 1.6928, Val loss: 1.5356\n",
      "Patience counter: 16\n",
      "Epoch: 165, Train loss: 1.9101, Val loss: 1.4961\n",
      "Patience counter: 17\n",
      "Epoch: 166, Train loss: 1.8343, Val loss: 1.5147\n",
      "Patience counter: 18\n",
      "Epoch: 167, Train loss: 1.9958, Val loss: 1.5315\n",
      "Patience counter: 19\n",
      "Epoch: 168, Train loss: 2.2386, Val loss: 1.4984\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-07\n",
      "Epoch: 169, Train loss: 1.7168, Val loss: 1.5517\n",
      "Patience counter: 1\n",
      "Epoch: 170, Train loss: 1.9922, Val loss: 1.5245\n",
      "Patience counter: 2\n",
      "Epoch: 171, Train loss: 1.9107, Val loss: 1.5357\n",
      "Patience counter: 3\n",
      "Epoch: 172, Train loss: 1.8307, Val loss: 1.5266\n",
      "Patience counter: 4\n",
      "Epoch: 173, Train loss: 1.6505, Val loss: 1.5461\n",
      "Patience counter: 5\n",
      "Epoch: 174, Train loss: 1.7911, Val loss: 1.5278\n",
      "Patience counter: 6\n",
      "Epoch: 175, Train loss: 1.7176, Val loss: 1.5264\n",
      "Patience counter: 7\n",
      "Epoch: 176, Train loss: 1.8392, Val loss: 1.5311\n",
      "Patience counter: 8\n",
      "Epoch: 177, Train loss: 1.8686, Val loss: 1.5143\n",
      "Patience counter: 9\n",
      "Epoch: 178, Train loss: 1.9011, Val loss: 1.5235\n",
      "Patience counter: 10\n",
      "Epoch: 179, Train loss: 2.0625, Val loss: 1.5173\n",
      "Patience counter: 11\n",
      "Epoch: 180, Train loss: 1.7884, Val loss: 1.5026\n",
      "Patience counter: 12\n",
      "Epoch: 181, Train loss: 1.7196, Val loss: 1.5403\n",
      "Patience counter: 13\n",
      "Epoch: 182, Train loss: 1.7966, Val loss: 1.5187\n",
      "Patience counter: 14\n",
      "Epoch: 183, Train loss: 2.0038, Val loss: 1.5220\n",
      "Patience counter: 15\n",
      "Epoch: 184, Train loss: 1.9782, Val loss: 1.5341\n",
      "Patience counter: 16\n",
      "Epoch: 185, Train loss: 1.7917, Val loss: 1.5368\n",
      "Patience counter: 17\n",
      "Epoch: 186, Train loss: 1.7687, Val loss: 1.5036\n",
      "Patience counter: 18\n",
      "Epoch: 187, Train loss: 1.7750, Val loss: 1.5080\n",
      "Patience counter: 19\n",
      "Epoch: 188, Train loss: 1.8149, Val loss: 1.5036\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-08\n",
      "Epoch: 189, Train loss: 1.9168, Val loss: 1.5420\n",
      "Patience counter: 1\n",
      "Epoch: 190, Train loss: 1.8093, Val loss: 1.5124\n",
      "Patience counter: 2\n",
      "Epoch: 191, Train loss: 1.8006, Val loss: 1.5531\n",
      "Patience counter: 3\n",
      "Epoch: 192, Train loss: 1.7292, Val loss: 1.5042\n",
      "Patience counter: 4\n",
      "Epoch: 193, Train loss: 2.0223, Val loss: 1.5378\n",
      "Patience counter: 5\n",
      "Epoch: 194, Train loss: 1.9856, Val loss: 1.5344\n",
      "Patience counter: 6\n",
      "Epoch: 195, Train loss: 1.8442, Val loss: 1.5358\n",
      "Patience counter: 7\n",
      "Epoch: 196, Train loss: 1.7281, Val loss: 1.5088\n",
      "Patience counter: 8\n",
      "Epoch: 197, Train loss: 1.9200, Val loss: 1.5106\n",
      "Patience counter: 9\n",
      "Epoch: 198, Train loss: 1.8980, Val loss: 1.4882\n",
      "Patience counter: 10\n",
      "Epoch: 199, Train loss: 1.8642, Val loss: 1.5104\n",
      "Patience counter: 11\n",
      "Test Loss: 2.0165, MSE: 2.1481, MAE: 1.0476, R2: 0.6826\n"
     ]
    }
   ],
   "source": [
    "# 训练模型，设置epoch数为100\n",
    "epochs = 200\n",
    "\n",
    "# 熔点GCN模型\n",
    "Tm_train_losses_gcn, Tm_val_losses_gcn, Tm_test_pred_gcn, Tm_test_true_gcn, Tm_test_mse_gcn, Tm_test_mae_gcn, Tm_test_r2_gcn = train_epochs(\n",
    "    0, epochs, model_Tm_GCN, Tm_train_loader, Tm_val_loader, Tm_test_loader, \"Tm_GCN_model.pt\"\n",
    ")\n",
    "\n",
    "# 电导率GCN模型\n",
    "conductivity_train_losses_gcn, conductivity_val_losses_gcn, conductivity_test_pred_gcn, conductivity_test_true_gcn, conductivity_test_mse_gcn, conductivity_test_mae_gcn, conductivity_test_r2_gcn = train_epochs(\n",
    "    0, epochs, model_conductivity_GCN, conductivity_train_loader, conductivity_val_loader, conductivity_test_loader, \"conductivity_GCN_model.pt\", scale=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c6c2b504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 2.0167, Val loss: 2.8464\n",
      "Model has been saved!\n",
      "Epoch: 1, Train loss: 1.6880, Val loss: 2.6999\n",
      "Model has been saved!\n",
      "Epoch: 2, Train loss: 1.6647, Val loss: 2.6945\n",
      "Model has been saved!\n",
      "Epoch: 3, Train loss: 1.7363, Val loss: 2.7108\n",
      "Patience counter: 1\n",
      "Epoch: 4, Train loss: 1.5792, Val loss: 2.6130\n",
      "Model has been saved!\n",
      "Epoch: 5, Train loss: 1.6416, Val loss: 2.6269\n",
      "Patience counter: 1\n",
      "Epoch: 6, Train loss: 1.3759, Val loss: 2.7134\n",
      "Patience counter: 2\n",
      "Epoch: 7, Train loss: 1.6198, Val loss: 2.6950\n",
      "Patience counter: 3\n",
      "Epoch: 8, Train loss: 1.9498, Val loss: 2.5693\n",
      "Model has been saved!\n",
      "Epoch: 9, Train loss: 1.6771, Val loss: 2.5602\n",
      "Model has been saved!\n",
      "Epoch: 10, Train loss: 1.4128, Val loss: 2.6052\n",
      "Patience counter: 1\n",
      "Epoch: 11, Train loss: 1.5502, Val loss: 2.6235\n",
      "Patience counter: 2\n",
      "Epoch: 12, Train loss: 1.4395, Val loss: 2.5787\n",
      "Patience counter: 3\n",
      "Epoch: 13, Train loss: 1.3177, Val loss: 2.5793\n",
      "Patience counter: 4\n",
      "Epoch: 14, Train loss: 1.3788, Val loss: 2.6939\n",
      "Patience counter: 5\n",
      "Epoch: 15, Train loss: 1.2684, Val loss: 2.7144\n",
      "Patience counter: 6\n",
      "Epoch: 16, Train loss: 1.4182, Val loss: 2.7377\n",
      "Patience counter: 7\n",
      "Epoch: 17, Train loss: 1.2520, Val loss: 2.6038\n",
      "Patience counter: 8\n",
      "Epoch: 18, Train loss: 1.4160, Val loss: 2.5907\n",
      "Patience counter: 9\n",
      "Epoch: 19, Train loss: 1.3020, Val loss: 2.7918\n",
      "Patience counter: 10\n",
      "Epoch: 20, Train loss: 1.3919, Val loss: 2.9006\n",
      "Patience counter: 11\n",
      "Epoch: 21, Train loss: 1.3467, Val loss: 2.7922\n",
      "Patience counter: 12\n",
      "Epoch: 22, Train loss: 1.3221, Val loss: 2.6405\n",
      "Patience counter: 13\n",
      "Epoch: 23, Train loss: 1.1746, Val loss: 2.6389\n",
      "Patience counter: 14\n",
      "Epoch: 24, Train loss: 1.3389, Val loss: 2.6789\n",
      "Patience counter: 15\n",
      "Epoch: 25, Train loss: 1.2477, Val loss: 2.6545\n",
      "Patience counter: 16\n",
      "Epoch: 26, Train loss: 1.4401, Val loss: 2.7309\n",
      "Patience counter: 17\n",
      "Epoch: 27, Train loss: 1.3516, Val loss: 2.7648\n",
      "Patience counter: 18\n",
      "Epoch: 28, Train loss: 1.2945, Val loss: 2.6790\n",
      "Patience counter: 19\n",
      "Epoch: 29, Train loss: 1.2827, Val loss: 2.7543\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-05\n",
      "Epoch: 30, Train loss: 1.2450, Val loss: 2.7487\n",
      "Patience counter: 1\n",
      "Epoch: 31, Train loss: 1.1478, Val loss: 2.7506\n",
      "Patience counter: 2\n",
      "Epoch: 32, Train loss: 1.3305, Val loss: 2.7513\n",
      "Patience counter: 3\n",
      "Epoch: 33, Train loss: 1.1565, Val loss: 2.7591\n",
      "Patience counter: 4\n",
      "Epoch: 34, Train loss: 1.0591, Val loss: 2.7539\n",
      "Patience counter: 5\n",
      "Epoch: 35, Train loss: 1.1118, Val loss: 2.7634\n",
      "Patience counter: 6\n",
      "Epoch: 36, Train loss: 1.1407, Val loss: 2.7882\n",
      "Patience counter: 7\n",
      "Epoch: 37, Train loss: 1.1219, Val loss: 2.8267\n",
      "Patience counter: 8\n",
      "Epoch: 38, Train loss: 1.2576, Val loss: 2.8062\n",
      "Patience counter: 9\n",
      "Epoch: 39, Train loss: 1.2458, Val loss: 2.7999\n",
      "Patience counter: 10\n",
      "Epoch: 40, Train loss: 1.1455, Val loss: 2.7984\n",
      "Patience counter: 11\n",
      "Epoch: 41, Train loss: 1.2358, Val loss: 2.7833\n",
      "Patience counter: 12\n",
      "Epoch: 42, Train loss: 1.1528, Val loss: 2.7902\n",
      "Patience counter: 13\n",
      "Epoch: 43, Train loss: 1.1962, Val loss: 2.7779\n",
      "Patience counter: 14\n",
      "Epoch: 44, Train loss: 1.2384, Val loss: 2.7384\n",
      "Patience counter: 15\n",
      "Epoch: 45, Train loss: 1.1264, Val loss: 2.7222\n",
      "Patience counter: 16\n",
      "Epoch: 46, Train loss: 1.1555, Val loss: 2.7317\n",
      "Patience counter: 17\n",
      "Epoch: 47, Train loss: 1.2104, Val loss: 2.7734\n",
      "Patience counter: 18\n",
      "Epoch: 48, Train loss: 1.0911, Val loss: 2.7899\n",
      "Patience counter: 19\n",
      "Epoch: 49, Train loss: 1.0973, Val loss: 2.8132\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-06\n",
      "Epoch: 50, Train loss: 1.1522, Val loss: 2.8043\n",
      "Patience counter: 1\n",
      "Epoch: 51, Train loss: 1.0758, Val loss: 2.8017\n",
      "Patience counter: 2\n",
      "Epoch: 52, Train loss: 1.2093, Val loss: 2.8096\n",
      "Patience counter: 3\n",
      "Epoch: 53, Train loss: 1.1467, Val loss: 2.8056\n",
      "Patience counter: 4\n",
      "Epoch: 54, Train loss: 1.0707, Val loss: 2.7960\n",
      "Patience counter: 5\n",
      "Epoch: 55, Train loss: 1.1999, Val loss: 2.8011\n",
      "Patience counter: 6\n",
      "Epoch: 56, Train loss: 1.1082, Val loss: 2.8010\n",
      "Patience counter: 7\n",
      "Epoch: 57, Train loss: 1.0936, Val loss: 2.7904\n",
      "Patience counter: 8\n",
      "Epoch: 58, Train loss: 1.1738, Val loss: 2.7909\n",
      "Patience counter: 9\n",
      "Epoch: 59, Train loss: 1.1745, Val loss: 2.7821\n",
      "Patience counter: 10\n",
      "Epoch: 60, Train loss: 1.1550, Val loss: 2.7865\n",
      "Patience counter: 11\n",
      "Epoch: 61, Train loss: 1.1362, Val loss: 2.7904\n",
      "Patience counter: 12\n",
      "Epoch: 62, Train loss: 1.1399, Val loss: 2.7858\n",
      "Patience counter: 13\n",
      "Epoch: 63, Train loss: 1.1404, Val loss: 2.7855\n",
      "Patience counter: 14\n",
      "Epoch: 64, Train loss: 1.0389, Val loss: 2.7845\n",
      "Patience counter: 15\n",
      "Epoch: 65, Train loss: 1.0409, Val loss: 2.7859\n",
      "Patience counter: 16\n",
      "Epoch: 66, Train loss: 1.2408, Val loss: 2.7811\n",
      "Patience counter: 17\n",
      "Epoch: 67, Train loss: 1.1692, Val loss: 2.7810\n",
      "Patience counter: 18\n",
      "Epoch: 68, Train loss: 1.1268, Val loss: 2.7815\n",
      "Patience counter: 19\n",
      "Epoch: 69, Train loss: 1.3112, Val loss: 2.7447\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-07\n",
      "Epoch: 70, Train loss: 1.1444, Val loss: 2.7549\n",
      "Patience counter: 1\n",
      "Epoch: 71, Train loss: 1.1191, Val loss: 2.7620\n",
      "Patience counter: 2\n",
      "Epoch: 72, Train loss: 1.1308, Val loss: 2.7515\n",
      "Patience counter: 3\n",
      "Epoch: 73, Train loss: 1.1132, Val loss: 2.7612\n",
      "Patience counter: 4\n",
      "Epoch: 74, Train loss: 1.1912, Val loss: 2.7677\n",
      "Patience counter: 5\n",
      "Epoch: 75, Train loss: 1.0717, Val loss: 2.7663\n",
      "Patience counter: 6\n",
      "Epoch: 76, Train loss: 1.0994, Val loss: 2.7748\n",
      "Patience counter: 7\n",
      "Epoch: 77, Train loss: 1.3210, Val loss: 2.7528\n",
      "Patience counter: 8\n",
      "Epoch: 78, Train loss: 1.0522, Val loss: 2.7698\n",
      "Patience counter: 9\n",
      "Epoch: 79, Train loss: 1.1169, Val loss: 2.7713\n",
      "Patience counter: 10\n",
      "Epoch: 80, Train loss: 1.1771, Val loss: 2.7617\n",
      "Patience counter: 11\n",
      "Epoch: 81, Train loss: 1.2125, Val loss: 2.7497\n",
      "Patience counter: 12\n",
      "Epoch: 82, Train loss: 1.0653, Val loss: 2.7500\n",
      "Patience counter: 13\n",
      "Epoch: 83, Train loss: 1.0439, Val loss: 2.7598\n",
      "Patience counter: 14\n",
      "Epoch: 84, Train loss: 1.0781, Val loss: 2.7679\n",
      "Patience counter: 15\n",
      "Epoch: 85, Train loss: 1.1897, Val loss: 2.7637\n",
      "Patience counter: 16\n",
      "Epoch: 86, Train loss: 1.1495, Val loss: 2.7500\n",
      "Patience counter: 17\n",
      "Epoch: 87, Train loss: 1.1804, Val loss: 2.7713\n",
      "Patience counter: 18\n",
      "Epoch: 88, Train loss: 1.0590, Val loss: 2.7700\n",
      "Patience counter: 19\n",
      "Epoch: 89, Train loss: 1.1336, Val loss: 2.7742\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-08\n",
      "Epoch: 90, Train loss: 1.1350, Val loss: 2.7598\n",
      "Patience counter: 1\n",
      "Epoch: 91, Train loss: 1.3021, Val loss: 2.7153\n",
      "Patience counter: 2\n",
      "Epoch: 92, Train loss: 1.1172, Val loss: 2.7339\n",
      "Patience counter: 3\n",
      "Epoch: 93, Train loss: 1.1247, Val loss: 2.7465\n",
      "Patience counter: 4\n",
      "Epoch: 94, Train loss: 1.2225, Val loss: 2.7510\n",
      "Patience counter: 5\n",
      "Epoch: 95, Train loss: 1.2364, Val loss: 2.7346\n",
      "Patience counter: 6\n",
      "Epoch: 96, Train loss: 1.1606, Val loss: 2.7537\n",
      "Patience counter: 7\n",
      "Epoch: 97, Train loss: 1.1832, Val loss: 2.7565\n",
      "Patience counter: 8\n",
      "Epoch: 98, Train loss: 1.0583, Val loss: 2.7594\n",
      "Patience counter: 9\n",
      "Epoch: 99, Train loss: 1.1962, Val loss: 2.7491\n",
      "Patience counter: 10\n",
      "Epoch: 100, Train loss: 1.1974, Val loss: 2.7625\n",
      "Patience counter: 11\n",
      "Epoch: 101, Train loss: 1.1028, Val loss: 2.7688\n",
      "Patience counter: 12\n",
      "Epoch: 102, Train loss: 1.0636, Val loss: 2.7704\n",
      "Patience counter: 13\n",
      "Epoch: 103, Train loss: 1.1886, Val loss: 2.7529\n",
      "Patience counter: 14\n",
      "Epoch: 104, Train loss: 1.0779, Val loss: 2.7591\n",
      "Patience counter: 15\n",
      "Epoch: 105, Train loss: 1.0757, Val loss: 2.7681\n",
      "Patience counter: 16\n",
      "Epoch: 106, Train loss: 1.0605, Val loss: 2.7648\n",
      "Patience counter: 17\n",
      "Epoch: 107, Train loss: 1.1802, Val loss: 2.7727\n",
      "Patience counter: 18\n",
      "Epoch: 108, Train loss: 1.1665, Val loss: 2.7672\n",
      "Patience counter: 19\n",
      "Epoch: 109, Train loss: 1.2723, Val loss: 2.7662\n",
      "Patience counter: 20\n",
      "Early stopping triggered. Learning rate has reached its minimum threshold (5.000000000000001e-08).\n",
      "Test Loss: 0.6377, MSE: 0.6377, MAE: 0.6483, R2: 0.3597\n",
      "Epoch: 0, Train loss: 1.1556, Val loss: 1.7435\n",
      "Model has been saved!\n",
      "Epoch: 1, Train loss: 0.9160, Val loss: 1.5852\n",
      "Model has been saved!\n",
      "Epoch: 2, Train loss: 0.9176, Val loss: 1.3000\n",
      "Model has been saved!\n",
      "Epoch: 3, Train loss: 0.7946, Val loss: 1.1374\n",
      "Model has been saved!\n",
      "Epoch: 4, Train loss: 0.7982, Val loss: 1.1114\n",
      "Model has been saved!\n",
      "Epoch: 5, Train loss: 0.8069, Val loss: 1.1466\n",
      "Patience counter: 1\n",
      "Epoch: 6, Train loss: 0.8105, Val loss: 1.0498\n",
      "Model has been saved!\n",
      "Epoch: 7, Train loss: 0.7944, Val loss: 1.0732\n",
      "Patience counter: 1\n",
      "Epoch: 8, Train loss: 0.6896, Val loss: 1.0393\n",
      "Model has been saved!\n",
      "Epoch: 9, Train loss: 0.7977, Val loss: 1.0771\n",
      "Patience counter: 1\n",
      "Epoch: 10, Train loss: 0.7585, Val loss: 1.1139\n",
      "Patience counter: 2\n",
      "Epoch: 11, Train loss: 0.7182, Val loss: 1.0209\n",
      "Model has been saved!\n",
      "Epoch: 12, Train loss: 0.7720, Val loss: 1.0329\n",
      "Patience counter: 1\n",
      "Epoch: 13, Train loss: 0.7221, Val loss: 1.0639\n",
      "Patience counter: 2\n",
      "Epoch: 14, Train loss: 0.6911, Val loss: 1.0940\n",
      "Patience counter: 3\n",
      "Epoch: 15, Train loss: 0.7107, Val loss: 1.1627\n",
      "Patience counter: 4\n",
      "Epoch: 16, Train loss: 0.7575, Val loss: 1.0207\n",
      "Model has been saved!\n",
      "Epoch: 17, Train loss: 0.7238, Val loss: 1.0431\n",
      "Patience counter: 1\n",
      "Epoch: 18, Train loss: 0.7249, Val loss: 1.1425\n",
      "Patience counter: 2\n",
      "Epoch: 19, Train loss: 0.8014, Val loss: 1.1112\n",
      "Patience counter: 3\n",
      "Epoch: 20, Train loss: 0.7192, Val loss: 1.0257\n",
      "Patience counter: 4\n",
      "Epoch: 21, Train loss: 0.7085, Val loss: 1.0038\n",
      "Model has been saved!\n",
      "Epoch: 22, Train loss: 0.6511, Val loss: 1.0151\n",
      "Patience counter: 1\n",
      "Epoch: 23, Train loss: 0.7315, Val loss: 1.0919\n",
      "Patience counter: 2\n",
      "Epoch: 24, Train loss: 0.6302, Val loss: 1.1177\n",
      "Patience counter: 3\n",
      "Epoch: 25, Train loss: 0.7295, Val loss: 1.1787\n",
      "Patience counter: 4\n",
      "Epoch: 26, Train loss: 0.6499, Val loss: 1.0346\n",
      "Patience counter: 5\n",
      "Epoch: 27, Train loss: 0.6536, Val loss: 1.0599\n",
      "Patience counter: 6\n",
      "Epoch: 28, Train loss: 0.6728, Val loss: 1.0869\n",
      "Patience counter: 7\n",
      "Epoch: 29, Train loss: 0.6407, Val loss: 1.1261\n",
      "Patience counter: 8\n",
      "Epoch: 30, Train loss: 0.6233, Val loss: 1.0959\n",
      "Patience counter: 9\n",
      "Epoch: 31, Train loss: 0.5772, Val loss: 1.0363\n",
      "Patience counter: 10\n",
      "Epoch: 32, Train loss: 0.6384, Val loss: 1.0597\n",
      "Patience counter: 11\n",
      "Epoch: 33, Train loss: 0.6149, Val loss: 1.0451\n",
      "Patience counter: 12\n",
      "Epoch: 34, Train loss: 0.6134, Val loss: 1.0745\n",
      "Patience counter: 13\n",
      "Epoch: 35, Train loss: 0.5887, Val loss: 1.0204\n",
      "Patience counter: 14\n",
      "Epoch: 36, Train loss: 0.6301, Val loss: 1.0372\n",
      "Patience counter: 15\n",
      "Epoch: 37, Train loss: 0.6491, Val loss: 1.1352\n",
      "Patience counter: 16\n",
      "Epoch: 38, Train loss: 0.6080, Val loss: 1.1635\n",
      "Patience counter: 17\n",
      "Epoch: 39, Train loss: 0.6140, Val loss: 1.2044\n",
      "Patience counter: 18\n",
      "Epoch: 40, Train loss: 0.6184, Val loss: 1.0379\n",
      "Patience counter: 19\n",
      "Epoch: 41, Train loss: 0.6211, Val loss: 1.0598\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-05\n",
      "Epoch: 42, Train loss: 0.5541, Val loss: 1.0710\n",
      "Patience counter: 1\n",
      "Epoch: 43, Train loss: 0.5775, Val loss: 1.0688\n",
      "Patience counter: 2\n",
      "Epoch: 44, Train loss: 0.5611, Val loss: 1.0778\n",
      "Patience counter: 3\n",
      "Epoch: 45, Train loss: 0.5812, Val loss: 1.0578\n",
      "Patience counter: 4\n",
      "Epoch: 46, Train loss: 0.5703, Val loss: 1.0766\n",
      "Patience counter: 5\n",
      "Epoch: 47, Train loss: 0.5665, Val loss: 1.0857\n",
      "Patience counter: 6\n",
      "Epoch: 48, Train loss: 0.5701, Val loss: 1.0727\n",
      "Patience counter: 7\n",
      "Epoch: 49, Train loss: 0.5476, Val loss: 1.0780\n",
      "Patience counter: 8\n",
      "Epoch: 50, Train loss: 0.5607, Val loss: 1.0676\n",
      "Patience counter: 9\n",
      "Epoch: 51, Train loss: 0.5623, Val loss: 1.0612\n",
      "Patience counter: 10\n",
      "Epoch: 52, Train loss: 0.5423, Val loss: 1.0530\n",
      "Patience counter: 11\n",
      "Epoch: 53, Train loss: 0.5822, Val loss: 1.0808\n",
      "Patience counter: 12\n",
      "Epoch: 54, Train loss: 0.5903, Val loss: 1.0756\n",
      "Patience counter: 13\n",
      "Epoch: 55, Train loss: 0.5650, Val loss: 1.0811\n",
      "Patience counter: 14\n",
      "Epoch: 56, Train loss: 0.5275, Val loss: 1.0811\n",
      "Patience counter: 15\n",
      "Epoch: 57, Train loss: 0.5605, Val loss: 1.0725\n",
      "Patience counter: 16\n",
      "Epoch: 58, Train loss: 0.5931, Val loss: 1.0626\n",
      "Patience counter: 17\n",
      "Epoch: 59, Train loss: 0.5562, Val loss: 1.0707\n",
      "Patience counter: 18\n",
      "Epoch: 60, Train loss: 0.5216, Val loss: 1.0428\n",
      "Patience counter: 19\n",
      "Epoch: 61, Train loss: 0.5168, Val loss: 1.0684\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-06\n",
      "Epoch: 62, Train loss: 0.5381, Val loss: 1.0689\n",
      "Patience counter: 1\n",
      "Epoch: 63, Train loss: 0.4971, Val loss: 1.0699\n",
      "Patience counter: 2\n",
      "Epoch: 64, Train loss: 0.5201, Val loss: 1.0666\n",
      "Patience counter: 3\n",
      "Epoch: 65, Train loss: 0.5293, Val loss: 1.0664\n",
      "Patience counter: 4\n",
      "Epoch: 66, Train loss: 0.5475, Val loss: 1.0624\n",
      "Patience counter: 5\n",
      "Epoch: 67, Train loss: 0.5492, Val loss: 1.0649\n",
      "Patience counter: 6\n",
      "Epoch: 68, Train loss: 0.5443, Val loss: 1.0581\n",
      "Patience counter: 7\n",
      "Epoch: 69, Train loss: 0.5355, Val loss: 1.0596\n",
      "Patience counter: 8\n",
      "Epoch: 70, Train loss: 0.5623, Val loss: 1.0604\n",
      "Patience counter: 9\n",
      "Epoch: 71, Train loss: 0.5531, Val loss: 1.0548\n",
      "Patience counter: 10\n",
      "Epoch: 72, Train loss: 0.5252, Val loss: 1.0594\n",
      "Patience counter: 11\n",
      "Epoch: 73, Train loss: 0.5050, Val loss: 1.0571\n",
      "Patience counter: 12\n",
      "Epoch: 74, Train loss: 0.5329, Val loss: 1.0554\n",
      "Patience counter: 13\n",
      "Epoch: 75, Train loss: 0.5375, Val loss: 1.0582\n",
      "Patience counter: 14\n",
      "Epoch: 76, Train loss: 0.5101, Val loss: 1.0629\n",
      "Patience counter: 15\n",
      "Epoch: 77, Train loss: 0.5286, Val loss: 1.0649\n",
      "Patience counter: 16\n",
      "Epoch: 78, Train loss: 0.5309, Val loss: 1.0622\n",
      "Patience counter: 17\n",
      "Epoch: 79, Train loss: 0.5552, Val loss: 1.0571\n",
      "Patience counter: 18\n",
      "Epoch: 80, Train loss: 0.5460, Val loss: 1.0599\n",
      "Patience counter: 19\n",
      "Epoch: 81, Train loss: 0.5501, Val loss: 1.0634\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-07\n",
      "Epoch: 82, Train loss: 0.5116, Val loss: 1.0666\n",
      "Patience counter: 1\n",
      "Epoch: 83, Train loss: 0.5596, Val loss: 1.0639\n",
      "Patience counter: 2\n",
      "Epoch: 84, Train loss: 0.5280, Val loss: 1.0624\n",
      "Patience counter: 3\n",
      "Epoch: 85, Train loss: 0.5600, Val loss: 1.0674\n",
      "Patience counter: 4\n",
      "Epoch: 86, Train loss: 0.5623, Val loss: 1.0622\n",
      "Patience counter: 5\n",
      "Epoch: 87, Train loss: 0.5437, Val loss: 1.0624\n",
      "Patience counter: 6\n",
      "Epoch: 88, Train loss: 0.5194, Val loss: 1.0641\n",
      "Patience counter: 7\n",
      "Epoch: 89, Train loss: 0.4994, Val loss: 1.0672\n",
      "Patience counter: 8\n",
      "Epoch: 90, Train loss: 0.5541, Val loss: 1.0619\n",
      "Patience counter: 9\n",
      "Epoch: 91, Train loss: 0.5547, Val loss: 1.0647\n",
      "Patience counter: 10\n",
      "Epoch: 92, Train loss: 0.5488, Val loss: 1.0638\n",
      "Patience counter: 11\n",
      "Epoch: 93, Train loss: 0.5710, Val loss: 1.0672\n",
      "Patience counter: 12\n",
      "Epoch: 94, Train loss: 0.5411, Val loss: 1.0666\n",
      "Patience counter: 13\n",
      "Epoch: 95, Train loss: 0.5336, Val loss: 1.0624\n",
      "Patience counter: 14\n",
      "Epoch: 96, Train loss: 0.5059, Val loss: 1.0615\n",
      "Patience counter: 15\n",
      "Epoch: 97, Train loss: 0.5476, Val loss: 1.0624\n",
      "Patience counter: 16\n",
      "Epoch: 98, Train loss: 0.5692, Val loss: 1.0622\n",
      "Patience counter: 17\n",
      "Epoch: 99, Train loss: 0.5456, Val loss: 1.0636\n",
      "Patience counter: 18\n",
      "Epoch: 100, Train loss: 0.5934, Val loss: 1.0631\n",
      "Patience counter: 19\n",
      "Epoch: 101, Train loss: 0.5576, Val loss: 1.0601\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-08\n",
      "Epoch: 102, Train loss: 0.5566, Val loss: 1.0581\n",
      "Patience counter: 1\n",
      "Epoch: 103, Train loss: 0.5825, Val loss: 1.0609\n",
      "Patience counter: 2\n",
      "Epoch: 104, Train loss: 0.5788, Val loss: 1.0629\n",
      "Patience counter: 3\n",
      "Epoch: 105, Train loss: 0.5165, Val loss: 1.0650\n",
      "Patience counter: 4\n",
      "Epoch: 106, Train loss: 0.5599, Val loss: 1.0604\n",
      "Patience counter: 5\n",
      "Epoch: 107, Train loss: 0.5705, Val loss: 1.0598\n",
      "Patience counter: 6\n",
      "Epoch: 108, Train loss: 0.5254, Val loss: 1.0663\n",
      "Patience counter: 7\n",
      "Epoch: 109, Train loss: 0.5510, Val loss: 1.0616\n",
      "Patience counter: 8\n",
      "Epoch: 110, Train loss: 0.5327, Val loss: 1.0619\n",
      "Patience counter: 9\n",
      "Epoch: 111, Train loss: 0.5020, Val loss: 1.0612\n",
      "Patience counter: 10\n",
      "Epoch: 112, Train loss: 0.5041, Val loss: 1.0629\n",
      "Patience counter: 11\n",
      "Epoch: 113, Train loss: 0.5280, Val loss: 1.0604\n",
      "Patience counter: 12\n",
      "Epoch: 114, Train loss: 0.5189, Val loss: 1.0596\n",
      "Patience counter: 13\n",
      "Epoch: 115, Train loss: 0.5209, Val loss: 1.0592\n",
      "Patience counter: 14\n",
      "Epoch: 116, Train loss: 0.5705, Val loss: 1.0607\n",
      "Patience counter: 15\n",
      "Epoch: 117, Train loss: 0.4833, Val loss: 1.0578\n",
      "Patience counter: 16\n",
      "Epoch: 118, Train loss: 0.5237, Val loss: 1.0623\n",
      "Patience counter: 17\n",
      "Epoch: 119, Train loss: 0.5517, Val loss: 1.0646\n",
      "Patience counter: 18\n",
      "Epoch: 120, Train loss: 0.5177, Val loss: 1.0644\n",
      "Patience counter: 19\n",
      "Epoch: 121, Train loss: 0.5632, Val loss: 1.0653\n",
      "Patience counter: 20\n",
      "Early stopping triggered. Learning rate has reached its minimum threshold (5.000000000000001e-08).\n",
      "Test Loss: 0.6264, MSE: 0.6123, MAE: 0.6059, R2: 0.3023\n"
     ]
    }
   ],
   "source": [
    "# 训练模型，设置epoch数为100\n",
    "epochs = 200\n",
    "\n",
    "# 阴离子氧化势GAT模型\n",
    "anion_ox_train_losses_gcn, anion_ox_val_losses_gcn, anion_ox_test_pred_gcn, anion_ox_test_true_gcn, anion_ox_test_mse_gcn, anion_ox_test_mae_gcn, anion_ox_test_r2_gcn = train_epochs(\n",
    "    0, epochs, model_anion_ox_GCN, anion_ox_train_loader, anion_ox_val_loader, anion_ox_test_loader, \"anion_ox_GCN_model.pt\"\n",
    ")\n",
    "\n",
    "# 阳离子还原势GAT模型\n",
    "cation_red_train_losses_gcn, cation_red_val_losses_gcn, cation_red_test_pred_gcn, cation_red_test_true_gcn, cation_red_test_mse_gcn, cation_red_test_mae_gcn, cation_red_test_r2_gcn = train_epochs(\n",
    "    0, epochs, model_cation_red_GCN, cation_red_train_loader, cation_red_val_loader, cation_red_test_loader, \"cation_red_GCN_model.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15819cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 3.4408, Val loss: 3.3737\n",
      "Model has been saved!\n",
      "Epoch: 1, Train loss: 2.2711, Val loss: 1.9721\n",
      "Model has been saved!\n",
      "Epoch: 2, Train loss: 2.0327, Val loss: 1.6317\n",
      "Model has been saved!\n",
      "Epoch: 3, Train loss: 2.0260, Val loss: 1.9676\n",
      "Patience counter: 1\n",
      "Epoch: 4, Train loss: 1.9163, Val loss: 1.3783\n",
      "Model has been saved!\n",
      "Epoch: 5, Train loss: 1.9274, Val loss: 2.3452\n",
      "Patience counter: 1\n",
      "Epoch: 6, Train loss: 1.7109, Val loss: 1.3619\n",
      "Model has been saved!\n",
      "Epoch: 7, Train loss: 1.7435, Val loss: 3.2062\n",
      "Patience counter: 1\n",
      "Epoch: 8, Train loss: 1.8608, Val loss: 1.7715\n",
      "Patience counter: 2\n",
      "Epoch: 9, Train loss: 1.5867, Val loss: 1.6533\n",
      "Patience counter: 3\n",
      "Epoch: 10, Train loss: 1.5599, Val loss: 2.0043\n",
      "Patience counter: 4\n",
      "Epoch: 11, Train loss: 1.6765, Val loss: 2.0675\n",
      "Patience counter: 5\n",
      "Epoch: 12, Train loss: 1.5098, Val loss: 1.3584\n",
      "Model has been saved!\n",
      "Epoch: 13, Train loss: 1.5162, Val loss: 1.7687\n",
      "Patience counter: 1\n",
      "Epoch: 14, Train loss: 1.3958, Val loss: 2.1377\n",
      "Patience counter: 2\n",
      "Epoch: 15, Train loss: 1.3230, Val loss: 1.5292\n",
      "Patience counter: 3\n",
      "Epoch: 16, Train loss: 1.3534, Val loss: 1.8057\n",
      "Patience counter: 4\n",
      "Epoch: 17, Train loss: 1.4772, Val loss: 1.8649\n",
      "Patience counter: 5\n",
      "Epoch: 18, Train loss: 1.3287, Val loss: 1.5304\n",
      "Patience counter: 6\n",
      "Epoch: 19, Train loss: 1.3659, Val loss: 2.4897\n",
      "Patience counter: 7\n",
      "Epoch: 20, Train loss: 1.2005, Val loss: 1.5310\n",
      "Patience counter: 8\n",
      "Epoch: 21, Train loss: 1.3363, Val loss: 1.5704\n",
      "Patience counter: 9\n",
      "Epoch: 22, Train loss: 1.2378, Val loss: 1.8098\n",
      "Patience counter: 10\n",
      "Epoch: 23, Train loss: 1.1559, Val loss: 1.6268\n",
      "Patience counter: 11\n",
      "Epoch: 24, Train loss: 1.1630, Val loss: 1.3932\n",
      "Patience counter: 12\n",
      "Epoch: 25, Train loss: 1.1796, Val loss: 1.8754\n",
      "Patience counter: 13\n",
      "Epoch: 26, Train loss: 1.3027, Val loss: 1.4032\n",
      "Patience counter: 14\n",
      "Epoch: 27, Train loss: 1.2113, Val loss: 1.3923\n",
      "Patience counter: 15\n",
      "Epoch: 28, Train loss: 1.2169, Val loss: 1.5613\n",
      "Patience counter: 16\n",
      "Epoch: 29, Train loss: 1.3027, Val loss: 2.5329\n",
      "Patience counter: 17\n",
      "Epoch: 30, Train loss: 1.1568, Val loss: 1.5359\n",
      "Patience counter: 18\n",
      "Epoch: 31, Train loss: 1.1937, Val loss: 2.6483\n",
      "Patience counter: 19\n",
      "Epoch: 32, Train loss: 1.2655, Val loss: 1.6820\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-05\n",
      "Epoch: 33, Train loss: 1.0615, Val loss: 1.8624\n",
      "Patience counter: 1\n",
      "Epoch: 34, Train loss: 1.0655, Val loss: 1.8874\n",
      "Patience counter: 2\n",
      "Epoch: 35, Train loss: 1.0374, Val loss: 1.7907\n",
      "Patience counter: 3\n",
      "Epoch: 36, Train loss: 1.0479, Val loss: 1.7331\n",
      "Patience counter: 4\n",
      "Epoch: 37, Train loss: 1.1104, Val loss: 1.7285\n",
      "Patience counter: 5\n",
      "Epoch: 38, Train loss: 1.0498, Val loss: 1.6418\n",
      "Patience counter: 6\n",
      "Epoch: 39, Train loss: 1.0394, Val loss: 1.8188\n",
      "Patience counter: 7\n",
      "Epoch: 40, Train loss: 1.0153, Val loss: 1.5909\n",
      "Patience counter: 8\n",
      "Epoch: 41, Train loss: 1.0055, Val loss: 1.7374\n",
      "Patience counter: 9\n",
      "Epoch: 42, Train loss: 1.0227, Val loss: 1.6944\n",
      "Patience counter: 10\n",
      "Epoch: 43, Train loss: 0.9955, Val loss: 1.6069\n",
      "Patience counter: 11\n",
      "Epoch: 44, Train loss: 0.9750, Val loss: 1.6828\n",
      "Patience counter: 12\n",
      "Epoch: 45, Train loss: 1.0291, Val loss: 1.5632\n",
      "Patience counter: 13\n",
      "Epoch: 46, Train loss: 0.9668, Val loss: 1.7475\n",
      "Patience counter: 14\n",
      "Epoch: 47, Train loss: 1.0199, Val loss: 1.7242\n",
      "Patience counter: 15\n",
      "Epoch: 48, Train loss: 0.9770, Val loss: 1.3915\n",
      "Patience counter: 16\n",
      "Epoch: 49, Train loss: 0.9504, Val loss: 1.5932\n",
      "Patience counter: 17\n",
      "Epoch: 50, Train loss: 0.9941, Val loss: 1.7198\n",
      "Patience counter: 18\n",
      "Epoch: 51, Train loss: 0.9645, Val loss: 1.6635\n",
      "Patience counter: 19\n",
      "Epoch: 52, Train loss: 1.0385, Val loss: 1.6400\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-06\n",
      "Epoch: 53, Train loss: 0.9857, Val loss: 1.6447\n",
      "Patience counter: 1\n",
      "Epoch: 54, Train loss: 1.0026, Val loss: 1.6837\n",
      "Patience counter: 2\n",
      "Epoch: 55, Train loss: 0.9232, Val loss: 1.6882\n",
      "Patience counter: 3\n",
      "Epoch: 56, Train loss: 0.8963, Val loss: 1.6864\n",
      "Patience counter: 4\n",
      "Epoch: 57, Train loss: 0.9746, Val loss: 1.6448\n",
      "Patience counter: 5\n",
      "Epoch: 58, Train loss: 0.9394, Val loss: 1.6757\n",
      "Patience counter: 6\n",
      "Epoch: 59, Train loss: 0.9915, Val loss: 1.6864\n",
      "Patience counter: 7\n",
      "Epoch: 60, Train loss: 1.0089, Val loss: 1.6653\n",
      "Patience counter: 8\n",
      "Epoch: 61, Train loss: 0.9524, Val loss: 1.6239\n",
      "Patience counter: 9\n",
      "Epoch: 62, Train loss: 0.8856, Val loss: 1.6690\n",
      "Patience counter: 10\n",
      "Epoch: 63, Train loss: 0.9654, Val loss: 1.6915\n",
      "Patience counter: 11\n",
      "Epoch: 64, Train loss: 0.9726, Val loss: 1.6288\n",
      "Patience counter: 12\n",
      "Epoch: 65, Train loss: 0.9231, Val loss: 1.6967\n",
      "Patience counter: 13\n",
      "Epoch: 66, Train loss: 0.9721, Val loss: 1.6825\n",
      "Patience counter: 14\n",
      "Epoch: 67, Train loss: 0.9685, Val loss: 1.6790\n",
      "Patience counter: 15\n",
      "Epoch: 68, Train loss: 0.9802, Val loss: 1.6516\n",
      "Patience counter: 16\n",
      "Epoch: 69, Train loss: 0.9618, Val loss: 1.7079\n",
      "Patience counter: 17\n",
      "Epoch: 70, Train loss: 1.0112, Val loss: 1.6905\n",
      "Patience counter: 18\n",
      "Epoch: 71, Train loss: 0.9571, Val loss: 1.6877\n",
      "Patience counter: 19\n",
      "Epoch: 72, Train loss: 0.9340, Val loss: 1.6438\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-07\n",
      "Epoch: 73, Train loss: 0.9396, Val loss: 1.6406\n",
      "Patience counter: 1\n",
      "Epoch: 74, Train loss: 0.9574, Val loss: 1.6951\n",
      "Patience counter: 2\n",
      "Epoch: 75, Train loss: 0.9652, Val loss: 1.7005\n",
      "Patience counter: 3\n",
      "Epoch: 76, Train loss: 0.9037, Val loss: 1.6594\n",
      "Patience counter: 4\n",
      "Epoch: 77, Train loss: 0.9436, Val loss: 1.6561\n",
      "Patience counter: 5\n",
      "Epoch: 78, Train loss: 0.9903, Val loss: 1.6736\n",
      "Patience counter: 6\n",
      "Epoch: 79, Train loss: 1.0408, Val loss: 1.7033\n",
      "Patience counter: 7\n",
      "Epoch: 80, Train loss: 1.0419, Val loss: 1.6959\n",
      "Patience counter: 8\n",
      "Epoch: 81, Train loss: 0.9849, Val loss: 1.7122\n",
      "Patience counter: 9\n",
      "Epoch: 82, Train loss: 0.9311, Val loss: 1.7019\n",
      "Patience counter: 10\n",
      "Epoch: 83, Train loss: 0.9984, Val loss: 1.6744\n",
      "Patience counter: 11\n",
      "Epoch: 84, Train loss: 0.9792, Val loss: 1.6464\n",
      "Patience counter: 12\n",
      "Epoch: 85, Train loss: 1.0300, Val loss: 1.6912\n",
      "Patience counter: 13\n",
      "Epoch: 86, Train loss: 0.9447, Val loss: 1.6596\n",
      "Patience counter: 14\n",
      "Epoch: 87, Train loss: 1.0237, Val loss: 1.7223\n",
      "Patience counter: 15\n",
      "Epoch: 88, Train loss: 0.9542, Val loss: 1.6426\n",
      "Patience counter: 16\n",
      "Epoch: 89, Train loss: 0.9992, Val loss: 1.6415\n",
      "Patience counter: 17\n",
      "Epoch: 90, Train loss: 0.9469, Val loss: 1.7073\n",
      "Patience counter: 18\n",
      "Epoch: 91, Train loss: 0.9538, Val loss: 1.6902\n",
      "Patience counter: 19\n",
      "Epoch: 92, Train loss: 0.9508, Val loss: 1.6767\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-08\n",
      "Epoch: 93, Train loss: 0.9959, Val loss: 1.6862\n",
      "Patience counter: 1\n",
      "Epoch: 94, Train loss: 0.9678, Val loss: 1.6917\n",
      "Patience counter: 2\n",
      "Epoch: 95, Train loss: 0.8494, Val loss: 1.6942\n",
      "Patience counter: 3\n",
      "Epoch: 96, Train loss: 0.9574, Val loss: 1.6785\n",
      "Patience counter: 4\n",
      "Epoch: 97, Train loss: 1.0247, Val loss: 1.6813\n",
      "Patience counter: 5\n",
      "Epoch: 98, Train loss: 0.9462, Val loss: 1.6812\n",
      "Patience counter: 6\n",
      "Epoch: 99, Train loss: 1.0075, Val loss: 1.6941\n",
      "Patience counter: 7\n",
      "Epoch: 100, Train loss: 0.9227, Val loss: 1.6810\n",
      "Patience counter: 8\n",
      "Epoch: 101, Train loss: 1.0358, Val loss: 1.6890\n",
      "Patience counter: 9\n",
      "Epoch: 102, Train loss: 0.9733, Val loss: 1.6881\n",
      "Patience counter: 10\n",
      "Epoch: 103, Train loss: 0.9692, Val loss: 1.7037\n",
      "Patience counter: 11\n",
      "Epoch: 104, Train loss: 0.9942, Val loss: 1.7306\n",
      "Patience counter: 12\n",
      "Epoch: 105, Train loss: 0.8840, Val loss: 1.6541\n",
      "Patience counter: 13\n",
      "Epoch: 106, Train loss: 0.9958, Val loss: 1.7164\n",
      "Patience counter: 14\n",
      "Epoch: 107, Train loss: 0.9256, Val loss: 1.6696\n",
      "Patience counter: 15\n",
      "Epoch: 108, Train loss: 0.9636, Val loss: 1.7090\n",
      "Patience counter: 16\n",
      "Epoch: 109, Train loss: 0.8986, Val loss: 1.6677\n",
      "Patience counter: 17\n",
      "Epoch: 110, Train loss: 1.0095, Val loss: 1.6802\n",
      "Patience counter: 18\n",
      "Epoch: 111, Train loss: 1.0098, Val loss: 1.6689\n",
      "Patience counter: 19\n",
      "Epoch: 112, Train loss: 0.9140, Val loss: 1.7038\n",
      "Patience counter: 20\n",
      "Early stopping triggered. Learning rate has reached its minimum threshold (5.000000000000001e-08).\n",
      "Test Loss: 1.3122, MSE: 1.3343, MAE: 0.9154, R2: 0.5478\n"
     ]
    }
   ],
   "source": [
    "# 训练模型，设置epoch数为100\n",
    "epochs = 200\n",
    "\n",
    "# 阳离子还原势GAT模型\n",
    "IL_ECW_train_losses_gcn, IL_ECW_val_losses_gcn, IL_ECW_test_pred_gcn, IL_ECW_test_true_gcn, IL_ECW_test_mse_gcn, IL_ECW_test_mae_gcn, IL_ECW_test_r2_gcn = train_epochs(\n",
    "    0, epochs, model_IL_ECW_GCN, IL_ECW_train_loader, IL_ECW_val_loader, IL_ECW_test_loader, \"IL_ECW_GCN_model.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae75a44",
   "metadata": {},
   "source": [
    "# MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7888391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 115869.9446, Val loss: 115048.6406\n",
      "Model has been saved!\n",
      "Epoch: 1, Train loss: 115499.3527, Val loss: 114616.5273\n",
      "Model has been saved!\n",
      "Epoch: 2, Train loss: 114909.9585, Val loss: 114026.6302\n",
      "Model has been saved!\n",
      "Epoch: 3, Train loss: 114435.5791, Val loss: 113571.4141\n",
      "Model has been saved!\n",
      "Epoch: 4, Train loss: 113791.2859, Val loss: 112932.7487\n",
      "Model has been saved!\n",
      "Epoch: 5, Train loss: 112985.2383, Val loss: 112124.9674\n",
      "Model has been saved!\n",
      "Epoch: 6, Train loss: 112215.6910, Val loss: 111131.8424\n",
      "Model has been saved!\n",
      "Epoch: 7, Train loss: 111409.5277, Val loss: 110628.0052\n",
      "Model has been saved!\n",
      "Epoch: 8, Train loss: 110374.5305, Val loss: 109699.7474\n",
      "Model has been saved!\n",
      "Epoch: 9, Train loss: 109443.7474, Val loss: 108852.0078\n",
      "Model has been saved!\n",
      "Epoch: 10, Train loss: 108369.2333, Val loss: 107850.0508\n",
      "Model has been saved!\n",
      "Epoch: 11, Train loss: 107061.9100, Val loss: 106394.1940\n",
      "Model has been saved!\n",
      "Epoch: 12, Train loss: 105758.2801, Val loss: 105147.4922\n",
      "Model has been saved!\n",
      "Epoch: 13, Train loss: 104596.5199, Val loss: 104046.3372\n",
      "Model has been saved!\n",
      "Epoch: 14, Train loss: 103094.4208, Val loss: 102738.0026\n",
      "Model has been saved!\n",
      "Epoch: 15, Train loss: 101538.8984, Val loss: 101709.1510\n",
      "Model has been saved!\n",
      "Epoch: 16, Train loss: 100093.2111, Val loss: 100063.4583\n",
      "Model has been saved!\n",
      "Epoch: 17, Train loss: 98349.9660, Val loss: 98680.7904\n",
      "Model has been saved!\n",
      "Epoch: 18, Train loss: 96697.1775, Val loss: 96674.4935\n",
      "Model has been saved!\n",
      "Epoch: 19, Train loss: 94848.5683, Val loss: 94952.1680\n",
      "Model has been saved!\n",
      "Epoch: 20, Train loss: 93218.5536, Val loss: 92941.2956\n",
      "Model has been saved!\n",
      "Epoch: 21, Train loss: 91458.7106, Val loss: 91655.0898\n",
      "Model has been saved!\n",
      "Epoch: 22, Train loss: 89529.0484, Val loss: 90619.8385\n",
      "Model has been saved!\n",
      "Epoch: 23, Train loss: 87769.0374, Val loss: 87389.9271\n",
      "Model has been saved!\n",
      "Epoch: 24, Train loss: 85606.0558, Val loss: 86548.1263\n",
      "Model has been saved!\n",
      "Epoch: 25, Train loss: 83485.8958, Val loss: 84143.3008\n",
      "Model has been saved!\n",
      "Epoch: 26, Train loss: 81777.2013, Val loss: 82543.6784\n",
      "Model has been saved!\n",
      "Epoch: 27, Train loss: 79764.0826, Val loss: 80987.8411\n",
      "Model has been saved!\n",
      "Epoch: 28, Train loss: 77464.5190, Val loss: 79245.8867\n",
      "Model has been saved!\n",
      "Epoch: 29, Train loss: 75357.2175, Val loss: 76849.4336\n",
      "Model has been saved!\n",
      "Epoch: 30, Train loss: 73214.3798, Val loss: 76466.8438\n",
      "Model has been saved!\n",
      "Epoch: 31, Train loss: 71414.6323, Val loss: 73864.3802\n",
      "Model has been saved!\n",
      "Epoch: 32, Train loss: 69338.0600, Val loss: 71097.6823\n",
      "Model has been saved!\n",
      "Epoch: 33, Train loss: 67501.7278, Val loss: 69836.2943\n",
      "Model has been saved!\n",
      "Epoch: 34, Train loss: 64804.9900, Val loss: 67825.3607\n",
      "Model has been saved!\n",
      "Epoch: 35, Train loss: 63040.5922, Val loss: 66605.5514\n",
      "Model has been saved!\n",
      "Epoch: 36, Train loss: 60939.3586, Val loss: 63900.8216\n",
      "Model has been saved!\n",
      "Epoch: 37, Train loss: 59316.5204, Val loss: 61556.0312\n",
      "Model has been saved!\n",
      "Epoch: 38, Train loss: 56678.2291, Val loss: 59024.0378\n",
      "Model has been saved!\n",
      "Epoch: 39, Train loss: 54818.0589, Val loss: 58802.5514\n",
      "Model has been saved!\n",
      "Epoch: 40, Train loss: 53348.5894, Val loss: 56648.6960\n",
      "Model has been saved!\n",
      "Epoch: 41, Train loss: 51159.4305, Val loss: 54908.4967\n",
      "Model has been saved!\n",
      "Epoch: 42, Train loss: 49236.5987, Val loss: 51803.7565\n",
      "Model has been saved!\n",
      "Epoch: 43, Train loss: 47374.7931, Val loss: 51264.7760\n",
      "Model has been saved!\n",
      "Epoch: 44, Train loss: 45507.1735, Val loss: 47794.2396\n",
      "Model has been saved!\n",
      "Epoch: 45, Train loss: 43919.5367, Val loss: 47756.2109\n",
      "Model has been saved!\n",
      "Epoch: 46, Train loss: 42316.2162, Val loss: 46344.3600\n",
      "Model has been saved!\n",
      "Epoch: 47, Train loss: 40384.7175, Val loss: 44126.0931\n",
      "Model has been saved!\n",
      "Epoch: 48, Train loss: 38537.9791, Val loss: 43334.8997\n",
      "Model has been saved!\n",
      "Epoch: 49, Train loss: 37627.2058, Val loss: 41503.6289\n",
      "Model has been saved!\n",
      "Epoch: 50, Train loss: 36133.5366, Val loss: 40107.4219\n",
      "Model has been saved!\n",
      "Epoch: 51, Train loss: 33609.3777, Val loss: 37654.6576\n",
      "Model has been saved!\n",
      "Epoch: 52, Train loss: 32188.5399, Val loss: 36212.5215\n",
      "Model has been saved!\n",
      "Epoch: 53, Train loss: 30717.4437, Val loss: 35746.5801\n",
      "Model has been saved!\n",
      "Epoch: 54, Train loss: 29020.1795, Val loss: 33498.6738\n",
      "Model has been saved!\n",
      "Epoch: 55, Train loss: 27717.0590, Val loss: 31984.3701\n",
      "Model has been saved!\n",
      "Epoch: 56, Train loss: 26284.5687, Val loss: 30693.8721\n",
      "Model has been saved!\n",
      "Epoch: 57, Train loss: 24898.0285, Val loss: 28666.0632\n",
      "Model has been saved!\n",
      "Epoch: 58, Train loss: 23862.4171, Val loss: 27438.4746\n",
      "Model has been saved!\n",
      "Epoch: 59, Train loss: 22458.0088, Val loss: 26614.5407\n",
      "Model has been saved!\n",
      "Epoch: 60, Train loss: 21305.8252, Val loss: 25702.0801\n",
      "Model has been saved!\n",
      "Epoch: 61, Train loss: 20315.7434, Val loss: 24529.1696\n",
      "Model has been saved!\n",
      "Epoch: 62, Train loss: 19656.4573, Val loss: 22745.6589\n",
      "Model has been saved!\n",
      "Epoch: 63, Train loss: 17932.8834, Val loss: 22086.6748\n",
      "Model has been saved!\n",
      "Epoch: 64, Train loss: 16728.5878, Val loss: 21374.2904\n",
      "Model has been saved!\n",
      "Epoch: 65, Train loss: 16293.9464, Val loss: 20213.8337\n",
      "Model has been saved!\n",
      "Epoch: 66, Train loss: 15933.0856, Val loss: 19019.7489\n",
      "Model has been saved!\n",
      "Epoch: 67, Train loss: 14702.4458, Val loss: 18089.7435\n",
      "Model has been saved!\n",
      "Epoch: 68, Train loss: 14123.4212, Val loss: 17107.0522\n",
      "Model has been saved!\n",
      "Epoch: 69, Train loss: 13275.5314, Val loss: 16759.3763\n",
      "Model has been saved!\n",
      "Epoch: 70, Train loss: 12007.3845, Val loss: 15050.3296\n",
      "Model has been saved!\n",
      "Epoch: 71, Train loss: 11353.0075, Val loss: 13754.0498\n",
      "Model has been saved!\n",
      "Epoch: 72, Train loss: 10799.1184, Val loss: 13465.5716\n",
      "Model has been saved!\n",
      "Epoch: 73, Train loss: 10034.3831, Val loss: 12389.0428\n",
      "Model has been saved!\n",
      "Epoch: 74, Train loss: 9959.2336, Val loss: 12296.8885\n",
      "Model has been saved!\n",
      "Epoch: 75, Train loss: 9233.5476, Val loss: 12079.6203\n",
      "Model has been saved!\n",
      "Epoch: 76, Train loss: 8634.1903, Val loss: 10990.7023\n",
      "Model has been saved!\n",
      "Epoch: 77, Train loss: 8153.1560, Val loss: 10469.3228\n",
      "Model has been saved!\n",
      "Epoch: 78, Train loss: 7827.6041, Val loss: 10212.0452\n",
      "Model has been saved!\n",
      "Epoch: 79, Train loss: 7449.7394, Val loss: 9532.5190\n",
      "Model has been saved!\n",
      "Epoch: 80, Train loss: 7243.3969, Val loss: 9059.1165\n",
      "Model has been saved!\n",
      "Epoch: 81, Train loss: 6690.5250, Val loss: 8732.1482\n",
      "Model has been saved!\n",
      "Epoch: 82, Train loss: 6952.0010, Val loss: 8279.0324\n",
      "Model has been saved!\n",
      "Epoch: 83, Train loss: 5897.6503, Val loss: 7738.7030\n",
      "Model has been saved!\n",
      "Epoch: 84, Train loss: 5846.9570, Val loss: 7076.8209\n",
      "Model has been saved!\n",
      "Epoch: 85, Train loss: 5130.8059, Val loss: 6934.6605\n",
      "Model has been saved!\n",
      "Epoch: 86, Train loss: 5199.2077, Val loss: 7104.2542\n",
      "Patience counter: 1\n",
      "Epoch: 87, Train loss: 4803.9420, Val loss: 7076.3513\n",
      "Patience counter: 2\n",
      "Epoch: 88, Train loss: 4691.2343, Val loss: 6914.7491\n",
      "Model has been saved!\n",
      "Epoch: 89, Train loss: 4765.0816, Val loss: 6429.5846\n",
      "Model has been saved!\n",
      "Epoch: 90, Train loss: 4016.7226, Val loss: 6406.0463\n",
      "Model has been saved!\n",
      "Epoch: 91, Train loss: 3906.2755, Val loss: 6035.3188\n",
      "Model has been saved!\n",
      "Epoch: 92, Train loss: 4062.7676, Val loss: 6348.8348\n",
      "Patience counter: 1\n",
      "Epoch: 93, Train loss: 4184.0748, Val loss: 5829.7016\n",
      "Model has been saved!\n",
      "Epoch: 94, Train loss: 3883.0062, Val loss: 5480.5193\n",
      "Model has been saved!\n",
      "Epoch: 95, Train loss: 3672.4186, Val loss: 4728.1022\n",
      "Model has been saved!\n",
      "Epoch: 96, Train loss: 3308.9557, Val loss: 4931.4017\n",
      "Patience counter: 1\n",
      "Epoch: 97, Train loss: 3213.7279, Val loss: 4645.6899\n",
      "Model has been saved!\n",
      "Epoch: 98, Train loss: 3288.8143, Val loss: 4817.1960\n",
      "Patience counter: 1\n",
      "Epoch: 99, Train loss: 3307.1090, Val loss: 4876.8326\n",
      "Patience counter: 2\n",
      "Epoch: 100, Train loss: 3308.5832, Val loss: 4545.9351\n",
      "Model has been saved!\n",
      "Epoch: 101, Train loss: 2916.1159, Val loss: 4297.8822\n",
      "Model has been saved!\n",
      "Epoch: 102, Train loss: 2619.7104, Val loss: 4364.9404\n",
      "Patience counter: 1\n",
      "Epoch: 103, Train loss: 3175.5951, Val loss: 4600.6345\n",
      "Patience counter: 2\n",
      "Epoch: 104, Train loss: 2716.5238, Val loss: 4354.2633\n",
      "Patience counter: 3\n",
      "Epoch: 105, Train loss: 2638.0296, Val loss: 3929.1224\n",
      "Model has been saved!\n",
      "Epoch: 106, Train loss: 2364.0718, Val loss: 3940.8841\n",
      "Patience counter: 1\n",
      "Epoch: 107, Train loss: 2422.4364, Val loss: 3355.4921\n",
      "Model has been saved!\n",
      "Epoch: 108, Train loss: 2688.0449, Val loss: 3364.6068\n",
      "Patience counter: 1\n",
      "Epoch: 109, Train loss: 2344.1244, Val loss: 3294.4907\n",
      "Model has been saved!\n",
      "Epoch: 110, Train loss: 2223.8423, Val loss: 3385.7456\n",
      "Patience counter: 1\n",
      "Epoch: 111, Train loss: 2223.7710, Val loss: 3290.3729\n",
      "Model has been saved!\n",
      "Epoch: 112, Train loss: 2199.2461, Val loss: 3197.3204\n",
      "Model has been saved!\n",
      "Epoch: 113, Train loss: 2146.4444, Val loss: 3332.5984\n",
      "Patience counter: 1\n",
      "Epoch: 114, Train loss: 2124.1318, Val loss: 2831.3816\n",
      "Model has been saved!\n",
      "Epoch: 115, Train loss: 2010.9298, Val loss: 2846.3955\n",
      "Patience counter: 1\n",
      "Epoch: 116, Train loss: 2089.9685, Val loss: 2646.0800\n",
      "Model has been saved!\n",
      "Epoch: 117, Train loss: 2079.7027, Val loss: 2633.0723\n",
      "Model has been saved!\n",
      "Epoch: 118, Train loss: 2054.9795, Val loss: 2833.7682\n",
      "Patience counter: 1\n",
      "Epoch: 119, Train loss: 2088.2099, Val loss: 2641.4827\n",
      "Patience counter: 2\n",
      "Epoch: 120, Train loss: 2112.4520, Val loss: 2725.6684\n",
      "Patience counter: 3\n",
      "Epoch: 121, Train loss: 1961.3107, Val loss: 2749.3572\n",
      "Patience counter: 4\n",
      "Epoch: 122, Train loss: 2151.2272, Val loss: 2865.0937\n",
      "Patience counter: 5\n",
      "Epoch: 123, Train loss: 1884.4779, Val loss: 2621.1264\n",
      "Model has been saved!\n",
      "Epoch: 124, Train loss: 2088.5491, Val loss: 2907.4642\n",
      "Patience counter: 1\n",
      "Epoch: 125, Train loss: 1770.2239, Val loss: 2652.6519\n",
      "Patience counter: 2\n",
      "Epoch: 126, Train loss: 2001.9739, Val loss: 2614.2919\n",
      "Model has been saved!\n",
      "Epoch: 127, Train loss: 2020.0040, Val loss: 2759.9775\n",
      "Patience counter: 1\n",
      "Epoch: 128, Train loss: 1789.0378, Val loss: 2474.0415\n",
      "Model has been saved!\n",
      "Epoch: 129, Train loss: 2018.6088, Val loss: 2700.9906\n",
      "Patience counter: 1\n",
      "Epoch: 130, Train loss: 1881.1237, Val loss: 2700.6547\n",
      "Patience counter: 2\n",
      "Epoch: 131, Train loss: 2168.0854, Val loss: 2678.0345\n",
      "Patience counter: 3\n",
      "Epoch: 132, Train loss: 1924.5999, Val loss: 2511.6706\n",
      "Patience counter: 4\n",
      "Epoch: 133, Train loss: 1973.6024, Val loss: 2804.9854\n",
      "Patience counter: 5\n",
      "Epoch: 134, Train loss: 1804.7442, Val loss: 2561.5558\n",
      "Patience counter: 6\n",
      "Epoch: 135, Train loss: 1816.9540, Val loss: 2570.7843\n",
      "Patience counter: 7\n",
      "Epoch: 136, Train loss: 1958.8819, Val loss: 2510.4263\n",
      "Patience counter: 8\n",
      "Epoch: 137, Train loss: 1988.8358, Val loss: 2519.3958\n",
      "Patience counter: 9\n",
      "Epoch: 138, Train loss: 1905.3378, Val loss: 2364.0253\n",
      "Model has been saved!\n",
      "Epoch: 139, Train loss: 1901.7438, Val loss: 2650.3964\n",
      "Patience counter: 1\n",
      "Epoch: 140, Train loss: 1961.2837, Val loss: 2556.7461\n",
      "Patience counter: 2\n",
      "Epoch: 141, Train loss: 1821.8651, Val loss: 2471.0520\n",
      "Patience counter: 3\n",
      "Epoch: 142, Train loss: 1794.4216, Val loss: 2423.5729\n",
      "Patience counter: 4\n",
      "Epoch: 143, Train loss: 1778.0771, Val loss: 2482.8001\n",
      "Patience counter: 5\n",
      "Epoch: 144, Train loss: 1921.8278, Val loss: 2675.3415\n",
      "Patience counter: 6\n",
      "Epoch: 145, Train loss: 2033.8852, Val loss: 2533.2721\n",
      "Patience counter: 7\n",
      "Epoch: 146, Train loss: 1743.5131, Val loss: 2478.2214\n",
      "Patience counter: 8\n",
      "Epoch: 147, Train loss: 1752.9544, Val loss: 2445.6950\n",
      "Patience counter: 9\n",
      "Epoch: 148, Train loss: 1670.6805, Val loss: 2352.0013\n",
      "Model has been saved!\n",
      "Epoch: 149, Train loss: 1878.5938, Val loss: 2326.8157\n",
      "Model has been saved!\n",
      "Epoch: 150, Train loss: 1737.3175, Val loss: 2487.1732\n",
      "Patience counter: 1\n",
      "Epoch: 151, Train loss: 1732.6648, Val loss: 2534.7715\n",
      "Patience counter: 2\n",
      "Epoch: 152, Train loss: 1774.2500, Val loss: 2521.2147\n",
      "Patience counter: 3\n",
      "Epoch: 153, Train loss: 1829.2151, Val loss: 2473.4189\n",
      "Patience counter: 4\n",
      "Epoch: 154, Train loss: 1988.6236, Val loss: 2539.3856\n",
      "Patience counter: 5\n",
      "Epoch: 155, Train loss: 1902.5332, Val loss: 2498.6687\n",
      "Patience counter: 6\n",
      "Epoch: 156, Train loss: 1792.2066, Val loss: 2526.1302\n",
      "Patience counter: 7\n",
      "Epoch: 157, Train loss: 1765.6255, Val loss: 2633.0717\n",
      "Patience counter: 8\n",
      "Epoch: 158, Train loss: 1769.0738, Val loss: 2617.4355\n",
      "Patience counter: 9\n",
      "Epoch: 159, Train loss: 1798.5644, Val loss: 2522.0216\n",
      "Patience counter: 10\n",
      "Epoch: 160, Train loss: 1830.3245, Val loss: 2718.2445\n",
      "Patience counter: 11\n",
      "Epoch: 161, Train loss: 1822.8128, Val loss: 2576.0941\n",
      "Patience counter: 12\n",
      "Epoch: 162, Train loss: 1721.8163, Val loss: 2416.1631\n",
      "Patience counter: 13\n",
      "Epoch: 163, Train loss: 1828.7299, Val loss: 2592.8547\n",
      "Patience counter: 14\n",
      "Epoch: 164, Train loss: 1791.5899, Val loss: 2629.4284\n",
      "Patience counter: 15\n",
      "Epoch: 165, Train loss: 1799.6809, Val loss: 2750.8898\n",
      "Patience counter: 16\n",
      "Epoch: 166, Train loss: 1685.9754, Val loss: 2640.1825\n",
      "Patience counter: 17\n",
      "Epoch: 167, Train loss: 1733.8954, Val loss: 2432.2318\n",
      "Patience counter: 18\n",
      "Epoch: 168, Train loss: 1807.5966, Val loss: 2674.0114\n",
      "Patience counter: 19\n",
      "Epoch: 169, Train loss: 1692.9895, Val loss: 2615.4446\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-05\n",
      "Epoch: 170, Train loss: 1701.4561, Val loss: 2678.4866\n",
      "Patience counter: 1\n",
      "Epoch: 171, Train loss: 1781.4301, Val loss: 2635.6669\n",
      "Patience counter: 2\n",
      "Epoch: 172, Train loss: 1757.8789, Val loss: 2558.8509\n",
      "Patience counter: 3\n",
      "Epoch: 173, Train loss: 1805.5269, Val loss: 2583.3178\n",
      "Patience counter: 4\n",
      "Epoch: 174, Train loss: 1618.4831, Val loss: 2587.4551\n",
      "Patience counter: 5\n",
      "Epoch: 175, Train loss: 1568.4384, Val loss: 2534.9713\n",
      "Patience counter: 6\n",
      "Epoch: 176, Train loss: 1714.3827, Val loss: 2527.3250\n",
      "Patience counter: 7\n",
      "Epoch: 177, Train loss: 1726.6782, Val loss: 2546.6498\n",
      "Patience counter: 8\n",
      "Epoch: 178, Train loss: 1791.0704, Val loss: 2576.0844\n",
      "Patience counter: 9\n",
      "Epoch: 179, Train loss: 1707.1804, Val loss: 2517.4113\n",
      "Patience counter: 10\n",
      "Epoch: 180, Train loss: 1605.2041, Val loss: 2455.6649\n",
      "Patience counter: 11\n",
      "Epoch: 181, Train loss: 1636.9004, Val loss: 2545.2002\n",
      "Patience counter: 12\n",
      "Epoch: 182, Train loss: 1654.8738, Val loss: 2547.2840\n",
      "Patience counter: 13\n",
      "Epoch: 183, Train loss: 1558.9245, Val loss: 2543.1907\n",
      "Patience counter: 14\n",
      "Epoch: 184, Train loss: 1636.6194, Val loss: 2582.5669\n",
      "Patience counter: 15\n",
      "Epoch: 185, Train loss: 1586.3320, Val loss: 2721.9862\n",
      "Patience counter: 16\n",
      "Epoch: 186, Train loss: 1763.6845, Val loss: 2487.8468\n",
      "Patience counter: 17\n",
      "Epoch: 187, Train loss: 1732.9392, Val loss: 2489.3472\n",
      "Patience counter: 18\n",
      "Epoch: 188, Train loss: 1641.9069, Val loss: 2553.6122\n",
      "Patience counter: 19\n",
      "Epoch: 189, Train loss: 1578.0163, Val loss: 2523.6034\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-06\n",
      "Epoch: 190, Train loss: 1778.1753, Val loss: 2529.2951\n",
      "Patience counter: 1\n",
      "Epoch: 191, Train loss: 1616.6752, Val loss: 2564.9373\n",
      "Patience counter: 2\n",
      "Epoch: 192, Train loss: 1588.6304, Val loss: 2620.4527\n",
      "Patience counter: 3\n",
      "Epoch: 193, Train loss: 1754.2029, Val loss: 2502.4836\n",
      "Patience counter: 4\n",
      "Epoch: 194, Train loss: 1782.0281, Val loss: 2469.2492\n",
      "Patience counter: 5\n",
      "Epoch: 195, Train loss: 1655.8082, Val loss: 2557.3065\n",
      "Patience counter: 6\n",
      "Epoch: 196, Train loss: 1642.6706, Val loss: 2589.0063\n",
      "Patience counter: 7\n",
      "Epoch: 197, Train loss: 1679.7945, Val loss: 2649.0622\n",
      "Patience counter: 8\n",
      "Epoch: 198, Train loss: 1630.0233, Val loss: 2539.9328\n",
      "Patience counter: 9\n",
      "Epoch: 199, Train loss: 1734.2700, Val loss: 2616.7232\n",
      "Patience counter: 10\n",
      "Test Loss: 1704.5413, MSE: 1712.1675, MAE: 30.6990, R2: 0.5441\n",
      "Epoch: 0, Train loss: 0.6451, Val loss: 0.1959\n",
      "Model has been saved!\n",
      "Epoch: 1, Train loss: 0.3549, Val loss: 0.1342\n",
      "Model has been saved!\n",
      "Epoch: 2, Train loss: 0.2945, Val loss: 0.0990\n",
      "Model has been saved!\n",
      "Epoch: 3, Train loss: 0.2162, Val loss: 0.0798\n",
      "Model has been saved!\n",
      "Epoch: 4, Train loss: 0.1760, Val loss: 0.0633\n",
      "Model has been saved!\n",
      "Epoch: 5, Train loss: 0.1520, Val loss: 0.0517\n",
      "Model has been saved!\n",
      "Epoch: 6, Train loss: 0.1512, Val loss: 0.0430\n",
      "Model has been saved!\n",
      "Epoch: 7, Train loss: 0.1706, Val loss: 0.0455\n",
      "Patience counter: 1\n",
      "Epoch: 8, Train loss: 0.1214, Val loss: 0.0604\n",
      "Patience counter: 2\n",
      "Epoch: 9, Train loss: 0.1423, Val loss: 0.0597\n",
      "Patience counter: 3\n",
      "Epoch: 10, Train loss: 0.1012, Val loss: 0.0625\n",
      "Patience counter: 4\n",
      "Epoch: 11, Train loss: 0.1155, Val loss: 0.0680\n",
      "Patience counter: 5\n",
      "Epoch: 12, Train loss: 0.1220, Val loss: 0.0634\n",
      "Patience counter: 6\n",
      "Epoch: 13, Train loss: 0.1007, Val loss: 0.0726\n",
      "Patience counter: 7\n",
      "Epoch: 14, Train loss: 0.1090, Val loss: 0.0723\n",
      "Patience counter: 8\n",
      "Epoch: 15, Train loss: 0.0799, Val loss: 0.0656\n",
      "Patience counter: 9\n",
      "Epoch: 16, Train loss: 0.0957, Val loss: 0.0553\n",
      "Patience counter: 10\n",
      "Epoch: 17, Train loss: 0.0965, Val loss: 0.0505\n",
      "Patience counter: 11\n",
      "Epoch: 18, Train loss: 0.0889, Val loss: 0.0543\n",
      "Patience counter: 12\n",
      "Epoch: 19, Train loss: 0.1052, Val loss: 0.0591\n",
      "Patience counter: 13\n",
      "Epoch: 20, Train loss: 0.0860, Val loss: 0.0590\n",
      "Patience counter: 14\n",
      "Epoch: 21, Train loss: 0.0916, Val loss: 0.0587\n",
      "Patience counter: 15\n",
      "Epoch: 22, Train loss: 0.0882, Val loss: 0.0526\n",
      "Patience counter: 16\n",
      "Epoch: 23, Train loss: 0.1104, Val loss: 0.0534\n",
      "Patience counter: 17\n",
      "Epoch: 24, Train loss: 0.0702, Val loss: 0.0472\n",
      "Patience counter: 18\n",
      "Epoch: 25, Train loss: 0.0884, Val loss: 0.0419\n",
      "Model has been saved!\n",
      "Epoch: 26, Train loss: 0.0878, Val loss: 0.0439\n",
      "Patience counter: 1\n",
      "Epoch: 27, Train loss: 0.0760, Val loss: 0.0508\n",
      "Patience counter: 2\n",
      "Epoch: 28, Train loss: 0.0849, Val loss: 0.0608\n",
      "Patience counter: 3\n",
      "Epoch: 29, Train loss: 0.0665, Val loss: 0.0606\n",
      "Patience counter: 4\n",
      "Epoch: 30, Train loss: 0.0882, Val loss: 0.0505\n",
      "Patience counter: 5\n",
      "Epoch: 31, Train loss: 0.0789, Val loss: 0.0543\n",
      "Patience counter: 6\n",
      "Epoch: 32, Train loss: 0.0868, Val loss: 0.0498\n",
      "Patience counter: 7\n",
      "Epoch: 33, Train loss: 0.0713, Val loss: 0.0503\n",
      "Patience counter: 8\n",
      "Epoch: 34, Train loss: 0.0543, Val loss: 0.0512\n",
      "Patience counter: 9\n",
      "Epoch: 35, Train loss: 0.0576, Val loss: 0.0533\n",
      "Patience counter: 10\n",
      "Epoch: 36, Train loss: 0.0763, Val loss: 0.0610\n",
      "Patience counter: 11\n",
      "Epoch: 37, Train loss: 0.0684, Val loss: 0.0596\n",
      "Patience counter: 12\n",
      "Epoch: 38, Train loss: 0.0692, Val loss: 0.0585\n",
      "Patience counter: 13\n",
      "Epoch: 39, Train loss: 0.0637, Val loss: 0.0531\n",
      "Patience counter: 14\n",
      "Epoch: 40, Train loss: 0.0520, Val loss: 0.0587\n",
      "Patience counter: 15\n",
      "Epoch: 41, Train loss: 0.0567, Val loss: 0.0642\n",
      "Patience counter: 16\n",
      "Epoch: 42, Train loss: 0.0564, Val loss: 0.0632\n",
      "Patience counter: 17\n",
      "Epoch: 43, Train loss: 0.0550, Val loss: 0.0675\n",
      "Patience counter: 18\n",
      "Epoch: 44, Train loss: 0.0543, Val loss: 0.0577\n",
      "Patience counter: 19\n",
      "Epoch: 45, Train loss: 0.0612, Val loss: 0.0560\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-05\n",
      "Epoch: 46, Train loss: 0.0721, Val loss: 0.0552\n",
      "Patience counter: 1\n",
      "Epoch: 47, Train loss: 0.0538, Val loss: 0.0518\n",
      "Patience counter: 2\n",
      "Epoch: 48, Train loss: 0.0573, Val loss: 0.0538\n",
      "Patience counter: 3\n",
      "Epoch: 49, Train loss: 0.0549, Val loss: 0.0567\n",
      "Patience counter: 4\n",
      "Epoch: 50, Train loss: 0.0568, Val loss: 0.0568\n",
      "Patience counter: 5\n",
      "Epoch: 51, Train loss: 0.0595, Val loss: 0.0565\n",
      "Patience counter: 6\n",
      "Epoch: 52, Train loss: 0.0638, Val loss: 0.0574\n",
      "Patience counter: 7\n",
      "Epoch: 53, Train loss: 0.0557, Val loss: 0.0577\n",
      "Patience counter: 8\n",
      "Epoch: 54, Train loss: 0.0562, Val loss: 0.0602\n",
      "Patience counter: 9\n",
      "Epoch: 55, Train loss: 0.0547, Val loss: 0.0613\n",
      "Patience counter: 10\n",
      "Epoch: 56, Train loss: 0.0473, Val loss: 0.0594\n",
      "Patience counter: 11\n",
      "Epoch: 57, Train loss: 0.0489, Val loss: 0.0547\n",
      "Patience counter: 12\n",
      "Epoch: 58, Train loss: 0.0466, Val loss: 0.0564\n",
      "Patience counter: 13\n",
      "Epoch: 59, Train loss: 0.0396, Val loss: 0.0564\n",
      "Patience counter: 14\n",
      "Epoch: 60, Train loss: 0.0482, Val loss: 0.0579\n",
      "Patience counter: 15\n",
      "Epoch: 61, Train loss: 0.0494, Val loss: 0.0598\n",
      "Patience counter: 16\n",
      "Epoch: 62, Train loss: 0.0522, Val loss: 0.0566\n",
      "Patience counter: 17\n",
      "Epoch: 63, Train loss: 0.0466, Val loss: 0.0594\n",
      "Patience counter: 18\n",
      "Epoch: 64, Train loss: 0.0442, Val loss: 0.0587\n",
      "Patience counter: 19\n",
      "Epoch: 65, Train loss: 0.0463, Val loss: 0.0609\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-06\n",
      "Epoch: 66, Train loss: 0.0426, Val loss: 0.0602\n",
      "Patience counter: 1\n",
      "Epoch: 67, Train loss: 0.0520, Val loss: 0.0621\n",
      "Patience counter: 2\n",
      "Epoch: 68, Train loss: 0.0574, Val loss: 0.0624\n",
      "Patience counter: 3\n",
      "Epoch: 69, Train loss: 0.0420, Val loss: 0.0619\n",
      "Patience counter: 4\n",
      "Epoch: 70, Train loss: 0.0455, Val loss: 0.0623\n",
      "Patience counter: 5\n",
      "Epoch: 71, Train loss: 0.0462, Val loss: 0.0626\n",
      "Patience counter: 6\n",
      "Epoch: 72, Train loss: 0.0460, Val loss: 0.0610\n",
      "Patience counter: 7\n",
      "Epoch: 73, Train loss: 0.0506, Val loss: 0.0616\n",
      "Patience counter: 8\n",
      "Epoch: 74, Train loss: 0.0381, Val loss: 0.0635\n",
      "Patience counter: 9\n",
      "Epoch: 75, Train loss: 0.0607, Val loss: 0.0617\n",
      "Patience counter: 10\n",
      "Epoch: 76, Train loss: 0.0426, Val loss: 0.0603\n",
      "Patience counter: 11\n",
      "Epoch: 77, Train loss: 0.0518, Val loss: 0.0614\n",
      "Patience counter: 12\n",
      "Epoch: 78, Train loss: 0.0583, Val loss: 0.0604\n",
      "Patience counter: 13\n",
      "Epoch: 79, Train loss: 0.0533, Val loss: 0.0621\n",
      "Patience counter: 14\n",
      "Epoch: 80, Train loss: 0.0588, Val loss: 0.0627\n",
      "Patience counter: 15\n",
      "Epoch: 81, Train loss: 0.0542, Val loss: 0.0595\n",
      "Patience counter: 16\n",
      "Epoch: 82, Train loss: 0.0493, Val loss: 0.0585\n",
      "Patience counter: 17\n",
      "Epoch: 83, Train loss: 0.0447, Val loss: 0.0619\n",
      "Patience counter: 18\n",
      "Epoch: 84, Train loss: 0.0419, Val loss: 0.0625\n",
      "Patience counter: 19\n",
      "Epoch: 85, Train loss: 0.0440, Val loss: 0.0625\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-07\n",
      "Epoch: 86, Train loss: 0.0421, Val loss: 0.0598\n",
      "Patience counter: 1\n",
      "Epoch: 87, Train loss: 0.0426, Val loss: 0.0577\n",
      "Patience counter: 2\n",
      "Epoch: 88, Train loss: 0.0461, Val loss: 0.0572\n",
      "Patience counter: 3\n",
      "Epoch: 89, Train loss: 0.0510, Val loss: 0.0595\n",
      "Patience counter: 4\n",
      "Epoch: 90, Train loss: 0.0539, Val loss: 0.0602\n",
      "Patience counter: 5\n",
      "Epoch: 91, Train loss: 0.0471, Val loss: 0.0592\n",
      "Patience counter: 6\n",
      "Epoch: 92, Train loss: 0.0423, Val loss: 0.0586\n",
      "Patience counter: 7\n",
      "Epoch: 93, Train loss: 0.0597, Val loss: 0.0606\n",
      "Patience counter: 8\n",
      "Epoch: 94, Train loss: 0.0529, Val loss: 0.0597\n",
      "Patience counter: 9\n",
      "Epoch: 95, Train loss: 0.0469, Val loss: 0.0603\n",
      "Patience counter: 10\n",
      "Epoch: 96, Train loss: 0.0628, Val loss: 0.0593\n",
      "Patience counter: 11\n",
      "Epoch: 97, Train loss: 0.0563, Val loss: 0.0592\n",
      "Patience counter: 12\n",
      "Epoch: 98, Train loss: 0.0559, Val loss: 0.0610\n",
      "Patience counter: 13\n",
      "Epoch: 99, Train loss: 0.0502, Val loss: 0.0597\n",
      "Patience counter: 14\n",
      "Epoch: 100, Train loss: 0.0462, Val loss: 0.0570\n",
      "Patience counter: 15\n",
      "Epoch: 101, Train loss: 0.0517, Val loss: 0.0587\n",
      "Patience counter: 16\n",
      "Epoch: 102, Train loss: 0.0644, Val loss: 0.0594\n",
      "Patience counter: 17\n",
      "Epoch: 103, Train loss: 0.0592, Val loss: 0.0585\n",
      "Patience counter: 18\n",
      "Epoch: 104, Train loss: 0.0527, Val loss: 0.0582\n",
      "Patience counter: 19\n",
      "Epoch: 105, Train loss: 0.0651, Val loss: 0.0574\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-08\n",
      "Epoch: 106, Train loss: 0.0409, Val loss: 0.0580\n",
      "Patience counter: 1\n",
      "Epoch: 107, Train loss: 0.0611, Val loss: 0.0605\n",
      "Patience counter: 2\n",
      "Epoch: 108, Train loss: 0.0478, Val loss: 0.0594\n",
      "Patience counter: 3\n",
      "Epoch: 109, Train loss: 0.0548, Val loss: 0.0605\n",
      "Patience counter: 4\n",
      "Epoch: 110, Train loss: 0.0479, Val loss: 0.0592\n",
      "Patience counter: 5\n",
      "Epoch: 111, Train loss: 0.0387, Val loss: 0.0586\n",
      "Patience counter: 6\n",
      "Epoch: 112, Train loss: 0.0416, Val loss: 0.0598\n",
      "Patience counter: 7\n",
      "Epoch: 113, Train loss: 0.0494, Val loss: 0.0593\n",
      "Patience counter: 8\n",
      "Epoch: 114, Train loss: 0.0575, Val loss: 0.0599\n",
      "Patience counter: 9\n",
      "Epoch: 115, Train loss: 0.0553, Val loss: 0.0601\n",
      "Patience counter: 10\n",
      "Epoch: 116, Train loss: 0.0670, Val loss: 0.0607\n",
      "Patience counter: 11\n",
      "Epoch: 117, Train loss: 0.0648, Val loss: 0.0591\n",
      "Patience counter: 12\n",
      "Epoch: 118, Train loss: 0.0576, Val loss: 0.0619\n",
      "Patience counter: 13\n",
      "Epoch: 119, Train loss: 0.0515, Val loss: 0.0606\n",
      "Patience counter: 14\n",
      "Epoch: 120, Train loss: 0.0417, Val loss: 0.0618\n",
      "Patience counter: 15\n",
      "Epoch: 121, Train loss: 0.0401, Val loss: 0.0615\n",
      "Patience counter: 16\n",
      "Epoch: 122, Train loss: 0.0462, Val loss: 0.0589\n",
      "Patience counter: 17\n",
      "Epoch: 123, Train loss: 0.0409, Val loss: 0.0624\n",
      "Patience counter: 18\n",
      "Epoch: 124, Train loss: 0.0490, Val loss: 0.0607\n",
      "Patience counter: 19\n",
      "Epoch: 125, Train loss: 0.0559, Val loss: 0.0615\n",
      "Patience counter: 20\n",
      "Early stopping triggered. Learning rate has reached its minimum threshold (5.000000000000001e-08).\n",
      "Test Loss: 0.0123, MSE: 0.0158, MAE: 0.0995, R2: 0.8092\n"
     ]
    }
   ],
   "source": [
    "# 训练模型，设置epoch数为100\n",
    "epochs = 200\n",
    "\n",
    "# 熔点MLP模型\n",
    "Tm_train_losses_mlp, Tm_val_losses_mlp, Tm_test_pred_mlp, Tm_test_true_mlp, Tm_test_mse_mlp, Tm_test_mae_mlp, Tm_test_r2_mlp = train_epochs_mlp(\n",
    "    0, epochs, model_Tm_MLP, Tm_train_loader, Tm_val_loader, Tm_test_loader, \"Tm_MLP_model.pt\", input_type=\"fp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00096b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 4.1381, Val loss: 7.1947\n",
      "Model has been saved!\n",
      "Epoch: 1, Train loss: 3.7686, Val loss: 7.5611\n",
      "Patience counter: 1\n",
      "Epoch: 2, Train loss: 3.7932, Val loss: 4.7687\n",
      "Model has been saved!\n",
      "Epoch: 3, Train loss: 2.3909, Val loss: 4.7472\n",
      "Model has been saved!\n",
      "Epoch: 4, Train loss: 2.7287, Val loss: 5.4201\n",
      "Patience counter: 1\n",
      "Epoch: 5, Train loss: 2.8889, Val loss: 6.0903\n",
      "Patience counter: 2\n",
      "Epoch: 6, Train loss: 3.1506, Val loss: 5.4364\n",
      "Patience counter: 3\n",
      "Epoch: 7, Train loss: 2.2077, Val loss: 5.6434\n",
      "Patience counter: 4\n",
      "Epoch: 8, Train loss: 1.8799, Val loss: 5.5333\n",
      "Patience counter: 5\n",
      "Epoch: 9, Train loss: 2.4029, Val loss: 5.8310\n",
      "Patience counter: 6\n",
      "Epoch: 10, Train loss: 3.0219, Val loss: 6.8104\n",
      "Patience counter: 7\n",
      "Epoch: 11, Train loss: 2.6004, Val loss: 5.5185\n",
      "Patience counter: 8\n",
      "Epoch: 12, Train loss: 3.1884, Val loss: 5.6318\n",
      "Patience counter: 9\n",
      "Epoch: 13, Train loss: 2.0706, Val loss: 6.0463\n",
      "Patience counter: 10\n",
      "Epoch: 14, Train loss: 2.8656, Val loss: 6.3905\n",
      "Patience counter: 11\n",
      "Epoch: 15, Train loss: 2.8164, Val loss: 5.8026\n",
      "Patience counter: 12\n",
      "Epoch: 16, Train loss: 3.4894, Val loss: 5.8330\n",
      "Patience counter: 13\n",
      "Epoch: 17, Train loss: 2.4388, Val loss: 6.8661\n",
      "Patience counter: 14\n",
      "Epoch: 18, Train loss: 3.2714, Val loss: 6.3016\n",
      "Patience counter: 15\n",
      "Epoch: 19, Train loss: 1.6706, Val loss: 7.6556\n",
      "Patience counter: 16\n",
      "Epoch: 20, Train loss: 1.8588, Val loss: 8.0332\n",
      "Patience counter: 17\n",
      "Epoch: 21, Train loss: 2.7644, Val loss: 8.4016\n",
      "Patience counter: 18\n",
      "Epoch: 22, Train loss: 2.2717, Val loss: 5.8603\n",
      "Patience counter: 19\n",
      "Epoch: 23, Train loss: 1.7738, Val loss: 4.6440\n",
      "Model has been saved!\n",
      "Epoch: 24, Train loss: 2.9389, Val loss: 4.7016\n",
      "Patience counter: 1\n",
      "Epoch: 25, Train loss: 2.2417, Val loss: 5.9727\n",
      "Patience counter: 2\n",
      "Epoch: 26, Train loss: 2.2951, Val loss: 6.3418\n",
      "Patience counter: 3\n",
      "Epoch: 27, Train loss: 2.4647, Val loss: 6.3480\n",
      "Patience counter: 4\n",
      "Epoch: 28, Train loss: 2.2061, Val loss: 5.9659\n",
      "Patience counter: 5\n",
      "Epoch: 29, Train loss: 3.6820, Val loss: 6.3929\n",
      "Patience counter: 6\n",
      "Epoch: 30, Train loss: 4.7626, Val loss: 5.3460\n",
      "Patience counter: 7\n",
      "Epoch: 31, Train loss: 2.4468, Val loss: 5.7243\n",
      "Patience counter: 8\n",
      "Epoch: 32, Train loss: 2.7828, Val loss: 4.9558\n",
      "Patience counter: 9\n",
      "Epoch: 33, Train loss: 3.6540, Val loss: 4.4679\n",
      "Model has been saved!\n",
      "Epoch: 34, Train loss: 2.6273, Val loss: 5.1099\n",
      "Patience counter: 1\n",
      "Epoch: 35, Train loss: 2.7200, Val loss: 4.6131\n",
      "Patience counter: 2\n",
      "Epoch: 36, Train loss: 2.2948, Val loss: 4.6106\n",
      "Patience counter: 3\n",
      "Epoch: 37, Train loss: 2.8199, Val loss: 5.8804\n",
      "Patience counter: 4\n",
      "Epoch: 38, Train loss: 2.4190, Val loss: 5.4112\n",
      "Patience counter: 5\n",
      "Epoch: 39, Train loss: 3.6258, Val loss: 5.5973\n",
      "Patience counter: 6\n",
      "Epoch: 40, Train loss: 2.3831, Val loss: 5.6824\n",
      "Patience counter: 7\n",
      "Epoch: 41, Train loss: 1.4278, Val loss: 5.4552\n",
      "Patience counter: 8\n",
      "Epoch: 42, Train loss: 2.6991, Val loss: 5.8546\n",
      "Patience counter: 9\n",
      "Epoch: 43, Train loss: 2.1942, Val loss: 5.9337\n",
      "Patience counter: 10\n",
      "Epoch: 44, Train loss: 1.7435, Val loss: 5.6882\n",
      "Patience counter: 11\n",
      "Epoch: 45, Train loss: 2.5432, Val loss: 6.3051\n",
      "Patience counter: 12\n",
      "Epoch: 46, Train loss: 3.4476, Val loss: 6.3393\n",
      "Patience counter: 13\n",
      "Epoch: 47, Train loss: 2.4673, Val loss: 5.4071\n",
      "Patience counter: 14\n",
      "Epoch: 48, Train loss: 2.5689, Val loss: 5.1350\n",
      "Patience counter: 15\n",
      "Epoch: 49, Train loss: 1.6383, Val loss: 5.0058\n",
      "Patience counter: 16\n",
      "Epoch: 50, Train loss: 2.2701, Val loss: 5.8335\n",
      "Patience counter: 17\n",
      "Epoch: 51, Train loss: 3.2704, Val loss: 7.4678\n",
      "Patience counter: 18\n",
      "Epoch: 52, Train loss: 3.0078, Val loss: 7.3340\n",
      "Patience counter: 19\n",
      "Epoch: 53, Train loss: 2.3656, Val loss: 7.9004\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-05\n",
      "Epoch: 54, Train loss: 4.5075, Val loss: 8.2275\n",
      "Patience counter: 1\n",
      "Epoch: 55, Train loss: 2.1303, Val loss: 7.2521\n",
      "Patience counter: 2\n",
      "Epoch: 56, Train loss: 2.8759, Val loss: 7.0574\n",
      "Patience counter: 3\n",
      "Epoch: 57, Train loss: 2.9364, Val loss: 7.3029\n",
      "Patience counter: 4\n",
      "Epoch: 58, Train loss: 2.5893, Val loss: 6.8793\n",
      "Patience counter: 5\n",
      "Epoch: 59, Train loss: 1.4268, Val loss: 6.9344\n",
      "Patience counter: 6\n",
      "Epoch: 60, Train loss: 1.5540, Val loss: 7.1205\n",
      "Patience counter: 7\n",
      "Epoch: 61, Train loss: 2.5035, Val loss: 7.2836\n",
      "Patience counter: 8\n",
      "Epoch: 62, Train loss: 2.5368, Val loss: 6.9981\n",
      "Patience counter: 9\n",
      "Epoch: 63, Train loss: 1.5210, Val loss: 6.7204\n",
      "Patience counter: 10\n",
      "Epoch: 64, Train loss: 2.0361, Val loss: 6.4251\n",
      "Patience counter: 11\n",
      "Epoch: 65, Train loss: 2.0448, Val loss: 6.9910\n",
      "Patience counter: 12\n",
      "Epoch: 66, Train loss: 2.9395, Val loss: 7.3795\n",
      "Patience counter: 13\n",
      "Epoch: 67, Train loss: 1.7592, Val loss: 6.9669\n",
      "Patience counter: 14\n",
      "Epoch: 68, Train loss: 1.4100, Val loss: 6.8769\n",
      "Patience counter: 15\n",
      "Epoch: 69, Train loss: 1.7329, Val loss: 6.6490\n",
      "Patience counter: 16\n",
      "Epoch: 70, Train loss: 2.7490, Val loss: 6.6481\n",
      "Patience counter: 17\n",
      "Epoch: 71, Train loss: 2.6380, Val loss: 7.0596\n",
      "Patience counter: 18\n",
      "Epoch: 72, Train loss: 2.9495, Val loss: 6.4011\n",
      "Patience counter: 19\n",
      "Epoch: 73, Train loss: 1.5784, Val loss: 6.1932\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-06\n",
      "Epoch: 74, Train loss: 2.0511, Val loss: 6.2265\n",
      "Patience counter: 1\n",
      "Epoch: 75, Train loss: 1.6068, Val loss: 6.4729\n",
      "Patience counter: 2\n",
      "Epoch: 76, Train loss: 1.1372, Val loss: 6.2027\n",
      "Patience counter: 3\n",
      "Epoch: 77, Train loss: 2.5830, Val loss: 6.3072\n",
      "Patience counter: 4\n",
      "Epoch: 78, Train loss: 1.1312, Val loss: 5.9983\n",
      "Patience counter: 5\n",
      "Epoch: 79, Train loss: 1.8720, Val loss: 6.1013\n",
      "Patience counter: 6\n",
      "Epoch: 80, Train loss: 1.9387, Val loss: 6.6981\n",
      "Patience counter: 7\n",
      "Epoch: 81, Train loss: 1.1105, Val loss: 6.9085\n",
      "Patience counter: 8\n",
      "Epoch: 82, Train loss: 1.8249, Val loss: 6.4521\n",
      "Patience counter: 9\n",
      "Epoch: 83, Train loss: 1.2551, Val loss: 6.3845\n",
      "Patience counter: 10\n",
      "Epoch: 84, Train loss: 1.8170, Val loss: 6.6424\n",
      "Patience counter: 11\n",
      "Epoch: 85, Train loss: 2.2939, Val loss: 6.2483\n",
      "Patience counter: 12\n",
      "Epoch: 86, Train loss: 3.4345, Val loss: 6.7677\n",
      "Patience counter: 13\n",
      "Epoch: 87, Train loss: 1.9725, Val loss: 6.7715\n",
      "Patience counter: 14\n",
      "Epoch: 88, Train loss: 2.4499, Val loss: 6.6066\n",
      "Patience counter: 15\n",
      "Epoch: 89, Train loss: 2.4989, Val loss: 6.8629\n",
      "Patience counter: 16\n",
      "Epoch: 90, Train loss: 2.1269, Val loss: 6.0971\n",
      "Patience counter: 17\n",
      "Epoch: 91, Train loss: 1.9720, Val loss: 6.6294\n",
      "Patience counter: 18\n",
      "Epoch: 92, Train loss: 1.7651, Val loss: 6.7183\n",
      "Patience counter: 19\n",
      "Epoch: 93, Train loss: 1.3344, Val loss: 6.7749\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-07\n",
      "Epoch: 94, Train loss: 2.6486, Val loss: 6.0222\n",
      "Patience counter: 1\n",
      "Epoch: 95, Train loss: 1.6398, Val loss: 6.3907\n",
      "Patience counter: 2\n",
      "Epoch: 96, Train loss: 1.7382, Val loss: 6.0739\n",
      "Patience counter: 3\n",
      "Epoch: 97, Train loss: 1.5812, Val loss: 6.5646\n",
      "Patience counter: 4\n",
      "Epoch: 98, Train loss: 2.2281, Val loss: 6.5872\n",
      "Patience counter: 5\n",
      "Epoch: 99, Train loss: 3.3210, Val loss: 5.9936\n",
      "Patience counter: 6\n",
      "Epoch: 100, Train loss: 1.8283, Val loss: 6.4435\n",
      "Patience counter: 7\n",
      "Epoch: 101, Train loss: 2.9529, Val loss: 6.7065\n",
      "Patience counter: 8\n",
      "Epoch: 102, Train loss: 1.8389, Val loss: 6.3748\n",
      "Patience counter: 9\n",
      "Epoch: 103, Train loss: 2.3786, Val loss: 5.8990\n",
      "Patience counter: 10\n",
      "Epoch: 104, Train loss: 1.4300, Val loss: 6.1489\n",
      "Patience counter: 11\n",
      "Epoch: 105, Train loss: 2.0649, Val loss: 6.4669\n",
      "Patience counter: 12\n",
      "Epoch: 106, Train loss: 2.1258, Val loss: 6.5159\n",
      "Patience counter: 13\n",
      "Epoch: 107, Train loss: 1.8696, Val loss: 6.7219\n",
      "Patience counter: 14\n",
      "Epoch: 108, Train loss: 1.6784, Val loss: 6.4444\n",
      "Patience counter: 15\n",
      "Epoch: 109, Train loss: 1.9692, Val loss: 6.4718\n",
      "Patience counter: 16\n",
      "Epoch: 110, Train loss: 2.9920, Val loss: 6.3611\n",
      "Patience counter: 17\n",
      "Epoch: 111, Train loss: 1.3183, Val loss: 6.0674\n",
      "Patience counter: 18\n",
      "Epoch: 112, Train loss: 1.0134, Val loss: 6.1307\n",
      "Patience counter: 19\n",
      "Epoch: 113, Train loss: 1.0447, Val loss: 5.7830\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-08\n",
      "Epoch: 114, Train loss: 2.3566, Val loss: 6.2968\n",
      "Patience counter: 1\n",
      "Epoch: 115, Train loss: 1.7493, Val loss: 5.9205\n",
      "Patience counter: 2\n",
      "Epoch: 116, Train loss: 2.0160, Val loss: 6.2036\n",
      "Patience counter: 3\n",
      "Epoch: 117, Train loss: 1.5097, Val loss: 6.3578\n",
      "Patience counter: 4\n",
      "Epoch: 118, Train loss: 1.8382, Val loss: 6.5093\n",
      "Patience counter: 5\n",
      "Epoch: 119, Train loss: 2.2234, Val loss: 5.9261\n",
      "Patience counter: 6\n",
      "Epoch: 120, Train loss: 1.7956, Val loss: 5.8937\n",
      "Patience counter: 7\n",
      "Epoch: 121, Train loss: 3.3812, Val loss: 5.8437\n",
      "Patience counter: 8\n",
      "Epoch: 122, Train loss: 2.0790, Val loss: 5.9743\n",
      "Patience counter: 9\n",
      "Epoch: 123, Train loss: 2.0306, Val loss: 6.5439\n",
      "Patience counter: 10\n",
      "Epoch: 124, Train loss: 2.6523, Val loss: 6.9736\n",
      "Patience counter: 11\n",
      "Epoch: 125, Train loss: 2.3731, Val loss: 6.4113\n",
      "Patience counter: 12\n",
      "Epoch: 126, Train loss: 1.9276, Val loss: 6.4012\n",
      "Patience counter: 13\n",
      "Epoch: 127, Train loss: 2.0922, Val loss: 6.6069\n",
      "Patience counter: 14\n",
      "Epoch: 128, Train loss: 1.6094, Val loss: 6.5866\n",
      "Patience counter: 15\n",
      "Epoch: 129, Train loss: 1.3565, Val loss: 6.4454\n",
      "Patience counter: 16\n",
      "Epoch: 130, Train loss: 1.6664, Val loss: 6.2965\n",
      "Patience counter: 17\n",
      "Epoch: 131, Train loss: 1.7470, Val loss: 5.9779\n",
      "Patience counter: 18\n",
      "Epoch: 132, Train loss: 1.9039, Val loss: 6.4780\n",
      "Patience counter: 19\n",
      "Epoch: 133, Train loss: 1.6853, Val loss: 6.4709\n",
      "Patience counter: 20\n",
      "Early stopping triggered. Learning rate has reached its minimum threshold (5.000000000000001e-08).\n",
      "Test Loss: 1.4566, MSE: 1.4180, MAE: 0.8260, R2: 0.8287\n"
     ]
    }
   ],
   "source": [
    "set_seed(421)\n",
    "# 电导率MLP模型\n",
    "conductivity_train_losses_mlp, conductivity_val_losses_mlp, conductivity_test_pred_mlp, conductivity_test_true_mlp, conductivity_test_mse_mlp, conductivity_test_mae_mlp, conductivity_test_r2_mlp = train_epochs_mlp(\n",
    "    0, epochs, model_conductivity_MLP, conductivity_train_loader, conductivity_val_loader, conductivity_test_loader, \"conductivity_MLP_model.pt\", scale=10, input_type=\"fp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7c04e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 2.8600, Val loss: 2.6131\n",
      "Model has been saved!\n",
      "Epoch: 1, Train loss: 2.2413, Val loss: 2.6078\n",
      "Model has been saved!\n",
      "Epoch: 2, Train loss: 1.8879, Val loss: 2.5993\n",
      "Model has been saved!\n",
      "Epoch: 3, Train loss: 1.5393, Val loss: 2.5853\n",
      "Model has been saved!\n",
      "Epoch: 4, Train loss: 1.4573, Val loss: 2.5678\n",
      "Model has been saved!\n",
      "Epoch: 5, Train loss: 1.3098, Val loss: 2.5489\n",
      "Model has been saved!\n",
      "Epoch: 6, Train loss: 1.2178, Val loss: 2.5306\n",
      "Model has been saved!\n",
      "Epoch: 7, Train loss: 1.0247, Val loss: 2.5077\n",
      "Model has been saved!\n",
      "Epoch: 8, Train loss: 0.8207, Val loss: 2.4831\n",
      "Model has been saved!\n",
      "Epoch: 9, Train loss: 0.7651, Val loss: 2.4526\n",
      "Model has been saved!\n",
      "Epoch: 10, Train loss: 0.8261, Val loss: 2.4256\n",
      "Model has been saved!\n",
      "Epoch: 11, Train loss: 0.5973, Val loss: 2.4155\n",
      "Model has been saved!\n",
      "Epoch: 12, Train loss: 0.4950, Val loss: 2.4072\n",
      "Model has been saved!\n",
      "Epoch: 13, Train loss: 0.5521, Val loss: 2.4060\n",
      "Model has been saved!\n",
      "Epoch: 14, Train loss: 0.5205, Val loss: 2.4100\n",
      "Patience counter: 1\n",
      "Epoch: 15, Train loss: 0.4792, Val loss: 2.4557\n",
      "Patience counter: 2\n",
      "Epoch: 16, Train loss: 0.3847, Val loss: 2.5117\n",
      "Patience counter: 3\n",
      "Epoch: 17, Train loss: 0.3373, Val loss: 2.5051\n",
      "Patience counter: 4\n",
      "Epoch: 18, Train loss: 0.4674, Val loss: 2.4808\n",
      "Patience counter: 5\n",
      "Epoch: 19, Train loss: 0.2784, Val loss: 2.4616\n",
      "Patience counter: 6\n",
      "Epoch: 20, Train loss: 0.3115, Val loss: 2.4382\n",
      "Patience counter: 7\n",
      "Epoch: 21, Train loss: 0.3568, Val loss: 2.4776\n",
      "Patience counter: 8\n",
      "Epoch: 22, Train loss: 0.3415, Val loss: 2.5264\n",
      "Patience counter: 9\n",
      "Epoch: 23, Train loss: 0.3010, Val loss: 2.5589\n",
      "Patience counter: 10\n",
      "Epoch: 24, Train loss: 0.2605, Val loss: 2.5697\n",
      "Patience counter: 11\n",
      "Epoch: 25, Train loss: 0.2712, Val loss: 2.5257\n",
      "Patience counter: 12\n",
      "Epoch: 26, Train loss: 0.2453, Val loss: 2.5585\n",
      "Patience counter: 13\n",
      "Epoch: 27, Train loss: 0.2147, Val loss: 2.5635\n",
      "Patience counter: 14\n",
      "Epoch: 28, Train loss: 0.2761, Val loss: 2.5713\n",
      "Patience counter: 15\n",
      "Epoch: 29, Train loss: 0.3797, Val loss: 2.5942\n",
      "Patience counter: 16\n",
      "Epoch: 30, Train loss: 0.2563, Val loss: 2.5902\n",
      "Patience counter: 17\n",
      "Epoch: 31, Train loss: 0.2978, Val loss: 2.6341\n",
      "Patience counter: 18\n",
      "Epoch: 32, Train loss: 0.2956, Val loss: 2.6626\n",
      "Patience counter: 19\n",
      "Epoch: 33, Train loss: 0.3010, Val loss: 2.6555\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-05\n",
      "Epoch: 34, Train loss: 0.3660, Val loss: 2.6402\n",
      "Patience counter: 1\n",
      "Epoch: 35, Train loss: 0.3256, Val loss: 2.5954\n",
      "Patience counter: 2\n",
      "Epoch: 36, Train loss: 0.1760, Val loss: 2.5811\n",
      "Patience counter: 3\n",
      "Epoch: 37, Train loss: 0.2256, Val loss: 2.5734\n",
      "Patience counter: 4\n",
      "Epoch: 38, Train loss: 0.2604, Val loss: 2.5764\n",
      "Patience counter: 5\n",
      "Epoch: 39, Train loss: 0.2534, Val loss: 2.5702\n",
      "Patience counter: 6\n",
      "Epoch: 40, Train loss: 0.2075, Val loss: 2.5733\n",
      "Patience counter: 7\n",
      "Epoch: 41, Train loss: 0.3299, Val loss: 2.5679\n",
      "Patience counter: 8\n",
      "Epoch: 42, Train loss: 0.2765, Val loss: 2.5643\n",
      "Patience counter: 9\n",
      "Epoch: 43, Train loss: 0.2304, Val loss: 2.5784\n",
      "Patience counter: 10\n",
      "Epoch: 44, Train loss: 0.2013, Val loss: 2.5793\n",
      "Patience counter: 11\n",
      "Epoch: 45, Train loss: 0.2045, Val loss: 2.5682\n",
      "Patience counter: 12\n",
      "Epoch: 46, Train loss: 0.2025, Val loss: 2.5672\n",
      "Patience counter: 13\n",
      "Epoch: 47, Train loss: 0.1810, Val loss: 2.5654\n",
      "Patience counter: 14\n",
      "Epoch: 48, Train loss: 0.1726, Val loss: 2.5620\n",
      "Patience counter: 15\n",
      "Epoch: 49, Train loss: 0.3337, Val loss: 2.5520\n",
      "Patience counter: 16\n",
      "Epoch: 50, Train loss: 0.2007, Val loss: 2.5446\n",
      "Patience counter: 17\n",
      "Epoch: 51, Train loss: 0.2154, Val loss: 2.5598\n",
      "Patience counter: 18\n",
      "Epoch: 52, Train loss: 0.1838, Val loss: 2.5585\n",
      "Patience counter: 19\n",
      "Epoch: 53, Train loss: 0.2192, Val loss: 2.5557\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-06\n",
      "Epoch: 54, Train loss: 0.1678, Val loss: 2.5506\n",
      "Patience counter: 1\n",
      "Epoch: 55, Train loss: 0.2248, Val loss: 2.5541\n",
      "Patience counter: 2\n",
      "Epoch: 56, Train loss: 0.2577, Val loss: 2.5530\n",
      "Patience counter: 3\n",
      "Epoch: 57, Train loss: 0.2162, Val loss: 2.5483\n",
      "Patience counter: 4\n",
      "Epoch: 58, Train loss: 0.2061, Val loss: 2.5590\n",
      "Patience counter: 5\n",
      "Epoch: 59, Train loss: 0.2212, Val loss: 2.5573\n",
      "Patience counter: 6\n",
      "Epoch: 60, Train loss: 0.2019, Val loss: 2.5856\n",
      "Patience counter: 7\n",
      "Epoch: 61, Train loss: 0.2229, Val loss: 2.5781\n",
      "Patience counter: 8\n",
      "Epoch: 62, Train loss: 0.2000, Val loss: 2.5876\n",
      "Patience counter: 9\n",
      "Epoch: 63, Train loss: 0.2199, Val loss: 2.5784\n",
      "Patience counter: 10\n",
      "Epoch: 64, Train loss: 0.2638, Val loss: 2.5675\n",
      "Patience counter: 11\n",
      "Epoch: 65, Train loss: 0.2166, Val loss: 2.5616\n",
      "Patience counter: 12\n",
      "Epoch: 66, Train loss: 0.2399, Val loss: 2.5728\n",
      "Patience counter: 13\n",
      "Epoch: 67, Train loss: 0.1511, Val loss: 2.5785\n",
      "Patience counter: 14\n",
      "Epoch: 68, Train loss: 0.2014, Val loss: 2.5783\n",
      "Patience counter: 15\n",
      "Epoch: 69, Train loss: 0.2254, Val loss: 2.5788\n",
      "Patience counter: 16\n",
      "Epoch: 70, Train loss: 0.2768, Val loss: 2.5833\n",
      "Patience counter: 17\n",
      "Epoch: 71, Train loss: 0.2183, Val loss: 2.5884\n",
      "Patience counter: 18\n",
      "Epoch: 72, Train loss: 0.1788, Val loss: 2.5803\n",
      "Patience counter: 19\n",
      "Epoch: 73, Train loss: 0.1484, Val loss: 2.5788\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-07\n",
      "Epoch: 74, Train loss: 0.2111, Val loss: 2.5654\n",
      "Patience counter: 1\n",
      "Epoch: 75, Train loss: 0.2214, Val loss: 2.5769\n",
      "Patience counter: 2\n",
      "Epoch: 76, Train loss: 0.2156, Val loss: 2.5775\n",
      "Patience counter: 3\n",
      "Epoch: 77, Train loss: 0.2614, Val loss: 2.5720\n",
      "Patience counter: 4\n",
      "Epoch: 78, Train loss: 0.2682, Val loss: 2.5716\n",
      "Patience counter: 5\n",
      "Epoch: 79, Train loss: 0.3933, Val loss: 2.5755\n",
      "Patience counter: 6\n",
      "Epoch: 80, Train loss: 0.2030, Val loss: 2.5691\n",
      "Patience counter: 7\n",
      "Epoch: 81, Train loss: 0.3436, Val loss: 2.5555\n",
      "Patience counter: 8\n",
      "Epoch: 82, Train loss: 0.3233, Val loss: 2.5650\n",
      "Patience counter: 9\n",
      "Epoch: 83, Train loss: 0.1949, Val loss: 2.5609\n",
      "Patience counter: 10\n",
      "Epoch: 84, Train loss: 0.2471, Val loss: 2.5686\n",
      "Patience counter: 11\n",
      "Epoch: 85, Train loss: 0.2666, Val loss: 2.5760\n",
      "Patience counter: 12\n",
      "Epoch: 86, Train loss: 0.2215, Val loss: 2.5901\n",
      "Patience counter: 13\n",
      "Epoch: 87, Train loss: 0.3254, Val loss: 2.5938\n",
      "Patience counter: 14\n",
      "Epoch: 88, Train loss: 0.1925, Val loss: 2.5857\n",
      "Patience counter: 15\n",
      "Epoch: 89, Train loss: 0.2387, Val loss: 2.5925\n",
      "Patience counter: 16\n",
      "Epoch: 90, Train loss: 0.3334, Val loss: 2.5982\n",
      "Patience counter: 17\n",
      "Epoch: 91, Train loss: 0.1778, Val loss: 2.5877\n",
      "Patience counter: 18\n",
      "Epoch: 92, Train loss: 0.2036, Val loss: 2.5734\n",
      "Patience counter: 19\n",
      "Epoch: 93, Train loss: 0.1898, Val loss: 2.5640\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-08\n",
      "Epoch: 94, Train loss: 0.2713, Val loss: 2.5593\n",
      "Patience counter: 1\n",
      "Epoch: 95, Train loss: 0.2442, Val loss: 2.5641\n",
      "Patience counter: 2\n",
      "Epoch: 96, Train loss: 0.1653, Val loss: 2.5728\n",
      "Patience counter: 3\n",
      "Epoch: 97, Train loss: 0.2207, Val loss: 2.6036\n",
      "Patience counter: 4\n",
      "Epoch: 98, Train loss: 0.3246, Val loss: 2.6012\n",
      "Patience counter: 5\n",
      "Epoch: 99, Train loss: 0.1240, Val loss: 2.5852\n",
      "Patience counter: 6\n",
      "Epoch: 100, Train loss: 0.2597, Val loss: 2.5838\n",
      "Patience counter: 7\n",
      "Epoch: 101, Train loss: 0.2072, Val loss: 2.5651\n",
      "Patience counter: 8\n",
      "Epoch: 102, Train loss: 0.2556, Val loss: 2.5771\n",
      "Patience counter: 9\n",
      "Epoch: 103, Train loss: 0.2106, Val loss: 2.5897\n",
      "Patience counter: 10\n",
      "Epoch: 104, Train loss: 0.2941, Val loss: 2.5858\n",
      "Patience counter: 11\n",
      "Epoch: 105, Train loss: 0.2253, Val loss: 2.5822\n",
      "Patience counter: 12\n",
      "Epoch: 106, Train loss: 0.2364, Val loss: 2.5794\n",
      "Patience counter: 13\n",
      "Epoch: 107, Train loss: 0.2189, Val loss: 2.5685\n",
      "Patience counter: 14\n",
      "Epoch: 108, Train loss: 0.3064, Val loss: 2.5706\n",
      "Patience counter: 15\n",
      "Epoch: 109, Train loss: 0.2305, Val loss: 2.5681\n",
      "Patience counter: 16\n",
      "Epoch: 110, Train loss: 0.2125, Val loss: 2.5581\n",
      "Patience counter: 17\n",
      "Epoch: 111, Train loss: 0.2334, Val loss: 2.5773\n",
      "Patience counter: 18\n",
      "Epoch: 112, Train loss: 0.2332, Val loss: 2.6001\n",
      "Patience counter: 19\n",
      "Epoch: 113, Train loss: 0.1841, Val loss: 2.5897\n",
      "Patience counter: 20\n",
      "Early stopping triggered. Learning rate has reached its minimum threshold (5.000000000000001e-08).\n",
      "Test Loss: 0.7019, MSE: 0.7019, MAE: 0.6784, R2: 0.2953\n",
      "Epoch: 0, Train loss: 1.9398, Val loss: 1.9799\n",
      "Model has been saved!\n",
      "Epoch: 1, Train loss: 1.1759, Val loss: 1.5504\n",
      "Model has been saved!\n",
      "Epoch: 2, Train loss: 0.7445, Val loss: 1.2208\n",
      "Model has been saved!\n",
      "Epoch: 3, Train loss: 0.5649, Val loss: 1.1154\n",
      "Model has been saved!\n",
      "Epoch: 4, Train loss: 0.4423, Val loss: 1.0939\n",
      "Model has been saved!\n",
      "Epoch: 5, Train loss: 0.3995, Val loss: 1.0748\n",
      "Model has been saved!\n",
      "Epoch: 6, Train loss: 0.3581, Val loss: 1.0747\n",
      "Model has been saved!\n",
      "Epoch: 7, Train loss: 0.3574, Val loss: 1.0710\n",
      "Model has been saved!\n",
      "Epoch: 8, Train loss: 0.3760, Val loss: 1.1457\n",
      "Patience counter: 1\n",
      "Epoch: 9, Train loss: 0.3492, Val loss: 1.1088\n",
      "Patience counter: 2\n",
      "Epoch: 10, Train loss: 0.3322, Val loss: 1.0588\n",
      "Model has been saved!\n",
      "Epoch: 11, Train loss: 0.3578, Val loss: 1.0936\n",
      "Patience counter: 1\n",
      "Epoch: 12, Train loss: 0.2672, Val loss: 1.1247\n",
      "Patience counter: 2\n",
      "Epoch: 13, Train loss: 0.3099, Val loss: 1.1382\n",
      "Patience counter: 3\n",
      "Epoch: 14, Train loss: 0.2760, Val loss: 1.0745\n",
      "Patience counter: 4\n",
      "Epoch: 15, Train loss: 0.2627, Val loss: 1.0760\n",
      "Patience counter: 5\n",
      "Epoch: 16, Train loss: 0.2992, Val loss: 1.0605\n",
      "Patience counter: 6\n",
      "Epoch: 17, Train loss: 0.2434, Val loss: 1.0759\n",
      "Patience counter: 7\n",
      "Epoch: 18, Train loss: 0.2665, Val loss: 1.0391\n",
      "Model has been saved!\n",
      "Epoch: 19, Train loss: 0.3043, Val loss: 1.0825\n",
      "Patience counter: 1\n",
      "Epoch: 20, Train loss: 0.2551, Val loss: 1.0759\n",
      "Patience counter: 2\n",
      "Epoch: 21, Train loss: 0.2620, Val loss: 1.0498\n",
      "Patience counter: 3\n",
      "Epoch: 22, Train loss: 0.2570, Val loss: 1.1033\n",
      "Patience counter: 4\n",
      "Epoch: 23, Train loss: 0.2363, Val loss: 1.0741\n",
      "Patience counter: 5\n",
      "Epoch: 24, Train loss: 0.2295, Val loss: 1.1072\n",
      "Patience counter: 6\n",
      "Epoch: 25, Train loss: 0.2312, Val loss: 1.0977\n",
      "Patience counter: 7\n",
      "Epoch: 26, Train loss: 0.2258, Val loss: 1.0890\n",
      "Patience counter: 8\n",
      "Epoch: 27, Train loss: 0.2287, Val loss: 1.0555\n",
      "Patience counter: 9\n",
      "Epoch: 28, Train loss: 0.2003, Val loss: 1.0595\n",
      "Patience counter: 10\n",
      "Epoch: 29, Train loss: 0.2143, Val loss: 1.1043\n",
      "Patience counter: 11\n",
      "Epoch: 30, Train loss: 0.2411, Val loss: 1.1343\n",
      "Patience counter: 12\n",
      "Epoch: 31, Train loss: 0.2371, Val loss: 1.1717\n",
      "Patience counter: 13\n",
      "Epoch: 32, Train loss: 0.2159, Val loss: 1.1292\n",
      "Patience counter: 14\n",
      "Epoch: 33, Train loss: 0.2063, Val loss: 1.0857\n",
      "Patience counter: 15\n",
      "Epoch: 34, Train loss: 0.2017, Val loss: 1.1117\n",
      "Patience counter: 16\n",
      "Epoch: 35, Train loss: 0.2110, Val loss: 1.0630\n",
      "Patience counter: 17\n",
      "Epoch: 36, Train loss: 0.1674, Val loss: 1.0939\n",
      "Patience counter: 18\n",
      "Epoch: 37, Train loss: 0.1902, Val loss: 1.1159\n",
      "Patience counter: 19\n",
      "Epoch: 38, Train loss: 0.2043, Val loss: 1.1519\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-05\n",
      "Epoch: 39, Train loss: 0.1973, Val loss: 1.1708\n",
      "Patience counter: 1\n",
      "Epoch: 40, Train loss: 0.1739, Val loss: 1.1391\n",
      "Patience counter: 2\n",
      "Epoch: 41, Train loss: 0.1828, Val loss: 1.1316\n",
      "Patience counter: 3\n",
      "Epoch: 42, Train loss: 0.1846, Val loss: 1.1314\n",
      "Patience counter: 4\n",
      "Epoch: 43, Train loss: 0.1915, Val loss: 1.1425\n",
      "Patience counter: 5\n",
      "Epoch: 44, Train loss: 0.1862, Val loss: 1.1292\n",
      "Patience counter: 6\n",
      "Epoch: 45, Train loss: 0.1679, Val loss: 1.1421\n",
      "Patience counter: 7\n",
      "Epoch: 46, Train loss: 0.2033, Val loss: 1.1251\n",
      "Patience counter: 8\n",
      "Epoch: 47, Train loss: 0.1886, Val loss: 1.1325\n",
      "Patience counter: 9\n",
      "Epoch: 48, Train loss: 0.1818, Val loss: 1.1342\n",
      "Patience counter: 10\n",
      "Epoch: 49, Train loss: 0.1763, Val loss: 1.1447\n",
      "Patience counter: 11\n",
      "Epoch: 50, Train loss: 0.1866, Val loss: 1.1423\n",
      "Patience counter: 12\n",
      "Epoch: 51, Train loss: 0.1982, Val loss: 1.1484\n",
      "Patience counter: 13\n",
      "Epoch: 52, Train loss: 0.1806, Val loss: 1.1391\n",
      "Patience counter: 14\n",
      "Epoch: 53, Train loss: 0.1835, Val loss: 1.1426\n",
      "Patience counter: 15\n",
      "Epoch: 54, Train loss: 0.1956, Val loss: 1.1495\n",
      "Patience counter: 16\n",
      "Epoch: 55, Train loss: 0.1618, Val loss: 1.1245\n",
      "Patience counter: 17\n",
      "Epoch: 56, Train loss: 0.1837, Val loss: 1.1220\n",
      "Patience counter: 18\n",
      "Epoch: 57, Train loss: 0.1670, Val loss: 1.1277\n",
      "Patience counter: 19\n",
      "Epoch: 58, Train loss: 0.1659, Val loss: 1.1239\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-06\n",
      "Epoch: 59, Train loss: 0.1725, Val loss: 1.1339\n",
      "Patience counter: 1\n",
      "Epoch: 60, Train loss: 0.1676, Val loss: 1.1152\n",
      "Patience counter: 2\n",
      "Epoch: 61, Train loss: 0.1536, Val loss: 1.1272\n",
      "Patience counter: 3\n",
      "Epoch: 62, Train loss: 0.1620, Val loss: 1.1177\n",
      "Patience counter: 4\n",
      "Epoch: 63, Train loss: 0.1967, Val loss: 1.1146\n",
      "Patience counter: 5\n",
      "Epoch: 64, Train loss: 0.1693, Val loss: 1.1329\n",
      "Patience counter: 6\n",
      "Epoch: 65, Train loss: 0.1635, Val loss: 1.1185\n",
      "Patience counter: 7\n",
      "Epoch: 66, Train loss: 0.1733, Val loss: 1.1268\n",
      "Patience counter: 8\n",
      "Epoch: 67, Train loss: 0.1773, Val loss: 1.1285\n",
      "Patience counter: 9\n",
      "Epoch: 68, Train loss: 0.1821, Val loss: 1.1440\n",
      "Patience counter: 10\n",
      "Epoch: 69, Train loss: 0.1958, Val loss: 1.1345\n",
      "Patience counter: 11\n",
      "Epoch: 70, Train loss: 0.1919, Val loss: 1.1306\n",
      "Patience counter: 12\n",
      "Epoch: 71, Train loss: 0.1718, Val loss: 1.1326\n",
      "Patience counter: 13\n",
      "Epoch: 72, Train loss: 0.1579, Val loss: 1.1226\n",
      "Patience counter: 14\n",
      "Epoch: 73, Train loss: 0.1703, Val loss: 1.1170\n",
      "Patience counter: 15\n",
      "Epoch: 74, Train loss: 0.1678, Val loss: 1.1238\n",
      "Patience counter: 16\n",
      "Epoch: 75, Train loss: 0.1742, Val loss: 1.1307\n",
      "Patience counter: 17\n",
      "Epoch: 76, Train loss: 0.1813, Val loss: 1.1311\n",
      "Patience counter: 18\n",
      "Epoch: 77, Train loss: 0.1863, Val loss: 1.1194\n",
      "Patience counter: 19\n",
      "Epoch: 78, Train loss: 0.1832, Val loss: 1.1386\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-07\n",
      "Epoch: 79, Train loss: 0.1820, Val loss: 1.1275\n",
      "Patience counter: 1\n",
      "Epoch: 80, Train loss: 0.1758, Val loss: 1.1201\n",
      "Patience counter: 2\n",
      "Epoch: 81, Train loss: 0.1680, Val loss: 1.1166\n",
      "Patience counter: 3\n",
      "Epoch: 82, Train loss: 0.1513, Val loss: 1.1227\n",
      "Patience counter: 4\n",
      "Epoch: 83, Train loss: 0.1780, Val loss: 1.1317\n",
      "Patience counter: 5\n",
      "Epoch: 84, Train loss: 0.1494, Val loss: 1.1228\n",
      "Patience counter: 6\n",
      "Epoch: 85, Train loss: 0.2008, Val loss: 1.1134\n",
      "Patience counter: 7\n",
      "Epoch: 86, Train loss: 0.1548, Val loss: 1.1179\n",
      "Patience counter: 8\n",
      "Epoch: 87, Train loss: 0.1681, Val loss: 1.1271\n",
      "Patience counter: 9\n",
      "Epoch: 88, Train loss: 0.1571, Val loss: 1.1262\n",
      "Patience counter: 10\n",
      "Epoch: 89, Train loss: 0.1829, Val loss: 1.1155\n",
      "Patience counter: 11\n",
      "Epoch: 90, Train loss: 0.1777, Val loss: 1.1266\n",
      "Patience counter: 12\n",
      "Epoch: 91, Train loss: 0.1707, Val loss: 1.1277\n",
      "Patience counter: 13\n",
      "Epoch: 92, Train loss: 0.1686, Val loss: 1.1282\n",
      "Patience counter: 14\n",
      "Epoch: 93, Train loss: 0.1527, Val loss: 1.1225\n",
      "Patience counter: 15\n",
      "Epoch: 94, Train loss: 0.1632, Val loss: 1.1312\n",
      "Patience counter: 16\n",
      "Epoch: 95, Train loss: 0.1913, Val loss: 1.1149\n",
      "Patience counter: 17\n",
      "Epoch: 96, Train loss: 0.1759, Val loss: 1.1378\n",
      "Patience counter: 18\n",
      "Epoch: 97, Train loss: 0.1491, Val loss: 1.1256\n",
      "Patience counter: 19\n",
      "Epoch: 98, Train loss: 0.1526, Val loss: 1.1201\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-08\n",
      "Epoch: 99, Train loss: 0.1851, Val loss: 1.1260\n",
      "Patience counter: 1\n",
      "Epoch: 100, Train loss: 0.1484, Val loss: 1.1252\n",
      "Patience counter: 2\n",
      "Epoch: 101, Train loss: 0.1721, Val loss: 1.1191\n",
      "Patience counter: 3\n",
      "Epoch: 102, Train loss: 0.1904, Val loss: 1.1197\n",
      "Patience counter: 4\n",
      "Epoch: 103, Train loss: 0.1620, Val loss: 1.1281\n",
      "Patience counter: 5\n",
      "Epoch: 104, Train loss: 0.1544, Val loss: 1.1281\n",
      "Patience counter: 6\n",
      "Epoch: 105, Train loss: 0.1725, Val loss: 1.1316\n",
      "Patience counter: 7\n",
      "Epoch: 106, Train loss: 0.1674, Val loss: 1.1282\n",
      "Patience counter: 8\n",
      "Epoch: 107, Train loss: 0.1605, Val loss: 1.1203\n",
      "Patience counter: 9\n",
      "Epoch: 108, Train loss: 0.1553, Val loss: 1.1118\n",
      "Patience counter: 10\n",
      "Epoch: 109, Train loss: 0.1614, Val loss: 1.1173\n",
      "Patience counter: 11\n",
      "Epoch: 110, Train loss: 0.1565, Val loss: 1.1157\n",
      "Patience counter: 12\n",
      "Epoch: 111, Train loss: 0.1946, Val loss: 1.1350\n",
      "Patience counter: 13\n",
      "Epoch: 112, Train loss: 0.1690, Val loss: 1.1365\n",
      "Patience counter: 14\n",
      "Epoch: 113, Train loss: 0.1774, Val loss: 1.1262\n",
      "Patience counter: 15\n",
      "Epoch: 114, Train loss: 0.1660, Val loss: 1.1315\n",
      "Patience counter: 16\n",
      "Epoch: 115, Train loss: 0.1883, Val loss: 1.1226\n",
      "Patience counter: 17\n",
      "Epoch: 116, Train loss: 0.1879, Val loss: 1.1314\n",
      "Patience counter: 18\n",
      "Epoch: 117, Train loss: 0.1671, Val loss: 1.1142\n",
      "Patience counter: 19\n",
      "Epoch: 118, Train loss: 0.1940, Val loss: 1.1342\n",
      "Patience counter: 20\n",
      "Early stopping triggered. Learning rate has reached its minimum threshold (5.000000000000001e-08).\n",
      "Test Loss: 0.6495, MSE: 0.6312, MAE: 0.5282, R2: 0.2808\n"
     ]
    }
   ],
   "source": [
    "# 训练模型，设置epoch数为100\n",
    "epochs = 200\n",
    "\n",
    "# 阴离子氧化势MLP\n",
    "anion_ox_train_losses_mlp, anion_ox_val_losses_mlp, anion_ox_test_pred_mlp, anion_ox_test_true_mlp, anion_ox_test_mse_mlp, anion_ox_test_mae_mlp, anion_ox_test_r2_mlp = train_epochs_mlp(\n",
    "    0, epochs, model_anion_ox_MLP, anion_ox_train_loader, anion_ox_val_loader, anion_ox_test_loader, \"anion_ox_MLP_model.pt\"\n",
    ")\n",
    "\n",
    "# 阳离子还原势MLP\n",
    "cation_red_train_losses_mlp, cation_red_val_losses_mlp, cation_red_test_pred_mlp, cation_red_test_true_mlp, cation_red_test_mse_mlp, cation_red_test_mae_mlp, cation_red_test_r2_mlp = train_epochs_mlp(\n",
    "    0, epochs, model_cation_red_MLP, cation_red_train_loader, cation_red_val_loader, cation_red_test_loader, \"cation_red_MLP_model.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7081906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练模型，设置epoch数为100\n",
    "epochs = 200\n",
    "\n",
    "# 阳离子还原势GAT模型\n",
    "IL_ECW_train_losses_mlp, IL_ECW_val_losses_mlp, IL_ECW_test_pred_mlp, IL_ECW_test_true_mlp, IL_ECW_test_mse_mlp, IL_ECW_test_mae_mlp, IL_ECW_test_r2_mlp = train_epochs_mlp(\n",
    "    0, epochs, model_IL_ECW_MLP, IL_ECW_train_loader, IL_ECW_val_loader, IL_ECW_test_loader, \"IL_ECW_MLP_model.pt\", input_type=\"fp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a93277b-a3e2-4134-bf37-1fb7ff702983",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def plot_loss(train_loss, val_loss):\n",
    "    # 绘制损失曲线\n",
    "    plt.plot(train_loss, label=\"Train loss\")\n",
    "    plt.plot(val_loss, label=\"Val loss\")\n",
    "    plt.legend()  # 添加图例\n",
    "    # plt.ylim(0, 2)  # 设置Y轴范围\n",
    "    plt.ylabel(\"Loss\")  # 设置Y轴标签\n",
    "    plt.xlabel(\"Epoch\")  # 设置X轴标签\n",
    "    plt.title(\"Model Loss\")  # 设置标题\n",
    "    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))  # 设置X轴刻度为整数\n",
    "    plt.show()  # 显示图像\n",
    "'''\n",
    "请你修改我给出的下列代码，函数的输入值原本为pred和ground_truth，我希望更改为cation_pred，cation_ground_truth，anion_pred，anion_ground_truth\n",
    "去除mse和mae，文本仅显示模型参数量。\n",
    "其中cation_pred，cation_ground_truth的散点用红色表示，anion_pred，anion_ground_truth的散点用蓝色表示。\n",
    "'''\n",
    "def plot_targets(pred, ground_truth, mse , mae, save_path=\"GAT_val.png\", figsize=(2.3, 2.3)):\n",
    "    \n",
    "    from sklearn.metrics import r2_score\n",
    "    \n",
    "    # 计算 R²（决定系数）\n",
    "    r2 = r2_score(ground_truth, pred)\n",
    "    # 绘制预测值与真实值的对比散点图\n",
    "    f, ax = plt.subplots(figsize=figsize)  # 创建图和轴对象\n",
    "    ax.scatter(pred, ground_truth, s=0.5)  # 绘制散点图\n",
    "    ax.axline((1, 1), slope=1, color=\"red\", linestyle=\"--\")  # 添加参考线\n",
    "    plt.xlabel(\"Predicted Value\")  # 设置X轴标签\n",
    "    plt.ylabel(\"Ground Truth\")  # 设置Y轴标签\n",
    "    # plt.title(\"Ground Truth vs Prediction\")  # 设置标题\n",
    "\n",
    "    # 在左上角显示 MAE 和 MSE\n",
    "    text_str = f\"MAE = {mae:.2f}\\nMSE = {mse:.2f}\\nR² = {r2:.2f}\\n\"\n",
    "    plt.text(\n",
    "        0.05, 0.95, text_str,\n",
    "        transform=ax.transAxes,  # 使用轴坐标进行定位\n",
    "        fontsize=7, color=\"black\",\n",
    "        verticalalignment=\"top\", horizontalalignment=\"left\"\n",
    "    )\n",
    "    # 保存图片\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")  # 保存图片，分辨率300 DPI\n",
    "    plt.show()  # 显示图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "902d0dc7-8f92-4399-b211-440d596b4952",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def plot_cation_anion_targets(cation_pred, cation_ground_truth, anion_pred, anion_ground_truth, title=\"GAT\", save_path=\"GAT_cation_anion_val.png\"):\n",
    "    \n",
    "    # 创建图和轴对象\n",
    "    fig, ax = plt.subplots(figsize=(1.75, 1.75))\n",
    "    \n",
    "    # 绘制阳离子的散点图（红色）\n",
    "    ax.scatter(cation_pred, cation_ground_truth, s=0.5, color='#f7c0c5', label='Cation')\n",
    "    \n",
    "    # 绘制阴离子的散点图（蓝色）\n",
    "    ax.scatter(anion_pred, anion_ground_truth, s=0.5, color='#bfcfe4', label='Anion')\n",
    "    \n",
    "    # 添加参考线 y = x\n",
    "    ax.axline((0, 0), slope=1, color=\"gray\", linestyle=\"--\")\n",
    "    \n",
    "    # 设置坐标轴标签\n",
    "    plt.xlabel(\"Predicted Value\")\n",
    "    plt.ylabel(\"Ground Truth\")\n",
    "    \n",
    "    # 在图例中显示标签\n",
    "    ax.legend(loc='lower right')\n",
    "    plt.title(title)\n",
    "    \n",
    "    # 保存图片\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6bd7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Train loss: 0.1505, Val loss: 0.0543\n",
      "Model has been saved!\n",
      "Epoch: 1, Train loss: 0.1316, Val loss: 0.0612\n",
      "Patience counter: 1\n",
      "Epoch: 2, Train loss: 0.1115, Val loss: 0.0669\n",
      "Patience counter: 2\n",
      "Epoch: 3, Train loss: 0.1058, Val loss: 0.0648\n",
      "Patience counter: 3\n",
      "Epoch: 4, Train loss: 0.1221, Val loss: 0.0744\n",
      "Patience counter: 4\n",
      "Epoch: 5, Train loss: 0.1064, Val loss: 0.0748\n",
      "Patience counter: 5\n",
      "Epoch: 6, Train loss: 0.1202, Val loss: 0.0479\n",
      "Model has been saved!\n",
      "Epoch: 7, Train loss: 0.0865, Val loss: 0.0519\n",
      "Patience counter: 1\n",
      "Epoch: 8, Train loss: 0.0934, Val loss: 0.0539\n",
      "Patience counter: 2\n",
      "Epoch: 9, Train loss: 0.0921, Val loss: 0.0568\n",
      "Patience counter: 3\n",
      "Epoch: 10, Train loss: 0.0810, Val loss: 0.0552\n",
      "Patience counter: 4\n",
      "Epoch: 11, Train loss: 0.0938, Val loss: 0.0572\n",
      "Patience counter: 5\n",
      "Epoch: 12, Train loss: 0.0991, Val loss: 0.0603\n",
      "Patience counter: 6\n",
      "Epoch: 13, Train loss: 0.0900, Val loss: 0.0477\n",
      "Model has been saved!\n",
      "Epoch: 14, Train loss: 0.0756, Val loss: 0.0413\n",
      "Model has been saved!\n",
      "Epoch: 15, Train loss: 0.0877, Val loss: 0.0590\n",
      "Patience counter: 1\n",
      "Epoch: 16, Train loss: 0.0903, Val loss: 0.0550\n",
      "Patience counter: 2\n",
      "Epoch: 17, Train loss: 0.0897, Val loss: 0.0655\n",
      "Patience counter: 3\n",
      "Epoch: 18, Train loss: 0.0786, Val loss: 0.0654\n",
      "Patience counter: 4\n",
      "Epoch: 19, Train loss: 0.0750, Val loss: 0.0643\n",
      "Patience counter: 5\n",
      "Epoch: 20, Train loss: 0.0723, Val loss: 0.0692\n",
      "Patience counter: 6\n",
      "Epoch: 21, Train loss: 0.0611, Val loss: 0.0682\n",
      "Patience counter: 7\n",
      "Epoch: 22, Train loss: 0.0604, Val loss: 0.0548\n",
      "Patience counter: 8\n",
      "Epoch: 23, Train loss: 0.0606, Val loss: 0.0437\n",
      "Patience counter: 9\n",
      "Epoch: 24, Train loss: 0.0408, Val loss: 0.0450\n",
      "Patience counter: 10\n",
      "Epoch: 25, Train loss: 0.0496, Val loss: 0.0546\n",
      "Patience counter: 11\n",
      "Epoch: 26, Train loss: 0.0601, Val loss: 0.0747\n",
      "Patience counter: 12\n",
      "Epoch: 27, Train loss: 0.0505, Val loss: 0.0740\n",
      "Patience counter: 13\n",
      "Epoch: 28, Train loss: 0.0373, Val loss: 0.0598\n",
      "Patience counter: 14\n",
      "Epoch: 29, Train loss: 0.0452, Val loss: 0.0417\n",
      "Patience counter: 15\n",
      "Epoch: 30, Train loss: 0.0484, Val loss: 0.0413\n",
      "Model has been saved!\n",
      "Epoch: 31, Train loss: 0.0492, Val loss: 0.0477\n",
      "Patience counter: 1\n",
      "Epoch: 32, Train loss: 0.0519, Val loss: 0.0590\n",
      "Patience counter: 2\n",
      "Epoch: 33, Train loss: 0.0505, Val loss: 0.0593\n",
      "Patience counter: 3\n",
      "Epoch: 34, Train loss: 0.0497, Val loss: 0.0506\n",
      "Patience counter: 4\n",
      "Epoch: 35, Train loss: 0.0431, Val loss: 0.0445\n",
      "Patience counter: 5\n",
      "Epoch: 36, Train loss: 0.0474, Val loss: 0.0433\n",
      "Patience counter: 6\n",
      "Epoch: 37, Train loss: 0.0515, Val loss: 0.0465\n",
      "Patience counter: 7\n",
      "Epoch: 38, Train loss: 0.0568, Val loss: 0.0516\n",
      "Patience counter: 8\n",
      "Epoch: 39, Train loss: 0.0562, Val loss: 0.0608\n",
      "Patience counter: 9\n",
      "Epoch: 40, Train loss: 0.0701, Val loss: 0.0499\n",
      "Patience counter: 10\n",
      "Epoch: 41, Train loss: 0.0649, Val loss: 0.0554\n",
      "Patience counter: 11\n",
      "Epoch: 42, Train loss: 0.0509, Val loss: 0.0547\n",
      "Patience counter: 12\n",
      "Epoch: 43, Train loss: 0.0533, Val loss: 0.0550\n",
      "Patience counter: 13\n",
      "Epoch: 44, Train loss: 0.0509, Val loss: 0.0511\n",
      "Patience counter: 14\n",
      "Epoch: 45, Train loss: 0.0291, Val loss: 0.0557\n",
      "Patience counter: 15\n",
      "Epoch: 46, Train loss: 0.0607, Val loss: 0.0586\n",
      "Patience counter: 16\n",
      "Epoch: 47, Train loss: 0.0432, Val loss: 0.0487\n",
      "Patience counter: 17\n",
      "Epoch: 48, Train loss: 0.0357, Val loss: 0.0488\n",
      "Patience counter: 18\n",
      "Epoch: 49, Train loss: 0.0413, Val loss: 0.0492\n",
      "Patience counter: 19\n",
      "Epoch: 50, Train loss: 0.0258, Val loss: 0.0508\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-05\n",
      "Epoch: 51, Train loss: 0.0421, Val loss: 0.0512\n",
      "Patience counter: 1\n",
      "Epoch: 52, Train loss: 0.0403, Val loss: 0.0496\n",
      "Patience counter: 2\n",
      "Epoch: 53, Train loss: 0.0335, Val loss: 0.0484\n",
      "Patience counter: 3\n",
      "Epoch: 54, Train loss: 0.0500, Val loss: 0.0473\n",
      "Patience counter: 4\n",
      "Epoch: 55, Train loss: 0.0363, Val loss: 0.0480\n",
      "Patience counter: 5\n",
      "Epoch: 56, Train loss: 0.0290, Val loss: 0.0473\n",
      "Patience counter: 6\n",
      "Epoch: 57, Train loss: 0.0447, Val loss: 0.0469\n",
      "Patience counter: 7\n",
      "Epoch: 58, Train loss: 0.0384, Val loss: 0.0491\n",
      "Patience counter: 8\n",
      "Epoch: 59, Train loss: 0.0460, Val loss: 0.0493\n",
      "Patience counter: 9\n",
      "Epoch: 60, Train loss: 0.0370, Val loss: 0.0500\n",
      "Patience counter: 10\n",
      "Epoch: 61, Train loss: 0.0561, Val loss: 0.0518\n",
      "Patience counter: 11\n",
      "Epoch: 62, Train loss: 0.0366, Val loss: 0.0529\n",
      "Patience counter: 12\n",
      "Epoch: 63, Train loss: 0.0477, Val loss: 0.0525\n",
      "Patience counter: 13\n",
      "Epoch: 64, Train loss: 0.0310, Val loss: 0.0537\n",
      "Patience counter: 14\n",
      "Epoch: 65, Train loss: 0.0341, Val loss: 0.0522\n",
      "Patience counter: 15\n",
      "Epoch: 66, Train loss: 0.0336, Val loss: 0.0497\n",
      "Patience counter: 16\n",
      "Epoch: 67, Train loss: 0.0404, Val loss: 0.0488\n",
      "Patience counter: 17\n",
      "Epoch: 68, Train loss: 0.0315, Val loss: 0.0526\n",
      "Patience counter: 18\n",
      "Epoch: 69, Train loss: 0.0266, Val loss: 0.0533\n",
      "Patience counter: 19\n",
      "Epoch: 70, Train loss: 0.0367, Val loss: 0.0534\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5e-06\n",
      "Epoch: 71, Train loss: 0.0310, Val loss: 0.0534\n",
      "Patience counter: 1\n",
      "Epoch: 72, Train loss: 0.0447, Val loss: 0.0527\n",
      "Patience counter: 2\n",
      "Epoch: 73, Train loss: 0.0295, Val loss: 0.0534\n",
      "Patience counter: 3\n",
      "Epoch: 74, Train loss: 0.0302, Val loss: 0.0541\n",
      "Patience counter: 4\n",
      "Epoch: 75, Train loss: 0.0355, Val loss: 0.0543\n",
      "Patience counter: 5\n",
      "Epoch: 76, Train loss: 0.0291, Val loss: 0.0551\n",
      "Patience counter: 6\n",
      "Epoch: 77, Train loss: 0.0354, Val loss: 0.0537\n",
      "Patience counter: 7\n",
      "Epoch: 78, Train loss: 0.0275, Val loss: 0.0535\n",
      "Patience counter: 8\n",
      "Epoch: 79, Train loss: 0.0380, Val loss: 0.0559\n",
      "Patience counter: 9\n",
      "Epoch: 80, Train loss: 0.0456, Val loss: 0.0567\n",
      "Patience counter: 10\n",
      "Epoch: 81, Train loss: 0.0504, Val loss: 0.0502\n",
      "Patience counter: 11\n",
      "Epoch: 82, Train loss: 0.0350, Val loss: 0.0523\n",
      "Patience counter: 12\n",
      "Epoch: 83, Train loss: 0.0387, Val loss: 0.0523\n",
      "Patience counter: 13\n",
      "Epoch: 84, Train loss: 0.0359, Val loss: 0.0487\n",
      "Patience counter: 14\n",
      "Epoch: 85, Train loss: 0.0287, Val loss: 0.0495\n",
      "Patience counter: 15\n",
      "Epoch: 86, Train loss: 0.0290, Val loss: 0.0501\n",
      "Patience counter: 16\n",
      "Epoch: 87, Train loss: 0.0372, Val loss: 0.0494\n",
      "Patience counter: 17\n",
      "Epoch: 88, Train loss: 0.0306, Val loss: 0.0504\n",
      "Patience counter: 18\n",
      "Epoch: 89, Train loss: 0.0340, Val loss: 0.0513\n",
      "Patience counter: 19\n",
      "Epoch: 90, Train loss: 0.0431, Val loss: 0.0549\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-07\n",
      "Epoch: 91, Train loss: 0.0388, Val loss: 0.0542\n",
      "Patience counter: 1\n",
      "Epoch: 92, Train loss: 0.0300, Val loss: 0.0535\n",
      "Patience counter: 2\n",
      "Epoch: 93, Train loss: 0.0381, Val loss: 0.0526\n",
      "Patience counter: 3\n",
      "Epoch: 94, Train loss: 0.0361, Val loss: 0.0551\n",
      "Patience counter: 4\n",
      "Epoch: 95, Train loss: 0.0381, Val loss: 0.0505\n",
      "Patience counter: 5\n",
      "Epoch: 96, Train loss: 0.0288, Val loss: 0.0528\n",
      "Patience counter: 6\n",
      "Epoch: 97, Train loss: 0.0296, Val loss: 0.0562\n",
      "Patience counter: 7\n",
      "Epoch: 98, Train loss: 0.0266, Val loss: 0.0546\n",
      "Patience counter: 8\n",
      "Epoch: 99, Train loss: 0.0331, Val loss: 0.0557\n",
      "Patience counter: 9\n",
      "Epoch: 100, Train loss: 0.0319, Val loss: 0.0542\n",
      "Patience counter: 10\n",
      "Epoch: 101, Train loss: 0.0486, Val loss: 0.0511\n",
      "Patience counter: 11\n",
      "Epoch: 102, Train loss: 0.0631, Val loss: 0.0498\n",
      "Patience counter: 12\n",
      "Epoch: 103, Train loss: 0.0293, Val loss: 0.0481\n",
      "Patience counter: 13\n",
      "Epoch: 104, Train loss: 0.0346, Val loss: 0.0520\n",
      "Patience counter: 14\n",
      "Epoch: 105, Train loss: 0.0520, Val loss: 0.0475\n",
      "Patience counter: 15\n",
      "Epoch: 106, Train loss: 0.0458, Val loss: 0.0519\n",
      "Patience counter: 16\n",
      "Epoch: 107, Train loss: 0.0479, Val loss: 0.0536\n",
      "Patience counter: 17\n",
      "Epoch: 108, Train loss: 0.0271, Val loss: 0.0516\n",
      "Patience counter: 18\n",
      "Epoch: 109, Train loss: 0.0380, Val loss: 0.0514\n",
      "Patience counter: 19\n",
      "Epoch: 110, Train loss: 0.0337, Val loss: 0.0528\n",
      "Patience counter: 20\n",
      "Learning rate reduced to: 5.000000000000001e-08\n",
      "Epoch: 111, Train loss: 0.0480, Val loss: 0.0575\n",
      "Patience counter: 1\n",
      "Epoch: 112, Train loss: 0.0404, Val loss: 0.0571\n",
      "Patience counter: 2\n",
      "Epoch: 113, Train loss: 0.0283, Val loss: 0.0552\n",
      "Patience counter: 3\n",
      "Epoch: 114, Train loss: 0.0308, Val loss: 0.0559\n",
      "Patience counter: 4\n",
      "Epoch: 115, Train loss: 0.0368, Val loss: 0.0536\n",
      "Patience counter: 5\n",
      "Epoch: 116, Train loss: 0.0348, Val loss: 0.0533\n",
      "Patience counter: 6\n",
      "Epoch: 117, Train loss: 0.0486, Val loss: 0.0522\n",
      "Patience counter: 7\n",
      "Epoch: 118, Train loss: 0.0378, Val loss: 0.0475\n",
      "Patience counter: 8\n",
      "Epoch: 119, Train loss: 0.0362, Val loss: 0.0533\n",
      "Patience counter: 9\n",
      "Epoch: 120, Train loss: 0.0325, Val loss: 0.0519\n",
      "Patience counter: 10\n",
      "Epoch: 121, Train loss: 0.0335, Val loss: 0.0550\n",
      "Patience counter: 11\n",
      "Epoch: 122, Train loss: 0.0291, Val loss: 0.0522\n",
      "Patience counter: 12\n",
      "Epoch: 123, Train loss: 0.0407, Val loss: 0.0536\n",
      "Patience counter: 13\n",
      "Epoch: 124, Train loss: 0.0403, Val loss: 0.0533\n",
      "Patience counter: 14\n",
      "Epoch: 125, Train loss: 0.0429, Val loss: 0.0508\n",
      "Patience counter: 15\n",
      "Epoch: 126, Train loss: 0.0525, Val loss: 0.0488\n",
      "Patience counter: 16\n",
      "Epoch: 127, Train loss: 0.0231, Val loss: 0.0491\n",
      "Patience counter: 17\n",
      "Epoch: 128, Train loss: 0.0320, Val loss: 0.0541\n",
      "Patience counter: 18\n",
      "Epoch: 129, Train loss: 0.0295, Val loss: 0.0509\n",
      "Patience counter: 19\n",
      "Epoch: 130, Train loss: 0.0418, Val loss: 0.0543\n",
      "Patience counter: 20\n",
      "Early stopping triggered. Learning rate has reached its minimum threshold (5.000000000000001e-08).\n",
      "Test Loss: 0.0145, MSE: 0.0187, MAE: 0.1079, R2: 0.7746\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 175x175 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seed(421)\n",
    "# 电导率MLP模型\n",
    "conductivity_train_losses_mlp, conductivity_val_losses_mlp, conductivity_test_pred_mlp, conductivity_test_true_mlp, conductivity_test_mse_mlp, conductivity_test_mae_mlp, conductivity_test_r2_mlp = train_epochs_mlp(\n",
    "    0, epochs, model_conductivity_MLP, conductivity_train_loader, conductivity_val_loader, conductivity_test_loader, \"conductivity_MLP_model.pt\", input_type=\"fp\"\n",
    ")\n",
    "\n",
    "plot_targets(conductivity_test_pred_mlp, conductivity_test_true_mlp, conductivity_test_mse_mlp, conductivity_test_mae_mlp, save_path=\"conductivity_MLP_test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c6ec4-b0e7-4b62-9a61-47bd8d363386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 175x175 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_targets(cation_test_pred, cation_test_true, cation_gat_mse, cation_gat_mae, save_path=\"cation_GAT_val_LUMO.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e684c8-f57f-419d-9c25-bcae58912589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa22bd17-2c76-49b6-a8f2-844bca33042e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9126bc-5399-430b-8d55-7fc287394988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9bcabc-2b96-402f-bafe-83db76530691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
