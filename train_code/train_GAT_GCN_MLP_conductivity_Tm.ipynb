{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84a3200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import sys \n",
    "sys.path.insert(0, \"/data/jupyternotebook_public/jifengwang/17_HTQC_analysis/AI_prediction_properties\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f13b19-e16a-4368-892e-850b74a6f8a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool\n",
    "from torch_geometric.loader import DataLoader  \n",
    "from torch_geometric.nn import global_mean_pool, global_add_pool  \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from GATModel import GAT\n",
    "from GCNModel import GCN\n",
    "from MLPModel import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fdf900-30f1-49a7-a367-2f1ff71d8d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"style.mplstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ed9c4e-8651-4e49-9bab-61bdbc601b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    import random\n",
    "    random.seed(seed)  \n",
    "    np.random.seed(seed) \n",
    "    torch.manual_seed(seed) \n",
    "    torch.cuda.manual_seed(seed) \n",
    "    torch.backends.cudnn.deterministic = True \n",
    "    torch.backends.cudnn.benchmark = False \n",
    "\n",
    "set_seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c83b31-15f2-4679-ac72-0cc90bcf7e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def load_data_list(file_path):\n",
    "    return torch.load(file_path)\n",
    "\n",
    "############## Tm ##############\n",
    "Tm_load_file_path = '../dataset/Tm_data_list.pt' \n",
    "Tm_load_train_dataset_path = '../dataset/train_Tm_data_list.pt' \n",
    "Tm_load_val_dataset_path = '../dataset/val_Tm_data_list.pt' \n",
    "Tm_load_test_dataset_path = '../dataset/test_Tm_data_list.pt' \n",
    "\n",
    "\n",
    "Tm_loaded_data_list = load_data_list(Tm_load_file_path)\n",
    "Tm_loaded_train_data_list = load_data_list(Tm_load_train_dataset_path)\n",
    "Tm_loaded_val_data_list = load_data_list(Tm_load_val_dataset_path)\n",
    "Tm_loaded_test_data_list = load_data_list(Tm_load_test_dataset_path)\n",
    "\n",
    "Tm_train_loader = DataLoader(Tm_loaded_train_data_list, batch_size=32, shuffle=True)  \n",
    "Tm_val_loader = DataLoader(Tm_loaded_val_data_list, batch_size=32, shuffle=False)  \n",
    "Tm_test_loader = DataLoader(Tm_loaded_test_data_list, batch_size=32, shuffle=False) \n",
    "\n",
    "\n",
    "############## conductivity ##############\n",
    "conductivity_load_file_path = 'conductivity_data_list.pt'\n",
    "conductivity_load_train_dataset_path = 'train_conductivity_data_list.pt' \n",
    "conductivity_load_val_dataset_path = 'val_conductivity_data_list.pt'\n",
    "conductivity_load_test_dataset_path = 'test_conductivity_data_list.pt' \n",
    "\n",
    "conductivity_loaded_data_list = load_data_list(conductivity_load_file_path)\n",
    "conductivity_loaded_train_data_list = load_data_list(conductivity_load_train_dataset_path)\n",
    "conductivity_loaded_val_data_list = load_data_list(conductivity_load_val_dataset_path)\n",
    "conductivity_loaded_test_data_list = load_data_list(conductivity_load_test_dataset_path)\n",
    "\n",
    "\n",
    "conductivity_train_loader = DataLoader(conductivity_loaded_train_data_list, batch_size=32, shuffle=True)  \n",
    "conductivity_val_loader = DataLoader(conductivity_loaded_val_data_list, batch_size=32, shuffle=False)  \n",
    "conductivity_test_loader = DataLoader(conductivity_loaded_test_data_list, batch_size=32, shuffle=False)  \n",
    "\n",
    "######################ECW######################\n",
    "IL_ECW_save_total_dataset_path = '../dataset/IL_ECW_data_list.pt' \n",
    "IL_ECW_save_train_dataset_path = '../dataset/train_IL_ECW_data_list.pt' \n",
    "IL_ECW_save_val_dataset_path = '../dataset/val_IL_ECW_data_list.pt'\n",
    "IL_ECW_save_test_dataset_path = '../dataset/test_IL_ECW_data_list.pt'\n",
    "\n",
    "IL_ECW_loaded_data_list = load_data_list(IL_ECW_save_total_dataset_path)\n",
    "IL_ECW_loaded_train_data_list = load_data_list(IL_ECW_save_train_dataset_path)\n",
    "IL_ECW_loaded_val_data_list = load_data_list(IL_ECW_save_val_dataset_path)\n",
    "IL_ECW_loaded_test_data_list = load_data_list(IL_ECW_save_test_dataset_path)\n",
    "\n",
    "IL_ECW_train_loader = DataLoader(IL_ECW_loaded_train_data_list, batch_size=32, shuffle=True)  \n",
    "IL_ECW_val_loader = DataLoader(IL_ECW_loaded_val_data_list, batch_size=32, shuffle=False)  \n",
    "IL_ECW_test_loader = DataLoader(IL_ECW_loaded_test_data_list, batch_size=32, shuffle=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060632a3-e3e4-49fc-aa52-f05dd0bfea8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def training(index, loader, model, loss_fn, optimizer, scale=1):\n",
    "\n",
    "    model.train() \n",
    "    total_loss = 0  \n",
    "    \n",
    "    for data in loader: \n",
    "        data = data.to(device) \n",
    "        optimizer.zero_grad()  \n",
    "        data.x = data.x.float()  \n",
    "        out = model(data)  \n",
    "        loss = loss_fn(out, scale*data.y.view(-1, 1)) \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        total_loss += loss.item() \n",
    "        \n",
    "    average_loss = total_loss / len(loader)  \n",
    "\n",
    "    return average_loss  \n",
    "\n",
    "def validation(index, loader, model, loss_fn, scale=1):\n",
    "    model.eval()  \n",
    "    total_loss = 0  \n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for data in loader: \n",
    "            data = data.to(device) \n",
    "            data.x = data.x.float()  \n",
    "            out = model(data) \n",
    "            loss = loss_fn(out, scale*data.y.view(-1, 1)) \n",
    "            total_loss += loss.item() \n",
    "            \n",
    "    average_loss = total_loss / len(loader)\n",
    "    \n",
    "    return average_loss \n",
    "\n",
    "def train_epochs(index, epochs, model, train_loader, val_loader, test_loader, path, scale=1):\n",
    "\n",
    "    initial_lr = 5e-4\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), initial_lr, weight_decay=5e-4)  \n",
    "    loss_fn = torch.nn.MSELoss()  \n",
    "\n",
    "    train_losses = np.zeros(epochs) \n",
    "    val_losses = np.zeros(epochs) \n",
    "    best_loss = float('inf') \n",
    "\n",
    "    patience_counter = 0      \n",
    "    max_patience = epochs/10         \n",
    "\n",
    "    current_lr = initial_lr\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = training(index, train_loader, model, loss_fn, optimizer, scale)\n",
    "        val_loss = validation(index, val_loader, model, loss_fn, scale)\n",
    "        \n",
    "        train_losses[epoch] = train_loss\n",
    "        val_losses[epoch] = val_loss\n",
    "\n",
    "        print(f\"Epoch: {epoch}, Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), path)\n",
    "            print(\"Model has been saved!\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Patience counter: {patience_counter}\")\n",
    "            if patience_counter >= max_patience:\n",
    "                if current_lr > initial_lr / 1000:\n",
    "                    current_lr /= 10\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        param_group['lr'] = current_lr\n",
    "                    print(f\"Learning rate reduced to: {current_lr}\")\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    print(f\"Early stopping triggered. Learning rate has reached its minimum threshold ({current_lr}).\")\n",
    "                    break\n",
    "\n",
    "    model.load_state_dict(torch.load(path)) \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    test_pred = []\n",
    "    test_true = []\n",
    "    loss_fn = torch.nn.MSELoss() \n",
    "\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        data.x = data.x.float()\n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, scale*data.y.view(-1, 1))  \n",
    "        total_loss += loss.item()\n",
    "        test_pred.append(out.detach().cpu().numpy())\n",
    "        test_true.append(scale*data.y.cpu().numpy())\n",
    "\n",
    "    test_pred = np.concatenate(test_pred, axis=0)\n",
    "    test_true = np.concatenate(test_true, axis=0)\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "\n",
    "    test_pred_flat = test_pred.flatten()  \n",
    "    test_true_flat = test_true.flatten() \n",
    "    test_mse = mean_squared_error(test_true_flat, test_pred_flat)\n",
    "    test_mae = mean_absolute_error(test_true_flat, test_pred_flat)\n",
    "    test_r2 = r2_score(test_true_flat, test_pred_flat)\n",
    "\n",
    "    print(f\"Test Loss: {average_loss:.4f}, MSE: {test_mse:.4f}, MAE: {test_mae:.4f}, R2: {test_r2:.4f}\")\n",
    "    \n",
    "    return train_losses, val_losses, test_pred, test_true, test_mse, test_mae, test_r2 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678cc6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def training_mlp(index, loader, model, loss_fn, optimizer, scale=10, input_type=\"fp\"):\n",
    "\n",
    "    model.train() \n",
    "    total_loss = 0  \n",
    "    for data in loader: \n",
    "        data = data.to(device)  \n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        if input_type==\"fp\":\n",
    "            data.morgan_fp = data.morgan_fp.float() \n",
    "        elif input_type==\"2Ddescriptors\":\n",
    "            data.moldescriptor = data.moldescriptor.float() \n",
    "            \n",
    "        out = model(data) \n",
    "        loss = loss_fn(out, scale*data.y.view(-1, 1)) \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        total_loss += loss.item()\n",
    "    average_loss = total_loss / len(loader)\n",
    "    return average_loss\n",
    "\n",
    "def validation_mlp(index, loader, model, loss_fn, scale=10, input_type=\"fp\"):\n",
    "\n",
    "    model.eval() \n",
    "    total_loss = 0  \n",
    "    with torch.no_grad():  \n",
    "        for data in loader:  \n",
    "            data = data.to(device) \n",
    "            \n",
    "            if input_type==\"fp\":\n",
    "                data.morgan_fp = data.morgan_fp.float()  \n",
    "            elif input_type==\"2Ddescriptors\":\n",
    "                data.moldescriptor = data.moldescriptor.float() \n",
    "\n",
    "            out = model(data) \n",
    "            loss = loss_fn(out, scale*data.y.view(-1, 1))\n",
    "            total_loss += loss.item() \n",
    "    average_loss = total_loss / len(loader) \n",
    "    return average_loss \n",
    "\n",
    "def train_epochs_mlp(index, epochs, model, train_loader, val_loader, test_loader, path, scale=10, input_type=\"fp\"):\n",
    "\n",
    "    initial_lr = 5e-4\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=initial_lr, weight_decay=5e-4)\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "    train_losses = np.zeros(epochs) \n",
    "    val_losses = np.zeros(epochs) \n",
    "    best_loss = float('inf') \n",
    "\n",
    "    patience_counter = 0     \n",
    "    max_patience = epochs/10         \n",
    "    current_lr = initial_lr\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = training_mlp(index, train_loader, model, loss_fn, optimizer, scale, input_type=\"fp\")\n",
    "        val_loss = validation_mlp(index, val_loader, model, loss_fn, scale, input_type=\"fp\")\n",
    "        \n",
    "        train_losses[epoch] = train_loss\n",
    "        val_losses[epoch] = val_loss\n",
    "        \n",
    "        print(f\"Epoch: {epoch}, Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}\")\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            torch.save(model.state_dict(), path)\n",
    "            print(\"Model has been saved!\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Patience counter: {patience_counter}\")\n",
    "            if patience_counter >= max_patience:\n",
    "                if current_lr > initial_lr / 1000:\n",
    "                    current_lr /= 10\n",
    "                    for param_group in optimizer.param_groups:\n",
    "                        param_group['lr'] = current_lr\n",
    "                    print(f\"Learning rate reduced to: {current_lr}\")\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    print(f\"Early stopping triggered. Learning rate has reached its minimum threshold ({current_lr}).\")\n",
    "                    break\n",
    "\n",
    "    model.load_state_dict(torch.load(path)) \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    test_pred = []\n",
    "    test_true = []\n",
    "    loss_fn = torch.nn.MSELoss() \n",
    "\n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        if input_type==\"fp\":\n",
    "            data.morgan_fp = data.morgan_fp.float()\n",
    "        elif input_type==\"2Ddescriptors\":\n",
    "            data.moldescriptor = data.moldescriptor.float() \n",
    "        out = model(data)\n",
    "        loss = loss_fn(out, scale*data.y.view(-1, 1)) \n",
    "        total_loss += loss.item()\n",
    "        test_pred.append(out.detach().cpu().numpy())\n",
    "        test_true.append(scale*data.y.cpu().numpy())\n",
    "\n",
    "    test_pred = np.concatenate(test_pred, axis=0)\n",
    "    test_true = np.concatenate(test_true, axis=0)\n",
    "    average_loss = total_loss / len(test_loader)\n",
    "\n",
    "    test_pred_flat = test_pred.flatten()  \n",
    "    test_true_flat = test_true.flatten()  \n",
    "    test_mse = mean_squared_error(test_true_flat, test_pred_flat)\n",
    "    test_mae = mean_absolute_error(test_true_flat, test_pred_flat)\n",
    "    test_r2 = r2_score(test_true_flat, test_pred_flat)\n",
    "\n",
    "    print(f\"Test Loss: {average_loss:.4f}, MSE: {test_mse:.4f}, MAE: {test_mae:.4f}, R2: {test_r2:.4f}\")\n",
    "    \n",
    "    return train_losses, val_losses, test_pred, test_true, test_mse, test_mae, test_r2 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cd444c-a852-4d03-b102-d6308967538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAT\n",
    "model_Tm_GAT = GAT(in_channels=5,hidden_channels=256).to(device)  \n",
    "model_conductivity_GAT = GAT(in_channels=5,hidden_channels=256).to(device)  \n",
    "model_anion_ox_GAT = GAT(in_channels=5,hidden_channels=256).to(device)  \n",
    "model_cation_red_GAT = GAT(in_channels=5,hidden_channels=256).to(device)  \n",
    "model_IL_ECW_GAT = GAT(in_channels=5,hidden_channels=256).to(device) \n",
    "# GCN\n",
    "model_Tm_GCN = GCN(hidden_dim=128).to(device)\n",
    "model_conductivity_GCN = GCN(hidden_dim=128).to(device) \n",
    "model_anion_ox_GCN = GCN(hidden_dim=128).to(device) \n",
    "model_cation_red_GCN = GCN(hidden_dim=128).to(device) \n",
    "model_IL_ECW_GCN = GCN(hidden_dim=128).to(device) \n",
    "# MLP\n",
    "input_size = 2048\n",
    "hidden_sizes = [256, 64]\n",
    "output_size = 1\n",
    "epochs = 200\n",
    "model_Tm_MLP = MLP(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size).to(device) \n",
    "model_conductivity_MLP = MLP(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size).to(device) \n",
    "model_anion_ox_MLP = MLP(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size).to(device) \n",
    "model_cation_red_MLP = MLP(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size).to(device) \n",
    "model_IL_ECW_MLP = MLP(input_size=input_size, hidden_sizes=hidden_sizes, output_size=output_size).to(device) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25cabc2b",
   "metadata": {},
   "source": [
    "# GAT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ee2dd6-0d79-4afa-8d68-82ffd27c243f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "\n",
    "Tm_train_losses_gat, Tm_val_losses_gat, Tm_test_pred_gat, Tm_test_true_gat, Tm_test_mse_gat, Tm_test_mae_gat, Tm_test_r2_gat = train_epochs(\n",
    "    0, epochs, model_Tm_GAT, Tm_train_loader, Tm_val_loader, Tm_test_loader, \"Tm_GAT_model.pt\"\n",
    ")\n",
    "\n",
    "conductivity_train_losses_gat, conductivity_val_losses_gat, conductivity_test_pred_gat, conductivity_test_true_gat, conductivity_test_mse_gat, conductivity_test_mae_gat, conductivity_test_r2_gat = train_epochs(\n",
    "    0, epochs, model_conductivity_GAT, conductivity_train_loader, conductivity_val_loader, conductivity_test_loader, \"conductivity_GAT_model.pt\", scale=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223e3546",
   "metadata": {},
   "source": [
    "# GCN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6038e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "\n",
    "Tm_train_losses_gcn, Tm_val_losses_gcn, Tm_test_pred_gcn, Tm_test_true_gcn, Tm_test_mse_gcn, Tm_test_mae_gcn, Tm_test_r2_gcn = train_epochs(\n",
    "    0, epochs, model_Tm_GCN, Tm_train_loader, Tm_val_loader, Tm_test_loader, \"Tm_GCN_model.pt\"\n",
    ")\n",
    "\n",
    "conductivity_train_losses_gcn, conductivity_val_losses_gcn, conductivity_test_pred_gcn, conductivity_test_true_gcn, conductivity_test_mse_gcn, conductivity_test_mae_gcn, conductivity_test_r2_gcn = train_epochs(\n",
    "    0, epochs, model_conductivity_GCN, conductivity_train_loader, conductivity_val_loader, conductivity_test_loader, \"conductivity_GCN_model.pt\", scale=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae75a44",
   "metadata": {},
   "source": [
    "# MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7888391",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "\n",
    "Tm_train_losses_mlp, Tm_val_losses_mlp, Tm_test_pred_mlp, Tm_test_true_mlp, Tm_test_mse_mlp, Tm_test_mae_mlp, Tm_test_r2_mlp = train_epochs_mlp(\n",
    "    0, epochs, model_Tm_MLP, Tm_train_loader, Tm_val_loader, Tm_test_loader, \"Tm_MLP_model.pt\", input_type=\"fp\"\n",
    ")\n",
    "\n",
    "conductivity_train_losses_mlp, conductivity_val_losses_mlp, conductivity_test_pred_mlp, conductivity_test_true_mlp, conductivity_test_mse_mlp, conductivity_test_mae_mlp, conductivity_test_r2_mlp = train_epochs_mlp(\n",
    "    0, epochs, model_conductivity_MLP, conductivity_train_loader, conductivity_val_loader, conductivity_test_loader, \"conductivity_MLP_model.pt\", scale=10, input_type=\"fp\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e684c8-f57f-419d-9c25-bcae58912589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa22bd17-2c76-49b6-a8f2-844bca33042e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9126bc-5399-430b-8d55-7fc287394988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9bcabc-2b96-402f-bafe-83db76530691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
